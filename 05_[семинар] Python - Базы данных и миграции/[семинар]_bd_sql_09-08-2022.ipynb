{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Python - базы данных и миграции**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vibo: запускаем Wireshark — анализатор сетевых протоколов \n",
    "#vibo: дать разрешение sudo chmod +x /usr/bin/dumpcap\n",
    "#vibo: обновиться, запустить loopback\n",
    "#vibo: отфильтровать по pgsql"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Клинет-серверный протокол PostgreSQL:** \n",
    "- Клиент -> cообщение (TCP socket) -> PostgreSQL\n",
    "- Клиент <- cообщение (TCP socket) <- PostgreSQL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Фазы клиент-серверного протокола PostgreSQL:**\n",
    "- фаза авторизации (только сообщения про авторизацию)\n",
    "- фаза сеанса (гоняем сообщения - запросы/ответы)\n",
    "- завершение соединения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Два ***протокола*** выполнения запросов PostgreSQL:\n",
    "- Simple Query (протокол простых запросов)\n",
    "- Extended Query (протокол расширенных запросов)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **=== Simple Query (протокол простых запросов) ===**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Клиент -> Query: SELECT 1 -> PostgreSQL      (запрос данных)\n",
    "2. Клиент <- RowDescription <- PostgreSQL       (описание возвращаемых данных)\n",
    "3. Клиент <- DataRow <- PostgreSQL              (возврат данных, НЕ ДОЖИДАЯСЬ ДОПОЛНИТЕЛЬНЫХ КОМАНД ОТ КЛИЕНТА)\n",
    "4. Клиент <- CommandComplete <- PostgreSQL      (сообщение о завершении передачи данных)\n",
    "5. Клиент <- ReadyForQuery <- PostgreSQL        (готов к запросу)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**СООБЩЕНИЕ != ЗАПРОС** (сообщение может содержать несколько запросов)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Особенности протокола простых запросов:**\n",
    "- экранировать запрос необходимо клиенту;\n",
    "- в одном сообщении можно передать несколько запросов, разделенных точкой с запятой;\n",
    "- сервер возвращает все данные после того, как отправлен запрос, нет возможности получать их частями на уровне протокола, но можно читать их по одному из сокета на уровне ***драйвера*** или используя ***курсоры***;\n",
    "- можно отправить несколько сообщений с запросами не дожидаясь ответа и затем обработать ответы в таком же порядке;\n",
    "- этот протокол реализован **psycopg (2, 3)** и **aiopg**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**драйвер** - программа, реализующая протокол определенной базы данных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**курсор** - объект в python, который позволяет выполнять запросы и получать результаты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,), (1,)]\n"
     ]
    }
   ],
   "source": [
    "#vibo: выполним запрос generate_series, некий аналог range из python, только в postgres\n",
    "import psycopg2\n",
    "\n",
    "\n",
    "conn = psycopg2.connect(\"postgresql://postgres:hackme@localhost\")\n",
    "\n",
    "with conn.cursor() as cur:\n",
    "    cur.execute(\"SELECT generate_series(%s, %s);\", (0, 1))\n",
    "    print(cur.fetchall())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В клиенте видим, что запрос уже ушел с подставленными 0 и 1 -> SELECT generate_series(0, 1)\n",
    "\n",
    "    Frame 363: 121 bytes on wire (968 bits), 121 bytes captured (968 bits) on interface lo, id 0\n",
    "    Ethernet II, Src: 00:00:00_00:00:00 (00:00:00:00:00:00), Dst: 00:00:00_00:00:00 (00:00:00:00:00:00)\n",
    "    Internet Protocol Version 6, Src: ::1, Dst: ::1\n",
    "    Transmission Control Protocol, Src Port: 44406, Dst Port: 5432, Seq: 61, Ack: 409, Len: 35\n",
    "    PostgreSQL\n",
    "        Type: Simple query\n",
    "        Length: 34\n",
    "        Query: SELECT generate_series(0, 1);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(2,)]\n"
     ]
    }
   ],
   "source": [
    "#vibo: выполним несколько запросов в одном сообщении\n",
    "import psycopg2\n",
    "\n",
    "\n",
    "conn = psycopg2.connect(\"postgresql://postgres:hackme@localhost\")\n",
    "\n",
    "with conn.cursor() as cur:\n",
    "    cur.execute(\"SELECT 1; SELECT 2;\")\n",
    "    print(cur.fetchall())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ответ запроса 1. потерялся, если хотим увидеть обе строки, то делаем запрос через оператор - **UNION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1,), (2,)]\n"
     ]
    }
   ],
   "source": [
    "#vibo: выполним несколько запросов в одном сообщении с оператором UNION\n",
    "import psycopg2\n",
    "\n",
    "\n",
    "conn = psycopg2.connect(\"postgresql://postgres:hackme@localhost\")\n",
    "\n",
    "with conn.cursor() as cur:\n",
    "    cur.execute(\"SELECT 1 UNION SELECT 2;\")\n",
    "    print(cur.fetchall())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1,)]\n",
      "[(2,)]\n"
     ]
    }
   ],
   "source": [
    "#vibo: а если сделать несколько сообщений, не дожидаясь ответа\n",
    "import psycopg2\n",
    "\n",
    "\n",
    "conn = psycopg2.connect(\"postgresql://postgres:hackme@localhost\")\n",
    "\n",
    "with conn.cursor() as cur:\n",
    "    cur.execute(\"SELECT pg_sleep(5); SELECT 1;\")\n",
    "    print(cur.fetchall())                             #vibo: если не выводить увидим только результат последнего запроса\n",
    "    cur.execute(\"SELECT pg_sleep(5); SELECT 2;\")\n",
    "    print(cur.fetchall())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**psycopg2 не позволяет отправить сообщение 2 не дождавшись ответа на сообщение 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vibo: ок, пишем свой драйвер, запросы ушли одновременно (чего мы и добивались), но на результат это не повлияло. Скорость ответа осталась такая же. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ИТОГО: ПРОТОКОЛ ПРОСТЫХ ЗАПРОСОВ**\n",
    "- чтобы получить все данные из нескольких запросов в одном сообщении нужен UNION;\n",
    "- в **psycopg2** есть интерфейс для экранирования данных, но работает он на стороне клиента;\n",
    "- можно передавать сообщения с запросами не дожидаясь ответа на предыдущие, но это не дает никаких преимуществ по времени;\n",
    "- если хочется выполнить несколько запросов параллельно - нужно несколько соединений."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('58c5080f-6726-42f3-a997-f143ad984201', '(37.46829361638372,55.05982583193995)', None), ('8f484690-f92b-417e-9b68-2bd58f1ed700', '(37.05780740487775,55.683570543711426)', None), ('becd1d25-1ab8-4f89-a310-e8177a94093f', '(37.94867354172965,55.313234742670744)', 'df65a1d8-e3c5-452d-a5b0-4e8b8abd55d3'), ('917e9894-0822-4a33-9bfc-5121b937b637', '(37.14825826460845,55.00325180712231)', None), ('5f32966e-87c9-4725-bf18-3d8439044c11', '(37.14117043538411,55.131343164062876)', None), ('45bec7d8-b60e-4fc0-9752-c0b3f6d204ee', '(37.70299881637874,55.75460344872543)', None), ('5898c44f-bfb8-4b6f-a14a-36e5797828b1', '(37.0970577108166,55.644623924666305)', None), ('abfbb1f6-c9b5-47a5-9f4f-0da16763310b', '(37.238075893682485,55.157759477336185)', None), ('0533e457-40f9-468a-ba70-4f1903b55d6b', '(37.26313503696669,55.3111815759084)', None), ('aff866f5-6877-4eea-9c19-b90980dd0d65', '(37.446735940409766,55.702897019510004)', None)]\n"
     ]
    }
   ],
   "source": [
    "#vibo: вот так можно прочитать базу данных из лекции по scooters\n",
    "import psycopg2\n",
    "\n",
    "conn = psycopg2.connect(\"postgres://postgres:hackme@localhost:5432/scooters\")\n",
    "\n",
    "with conn.cursor() as cur: \n",
    "    cur.execute(\"SELECT * FROM scooters\")\n",
    "    print(cur.fetchall())                             "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***ОЧЕНЬ ВАЖНО ПОНИМАТЬ!!!*** PostgreSQL не может параллельно (асинхронно) обрабатывать запросы. Когда есть соединение с PostgreSQL, мы работаем с ним синхронно или асинхронно в зависимости от выбора протокола. Разница заключается в том, что когда мы работаем **синхронно** - и дошли до извлечения данных наше приложение засыпает до тех пор пока к нему не пришли данные, а если приложение **асинхронное** - у нас засыпает не весь процесс (тред), а засыпает корутина, т.е. ваш код может продолжать работать дальше. Т.к. в асинхронном режиме не весь процесс засыпает, и нам никто не мешает создать еще одно соединение и во втором соединении начать выполнять еще одну команду и дожидаться, что PostgreSQL на нее скажет."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **=== Extended Query (протокол расширенных запросов) ===**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Запрос Query -> Команда **Parse** с запросом -> на стороне PostgreSQL появляется сущность \"Prepared statement\"\n",
    "2. Командой \"Descibe\" мы можем увидеть, какие данные для нас подготовлены, что будет нам выдавать PostgreSQL (\"PretranedDescription\", \"RowDescription\")\n",
    "3. Делаем команду **Bind**, на стороне PostgreSQL создается новая сущность Portal\n",
    "4. Командой \"Descibe\" мы можем увидеть, типы данных (\"RowDescription\")\n",
    "5. Выполняем команду **Execute** (в команде можем контролировать сколько строк хотим получить) -> PostgreSQL возвращает нам строки данных DataRow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Протокол расширенных запросов:**\n",
    "- можно не посылать запрос каждый раз, а переиспользовать ранее посланные;\n",
    "- позволяет экранировать параметры средствами PostgreSQL;\n",
    "- можно контролирвоать процесс получения данных от сервера (для этого не нкжно создавать отдельный курсор);\n",
    "- в одном сообщении может быть толко один запрос;\n",
    "- процесс выполнени запроса разбит на несколько шагов: **parse, bind, execute**;\n",
    "- реализован в **asyncpg** и **psycopg3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting asyncpg\n",
      "  Downloading asyncpg-0.26.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m160.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: asyncpg\n",
      "Successfully installed asyncpg-0.26.0\n"
     ]
    }
   ],
   "source": [
    "!pip install asyncpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vibo: пример кода с расширенным протоколом запросов\n",
    "import asyncio\n",
    "import asyncpg\n",
    "\n",
    "async def main():\n",
    "    #vibo: подключаемся через asyncpg к PostgreSQL\n",
    "    conn = await asyncpg.connect('postgresql://postgres:hackme@localhost')\n",
    "    async with conn.transaction():\n",
    "        cursor = await conn.cursor(\n",
    "            #vibo: указываем отдельно строку, отдельно параметры\n",
    "            'SELECT generate_series(0, $1) as id', 1\n",
    "        )\n",
    "        #vibo: по одной строке забираем из базы данных\n",
    "        print(await cursor.fetch(1))    #[<Record id=0>]\n",
    "        print(await cursor.fetch(1))    #[<Record id=1>]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<Record id=0>]\n",
      "[<Record id=1>]\n"
     ]
    }
   ],
   "source": [
    "#vibo: эту функцию можно запустить из jupyter так\n",
    "await main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<Record id=0>]\n",
      "[<Record id=1>]\n"
     ]
    }
   ],
   "source": [
    "#vibo: или через python\n",
    "!python main1.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим в wireshark следующее:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "36\t9.372794274\t::1\t::1\tPGSQL\t178\t>P/D/H          #vibo: запрос Parse - Describe - Flush\n",
    "37\t9.373112400\t::1\t::1\tPGSQL\t130\t<1/t/T          #vibo: овет Parse completion\n",
    "38\t9.373551040\t::1\t::1\tPGSQL\t154\t>B/S            #vibo: запрос Bind\n",
    "39\t9.373650575\t::1\t::1\tPGSQL\t97\t<2/Z            #vibo: ответ Bined completion\n",
    "40\t9.373765348\t::1\t::1\tPGSQL\t121\t>E/S            #vibo: запрос1 Execute\n",
    "41\t9.373783438\t::1\t::1\tPGSQL\t112\t<D/s/Z          #vibo: собственно Data row 1\n",
    "42\t9.373901571\t::1\t::1\tPGSQL\t121\t>E/S            #vibo: запрос2 Execute\n",
    "43\t9.373911852\t::1\t::1\tPGSQL\t112\t<D/s/Z          #vibo: собственно Data row 2\n",
    "44\t9.374088159\t::1\t::1\tPGSQL\t99\t>Q              #vibo: Simple Query\n",
    "45\t9.374120895\t::1\t::1\tPGSQL\t104\t<C/Z            #vibo: Ready Query \n",
    "46\t9.374199691\t::1\t::1\tPGSQL\t91\t>X              #vibo: Termination"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим (36), что сразу отправляются три команды Parse - Describe - Flush"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Frame 36: 178 bytes on wire (1424 bits), 178 bytes captured (1424 bits) on interface lo, id 0\n",
    "Ethernet II, Src: 00:00:00_00:00:00 (00:00:00:00:00:00), Dst: 00:00:00_00:00:00 (00:00:00:00:00:00)\n",
    "Internet Protocol Version 6, Src: ::1, Dst: ::1\n",
    "Transmission Control Protocol, Src Port: 55784, Dst Port: 5432, Seq: 86, Ack: 409, Len: 92\n",
    "PostgreSQL\n",
    "    Type: Parse\n",
    "    Length: 61\n",
    "    Statement: __asyncpg_stmt_3__\n",
    "    Query: SELECT generate_series(0, $1) as id\n",
    "    Parameters: 0\n",
    "PostgreSQL\n",
    "    Type: Describe\n",
    "    Length: 24\n",
    "    Statement: __asyncpg_stmt_3__\n",
    "PostgreSQL\n",
    "    Type: Flush\n",
    "    Length: 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В ответе обращаем внимание на Type OID: 23 (по этому параметру asyncpg понимает, как ему данные мапить). Стандартные данные в PostgreSQL 23 = int4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Frame 37: 130 bytes on wire (1040 bits), 130 bytes captured (1040 bits) on interface lo, id 0\n",
    "Ethernet II, Src: 00:00:00_00:00:00 (00:00:00:00:00:00), Dst: 00:00:00_00:00:00 (00:00:00:00:00:00)\n",
    "Internet Protocol Version 6, Src: ::1, Dst: ::1\n",
    "Transmission Control Protocol, Src Port: 5432, Dst Port: 55784, Seq: 409, Ack: 178, Len: 44\n",
    "PostgreSQL\n",
    "    Type: Parse completion\n",
    "    Length: 4\n",
    "PostgreSQL\n",
    "    Type: Parameter description\n",
    "    Length: 10\n",
    "    Parameters: 1\n",
    "        Type OID: 23\n",
    "PostgreSQL\n",
    "    Type: Row description\n",
    "    Length: 27\n",
    "    Field count: 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Параметры в DDL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vibo: создадим таблицу с какими-нибудь данными от пользователя и постараемся ее экранировать силами PostgreSQL\n",
    "import asyncio\n",
    "import asyncpg\n",
    "\n",
    "async def main():\n",
    "    #vibo: подключаемся через asyncpg к PostgreSQL\n",
    "    conn = await asyncpg.connect(\n",
    "        'postgresql://postgres:hackme@localhost'\n",
    "    )\n",
    "\n",
    "    await conn.execute(\n",
    "        'CREATE TABLE $1(id SERIAL PRIMARY KEY)', 'mytable'\n",
    "    )\n",
    "\n",
    "    await conn.execute(\n",
    "        'CREATE TABLE mytable($1 SERIAL PRIMARY KEY)', 'mycolumn'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "PostgresSyntaxError",
     "evalue": "syntax error at or near \"$1\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPostgresSyntaxError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/home/vibo/vs_code/!!!bd_sql_09.08.2022.ipynb Cell 36\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/vibo/vs_code/%21%21%21bd_sql_09.08.2022.ipynb#ch0000037?line=0'>1</a>\u001b[0m \u001b[39m#vibo: эту функцию можно запустить из jupyter так\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/vibo/vs_code/%21%21%21bd_sql_09.08.2022.ipynb#ch0000037?line=1'>2</a>\u001b[0m \u001b[39mawait\u001b[39;00m main()\n",
      "\u001b[1;32m/home/vibo/vs_code/!!!bd_sql_09.08.2022.ipynb Cell 36\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/vibo/vs_code/%21%21%21bd_sql_09.08.2022.ipynb#ch0000037?line=4'>5</a>\u001b[0m \u001b[39masync\u001b[39;00m \u001b[39mdef\u001b[39;00m \u001b[39mmain\u001b[39m():\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/vibo/vs_code/%21%21%21bd_sql_09.08.2022.ipynb#ch0000037?line=5'>6</a>\u001b[0m     \u001b[39m#vibo: подключаемся через asyncpg к PostgreSQL\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/vibo/vs_code/%21%21%21bd_sql_09.08.2022.ipynb#ch0000037?line=6'>7</a>\u001b[0m     conn \u001b[39m=\u001b[39m \u001b[39mawait\u001b[39;00m asyncpg\u001b[39m.\u001b[39mconnect(\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/vibo/vs_code/%21%21%21bd_sql_09.08.2022.ipynb#ch0000037?line=7'>8</a>\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mpostgresql://postgres:hackme@localhost\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/vibo/vs_code/%21%21%21bd_sql_09.08.2022.ipynb#ch0000037?line=8'>9</a>\u001b[0m     )\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/vibo/vs_code/%21%21%21bd_sql_09.08.2022.ipynb#ch0000037?line=10'>11</a>\u001b[0m     \u001b[39mawait\u001b[39;00m conn\u001b[39m.\u001b[39mexecute(\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/vibo/vs_code/%21%21%21bd_sql_09.08.2022.ipynb#ch0000037?line=11'>12</a>\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mCREATE TABLE $1(id SERIAL PRIMARY KEY)\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mmytable\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/vibo/vs_code/%21%21%21bd_sql_09.08.2022.ipynb#ch0000037?line=12'>13</a>\u001b[0m     )\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/vibo/vs_code/%21%21%21bd_sql_09.08.2022.ipynb#ch0000037?line=14'>15</a>\u001b[0m     \u001b[39mawait\u001b[39;00m conn\u001b[39m.\u001b[39mexecute(\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/vibo/vs_code/%21%21%21bd_sql_09.08.2022.ipynb#ch0000037?line=15'>16</a>\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mCREATE TABLE mytable($1 SERIAL PRIMARY KEY)\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mmycolumn\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/vibo/vs_code/%21%21%21bd_sql_09.08.2022.ipynb#ch0000037?line=16'>17</a>\u001b[0m     )\n",
      "File \u001b[0;32m~/vs_code/venv-vsc/lib/python3.9/site-packages/asyncpg/connection.py:320\u001b[0m, in \u001b[0;36mConnection.execute\u001b[0;34m(self, query, timeout, *args)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m args:\n\u001b[1;32m    318\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mawait\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_protocol\u001b[39m.\u001b[39mquery(query, timeout)\n\u001b[0;32m--> 320\u001b[0m _, status, _ \u001b[39m=\u001b[39m \u001b[39mawait\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_execute(\n\u001b[1;32m    321\u001b[0m     query,\n\u001b[1;32m    322\u001b[0m     args,\n\u001b[1;32m    323\u001b[0m     \u001b[39m0\u001b[39m,\n\u001b[1;32m    324\u001b[0m     timeout,\n\u001b[1;32m    325\u001b[0m     return_status\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m    326\u001b[0m )\n\u001b[1;32m    327\u001b[0m \u001b[39mreturn\u001b[39;00m status\u001b[39m.\u001b[39mdecode()\n",
      "File \u001b[0;32m~/vs_code/venv-vsc/lib/python3.9/site-packages/asyncpg/connection.py:1659\u001b[0m, in \u001b[0;36mConnection._execute\u001b[0;34m(self, query, args, limit, timeout, return_status, ignore_custom_codec, record_class)\u001b[0m\n\u001b[1;32m   1647\u001b[0m \u001b[39masync\u001b[39;00m \u001b[39mdef\u001b[39;00m \u001b[39m_execute\u001b[39m(\n\u001b[1;32m   1648\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   1649\u001b[0m     query,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1656\u001b[0m     record_class\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1657\u001b[0m ):\n\u001b[1;32m   1658\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stmt_exclusive_section:\n\u001b[0;32m-> 1659\u001b[0m         result, _ \u001b[39m=\u001b[39m \u001b[39mawait\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__execute(\n\u001b[1;32m   1660\u001b[0m             query,\n\u001b[1;32m   1661\u001b[0m             args,\n\u001b[1;32m   1662\u001b[0m             limit,\n\u001b[1;32m   1663\u001b[0m             timeout,\n\u001b[1;32m   1664\u001b[0m             return_status\u001b[39m=\u001b[39mreturn_status,\n\u001b[1;32m   1665\u001b[0m             record_class\u001b[39m=\u001b[39mrecord_class,\n\u001b[1;32m   1666\u001b[0m             ignore_custom_codec\u001b[39m=\u001b[39mignore_custom_codec,\n\u001b[1;32m   1667\u001b[0m         )\n\u001b[1;32m   1668\u001b[0m     \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/vs_code/venv-vsc/lib/python3.9/site-packages/asyncpg/connection.py:1684\u001b[0m, in \u001b[0;36mConnection.__execute\u001b[0;34m(self, query, args, limit, timeout, return_status, ignore_custom_codec, record_class)\u001b[0m\n\u001b[1;32m   1681\u001b[0m executor \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m stmt, timeout: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_protocol\u001b[39m.\u001b[39mbind_execute(\n\u001b[1;32m   1682\u001b[0m     stmt, args, \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m, limit, return_status, timeout)\n\u001b[1;32m   1683\u001b[0m timeout \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_protocol\u001b[39m.\u001b[39m_get_timeout(timeout)\n\u001b[0;32m-> 1684\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mawait\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_do_execute(\n\u001b[1;32m   1685\u001b[0m     query,\n\u001b[1;32m   1686\u001b[0m     executor,\n\u001b[1;32m   1687\u001b[0m     timeout,\n\u001b[1;32m   1688\u001b[0m     record_class\u001b[39m=\u001b[39mrecord_class,\n\u001b[1;32m   1689\u001b[0m     ignore_custom_codec\u001b[39m=\u001b[39mignore_custom_codec,\n\u001b[1;32m   1690\u001b[0m )\n",
      "File \u001b[0;32m~/vs_code/venv-vsc/lib/python3.9/site-packages/asyncpg/connection.py:1711\u001b[0m, in \u001b[0;36mConnection._do_execute\u001b[0;34m(self, query, executor, timeout, retry, ignore_custom_codec, record_class)\u001b[0m\n\u001b[1;32m   1700\u001b[0m \u001b[39masync\u001b[39;00m \u001b[39mdef\u001b[39;00m \u001b[39m_do_execute\u001b[39m(\n\u001b[1;32m   1701\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   1702\u001b[0m     query,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1708\u001b[0m     record_class\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1709\u001b[0m ):\n\u001b[1;32m   1710\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1711\u001b[0m         stmt \u001b[39m=\u001b[39m \u001b[39mawait\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_statement(\n\u001b[1;32m   1712\u001b[0m             query,\n\u001b[1;32m   1713\u001b[0m             \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   1714\u001b[0m             record_class\u001b[39m=\u001b[39mrecord_class,\n\u001b[1;32m   1715\u001b[0m             ignore_custom_codec\u001b[39m=\u001b[39mignore_custom_codec,\n\u001b[1;32m   1716\u001b[0m         )\n\u001b[1;32m   1717\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1718\u001b[0m         before \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mmonotonic()\n",
      "File \u001b[0;32m~/vs_code/venv-vsc/lib/python3.9/site-packages/asyncpg/connection.py:398\u001b[0m, in \u001b[0;36mConnection._get_statement\u001b[0;34m(self, query, timeout, named, use_cache, ignore_custom_codec, record_class)\u001b[0m\n\u001b[1;32m    395\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    396\u001b[0m     stmt_name \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m--> 398\u001b[0m statement \u001b[39m=\u001b[39m \u001b[39mawait\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_protocol\u001b[39m.\u001b[39mprepare(\n\u001b[1;32m    399\u001b[0m     stmt_name,\n\u001b[1;32m    400\u001b[0m     query,\n\u001b[1;32m    401\u001b[0m     timeout,\n\u001b[1;32m    402\u001b[0m     record_class\u001b[39m=\u001b[39mrecord_class,\n\u001b[1;32m    403\u001b[0m     ignore_custom_codec\u001b[39m=\u001b[39mignore_custom_codec,\n\u001b[1;32m    404\u001b[0m )\n\u001b[1;32m    405\u001b[0m need_reprepare \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    406\u001b[0m types_with_missing_codecs \u001b[39m=\u001b[39m statement\u001b[39m.\u001b[39m_init_types()\n",
      "File \u001b[0;32m~/vs_code/venv-vsc/lib/python3.9/site-packages/asyncpg/protocol/protocol.pyx:168\u001b[0m, in \u001b[0;36mprepare\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mPostgresSyntaxError\u001b[0m: syntax error at or near \"$1\""
     ]
    }
   ],
   "source": [
    "#vibo: эту функцию можно запустить из jupyter так\n",
    "await main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PostgresSyntaxError: syntax error at or near \"$1\" - НЕЛЬЗЯ ЭКРАНИРОВАТЬ DDL НА УРОНЕ ПРОТОКОЛА**, если хотим использовать запросы в которых есть пользовательский ввод, которому мы не доверяем - прийдется экранировать это на уровне клиента, на уровне протокола не получится."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Почему DDL работает в SQLAlchemy 1.4?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sqlalchemy\n",
      "  Downloading SQLAlchemy-1.4.40-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m412.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: greenlet!=0.4.17 in ./venv-vsc/lib/python3.9/site-packages (from sqlalchemy) (1.1.2)\n",
      "Installing collected packages: sqlalchemy\n",
      "Successfully installed sqlalchemy-1.4.40\n"
     ]
    }
   ],
   "source": [
    "!pip install sqlalchemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vibo: используем SQLAlchemy 1.4+, т.к. в ней появился asyncpg\n",
    "import asyncio\n",
    "from sqlalchemy import Table, MetaData, Column, Integer\n",
    "from sqlalchemy.ext.asyncio import create_async_engine\n",
    "\n",
    "metadata = MetaData()\n",
    "example = Table('example', metadata, Column('id', Integer()))\n",
    "\n",
    "async def main():\n",
    "    engine = create_async_engine(\n",
    "        'postgresql+asyncpg://postgres:hackme@localhost'\n",
    "    )\n",
    "    async with engine.begin() as conn:\n",
    "        await conn.run_sync(metadata.create_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vibo: эту функцию можно запустить из jupyter так\n",
    "await main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ВСЕ РАБОТАЕТ! SQLAlchemy экранирует данные на стророне клиента** Запрос CREATE TABLE отправляется без всяких $1, он уже полностью сформирован. Alchemy сделала за нас всю работу. Магии в этом нет DDL экранировать в данном случае нельзя. Еще одна особенность использования данного протокола - это ораничение на количество переменных (32767 + 1 -> лимит, органичение). В  SQLAlchemy такие органичения отсутствуют."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ИТОГО: ПРОТОКОЛ РАСШИРЕННЫХ ЗАПРОСОВ**\n",
    "- протокол более сложный в реализации, но позволяет более эффективно работать с запросами, данными (как минимум экономим на команде parse);\n",
    "- дает больше контроля над передачей данных на уровне протокола;\n",
    "- состояние описывается несколькими сущностями;\n",
    "- не позволяет экранировать DDL, нужно делать на клиенте (как в psycopg2);\n",
    "- его нет в psycopg2, есть в **psycopg3** и в **libpq**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**экранирование** - ограничение, накладываемое на данные от пользователя, например, чтобы в одном сообщении на регистрацию в базе данных не пришел запрос DROP TABLE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **=== Д Р А Й В Е Р Ы ====**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Синхронные**:\n",
    "- **psycopg2, 3**\n",
    "- pg8000\n",
    "- PyGreSQL\n",
    "- py-postgresql\n",
    "- psycopg2cffi\n",
    "\n",
    "**Ассинхронные**:\n",
    "- **aiopg**\n",
    "- **asyncpg**\n",
    "- psycopg3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "libpq - интерфейс PostgreSQL для программирования приложений на языке Си. Содержит набор функций, которые позволяют клиенту передавать запросы серверу PostgreSQL и принимать результаты этих запросов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DBAPI 2.0 (PEP 249) - набор рекомендаций по реализации драйверов, предлагающий единый синтаксис и способ доступа к базе данных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**psycopg2** (наиболее популярный синхронный драйвер с очень богатыми возможностями):\n",
    "- используется в SQLAlchemy и Django\n",
    "- реализован на Си (только CPython)\n",
    "- использует libpq\n",
    "- потокобезопасный (одно соединение в нескольких потоках)\n",
    "- умеет экранировать DDL на клиенте\n",
    "- DictCursor, RealDictCursor, NamedTupleCursor\n",
    "- LoggingConnection, Logging Cursor\n",
    "- COPY TO, COPY FROM\n",
    "- LogicalReplicationConnection, PhysicalReplicationConnection и др.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**psycopg3**\n",
    "- поддерживает оба протокола запросов в PosgreSQL\n",
    "- может использоваться как в синхронном, так и асинхронном режиме\n",
    "- поддерживается в SQLAlchemy 2.0 (она еще в разработке)\n",
    "- использует libpq\n",
    "- пулы соединений (пакет psycopg_pool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**pg8000** (реализация синхронного драйвера на чистом python, но медленный)\n",
    "- не требует libpq\n",
    "- совместим с CPython, Jython, PyPy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**aiopg** (ассинхронная реализация psycopg2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**asyncpg** (самый быстрый ассинхронный драйвер для CPython)\n",
    "- использует бинарный протокол PostgreSQL, напрямую, без DBAPI\n",
    "- только Prepared statement\n",
    "- транзакции\n",
    "- курсоры и частичная интеграция по данным\n",
    "- пулы соединениц"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **=== Как подключиться? ===**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Docker**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "docker run --rm \\\n",
    "    --detach \\\n",
    "    --publish 5432:5432 \\\n",
    "    --env POSTGRES_DB=test \\\n",
    "    --env POSTGRES_USER=user \\\n",
    "    --env POSTGRES_PASSWORD=hackme \\\n",
    "    postgres"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Локально**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1,)\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "\n",
    "conn = psycopg2.connect('postgresql://postgres:hackme@localhost')\n",
    "cur = conn.cursor()\n",
    "\n",
    "cur.execute(\"SELECT 1\")\n",
    "data = cur.fetchone() # <class 'tuple'>: (1,)\n",
    "print(data)\n",
    "\n",
    "cur.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оъекты Connection и Cursor представляют интерфейс контекстного менеджера (если бы не это, то пришлось бы писать close)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1,)\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "\n",
    "with psycopg2.connect('postgresql://postgres:hackme@localhost') as conn:\n",
    "    with conn.cursor() as cur:\n",
    "        cur.execute(\"SELECT 1\")\n",
    "        data = cur.fetchone() # <class 'tuple'>: (1,)\n",
    "        print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Получаем несколько строк (все результаты запроса)**\n",
    "Cursor.fetchall() возвращает все (оставшиеся) результаты запроса в виде кортежа, либо пустой список"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "\n",
    "with psycopg2.connect('postgresql://postgres:hackme@localhost') as conn:\n",
    "    with conn.cursor() as cur:\n",
    "        cur.execute(\"SELECT * FROM generate_series(1, 999)\")\n",
    "        data = cur.fetchall() # <class 'list'>: [(1,), (2,), (3,), (4,), ...]\n",
    "        #print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1,)\n"
     ]
    }
   ],
   "source": [
    "#vibo: несмотря на то, что мы просим одно значение PostgreSQL возвращает все\n",
    "import psycopg2\n",
    "\n",
    "with psycopg2.connect('postgresql://postgres:hackme@localhost') as conn:\n",
    "    with conn.cursor() as cur:\n",
    "        cur.execute(\"SELECT * FROM generate_series(1, 999)\")\n",
    "        \n",
    "        for row in cur:\n",
    "            print(row) # <class 'tuple'>: (1,)\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **=== К У Р С О Р Ы ===**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- позволяют выполнять запросы и получать результаты\n",
    "- бывают client-side и server-side (именованные)\n",
    "- в одном соединении может быть несколько курсоров одновременно, но только один курсор работает в один момент времени\n",
    "- курсоры одного соединение не изолированы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**На стороне КЛИЕНТА:**\n",
    "- conn.cursor()\n",
    "- обычный объект в Python\n",
    "- получает результаты запроса сразу целиком в память\n",
    "- подходят дял работы с небольшим количеством данных\n",
    "- неэффективно расходуют память"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**На стороное СЕРВЕРА:**\n",
    "- conn.cursor(name='somename')\n",
    "- специальный объект в PostgreSQL, создается с помощью команды DECLARE\n",
    "- может получать результаты запроса по частям\n",
    "- может двигаться по результатам вперед-назад\n",
    "- хороши для эффективной работы с большим количеством данных\n",
    "- позволяют по кусочкам отрабатывать результаты сразу нескольких запросов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Итерация по курсору на стороне сервера**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1,)\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "\n",
    "#vibo: подключаемся к PostgreSQL\n",
    "with psycopg2.connect('postgresql://postgres:hackme@localhost') as conn:\n",
    "    #vibo: создаем именованный курсок example\n",
    "    with conn.cursor(name='example') as cur:\n",
    "        \n",
    "        #vibo: изменяем количество объектов, которые курсор будет забирвть каждый раз (по умолчанию их 2000)\n",
    "        # by default: 2000\n",
    "        cur.itersize = 1\n",
    "\n",
    "        #vibo: задаем range от 1 до 999\n",
    "        cur.execute(\"SELECT * FROM generate_series(1, 999)\")\n",
    "        \n",
    "        #vibo: берем первую строчку и прерываемся\n",
    "        for row in cur:\n",
    "            print(row) # <class 'tuple'>: (1,)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1,), (2,), (3,), (4,), (5,)]\n",
      "[(1,), (2,), (3,), (4,), (5,)]\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "\n",
    "with psycopg2.connect('postgresql://postgres:hackme@localhost') as conn:\n",
    "    with conn.cursor(name='example') as cur:\n",
    "        cur.itersize = 1\n",
    "        cur.execute(\"SELECT * FROM generate_series(1, 5)\")\n",
    "\n",
    "        print(cur.fetchall()) # [(1,), (2,), (3,), (4,) (5,)]\n",
    "\n",
    "        # cur.scroll (0, mode='absolute')\n",
    "        cur.scroll(-6)\n",
    "\n",
    "        print(cur.fetchall()) # [(1,), (2,), (3,), (4,) (5,)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DictCursor** (позволяет обращаться к контейнеру с данными по названию столбцов)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import psycopg2\n",
    "from psycopg2.extras import DictCursor\n",
    "\n",
    "with psycopg2.connect('postgresql://postgres:hackme@localhost') as conn:\n",
    "    with conn.cursor(cursor_factory=DictCursor) as cur:\n",
    "        cur.execute(\"SELECT * FROM generate_series(1, 999) as col\")\n",
    "        row = cur.fetchone() # {psycopg2.extras.DictRow} [1]\n",
    "        row[0] # {int} 1\n",
    "        row['col'] # {int} 1\n",
    "        json.dumps(row) # {str} \"[1]\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RealDictCursor** (основным преимуществом является простота получения данных в виде json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/home/vibo/vs_code/!!!bd_sql_09.08.2022.ipynb Cell 75\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/vibo/vs_code/%21%21%21bd_sql_09.08.2022.ipynb#ch0000079?line=7'>8</a>\u001b[0m row \u001b[39m=\u001b[39m cur\u001b[39m.\u001b[39mfetchone() \u001b[39m# {psycopg2.extras.RealDictRow} [1]\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/vibo/vs_code/%21%21%21bd_sql_09.08.2022.ipynb#ch0000079?line=8'>9</a>\u001b[0m row[\u001b[39m'\u001b[39m\u001b[39mcol\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m# {int} 1\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/vibo/vs_code/%21%21%21bd_sql_09.08.2022.ipynb#ch0000079?line=9'>10</a>\u001b[0m row[\u001b[39m0\u001b[39;49m] \u001b[39m# KeyError\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/vibo/vs_code/%21%21%21bd_sql_09.08.2022.ipynb#ch0000079?line=10'>11</a>\u001b[0m json\u001b[39m.\u001b[39mdumps(row)\n",
      "\u001b[0;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import psycopg2\n",
    "from psycopg2.extras import RealDictCursor\n",
    "\n",
    "with psycopg2.connect('postgresql://postgres:hackme@localhost') as conn:\n",
    "    with conn.cursor(cursor_factory=RealDictCursor) as cur:\n",
    "        cur.execute(\"SELECT * FROM generate_series(1, 999) as col\")\n",
    "        row = cur.fetchone() # {psycopg2.extras.RealDictRow} [1]\n",
    "        row['col'] # {int} 1\n",
    "        row[0] # KeyError\n",
    "        json.dumps(row) # {str} \"{'col\": 1}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NamedTupleCursor** (вызов через точку)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "from psycopg2.extras import NamedTupleCursor\n",
    "\n",
    "with psycopg2.connect('postgresql://postgres:hackme@localhost') as conn:\n",
    "    with conn.cursor(cursor_factory=NamedTupleCursor) as cur:\n",
    "        cur.execute(\"SELECT * FROM generate_series(1, 999) as col\")\n",
    "        row = cur.fetchone() # {psycopg2.extras.Record} [1]\n",
    "        row[0] # {int} 1\n",
    "        row.col # {int} 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **=== Т Р А Н З А К Ц И И ===**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- psycopg2 создает транзакию перед выполнением первого запроса\n",
    "- следующие запросы (в т.ч. других курсоров) выполняются в контексте одной транзакции\n",
    "- чтобы изменения применились необходимо явно обратитсья **Connection.commit()**\n",
    "- если какой-либо запрос завершается неудачно, транзакция будет прервана. Никакой другой запрос не будет выполнен до вызова метода **rollback()**\n",
    "- в одном соединении можно выполнять несколько почледовательных транакций"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "\n",
    "with psycopg2.connect('postgresql://postgres:hackme@localhost') as conn:\n",
    "    with conn.cursor() as cur:\n",
    "        # 1st transaction\n",
    "        cur.execute(\n",
    "            \"CREATE TABLE users(id SERIAL PRIMARY KEY, name TEXT)\"\n",
    "        )\n",
    "        conn.commit()\n",
    "\n",
    "        # 2st transaction\n",
    "        cur.execute(\n",
    "            \"INSERT INTO users(name) VALUES ('Elon Musk')\"\n",
    "        )\n",
    "        conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- многие драйверы (или абстаркции более высокого уровня) представляют контекстные менеджеры для работы с транакциями\n",
    "- если контекстный менеджер завершаетс яуспешно - вызывается Connection.commit() и все изменения сохраняются\n",
    "- если внутри контекстного менеджена происходит ошибка - вызывается Connection.rollback() и все изменения откладываются "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Как сделать контекстный менеджер для транзакций**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from psycopg2.extensions import STATUS_IN_TRANSACTION\n",
    "\n",
    "class TransactionCtx:\n",
    "    def __init__(self, conn):\n",
    "        self.conn = conn\n",
    "    \n",
    "    def __enter__(self):\n",
    "        return self\n",
    "    \n",
    "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "        if self.conn.status == STATUS_IN_TRANSACTION:\n",
    "            if exc_val:\n",
    "                self.conn.rollback()\n",
    "            else:\n",
    "                self.conn.commit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Как испоьзовать контекстный менеджер для транзакций**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/vibo/vs_code/!!!bd_sql_09.08.2022.ipynb Cell 85\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/vibo/vs_code/%21%21%21bd_sql_09.08.2022.ipynb#ch0000089?line=4'>5</a>\u001b[0m \u001b[39mwith\u001b[39;00m conn\u001b[39m.\u001b[39mcursor() \u001b[39mas\u001b[39;00m cur:\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/vibo/vs_code/%21%21%21bd_sql_09.08.2022.ipynb#ch0000089?line=5'>6</a>\u001b[0m     cur\u001b[39m.\u001b[39mexecute(\u001b[39m'\u001b[39m\u001b[39mSELECT 1\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/vibo/vs_code/%21%21%21bd_sql_09.08.2022.ipynb#ch0000089?line=6'>7</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "\n",
    "with psycopg2.connect('postgresql://postgres:hackme@localhost') as conn:\n",
    "    with TransactionCtx(conn) as transaction:\n",
    "        with conn.cursor() as cur:\n",
    "            cur.execute('SELECT 1')\n",
    "            raise RuntimeError\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Точки сохранения в транзакциях** (SAVEPOINT позволяет откатить все команды, выполненные после нее и восстановить состояние на момент утсановки этой точки)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with psycopg2.connect('postgresql://postgres:hackme@localhost') as conn:\n",
    "    with conn.cursor() as cur:\n",
    "        cur.execute(\"CREATE TABLE users(id ...)\")\n",
    "        cur.execute(\"SAVEPOINT sp1\")\n",
    "\n",
    "        try:\n",
    "            cur.execute(\"CREATE TABLE users(id ...)\")\n",
    "        except psycopg2.errors.DatabaseError:\n",
    "            cur.execute(\"ROLLBACK TO SAVEPOINT sp1\")\n",
    "        \n",
    "        conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RETURNING** (позволяет получать данные из модифицируемых строк в процессе их обработки в запросах INSERT, UPDATE, DELETE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "\n",
    "query = \"INSERT INTO users(name) VALUES ('John') RETURNING users.*\"\n",
    "\n",
    "with psycopg2.connect('postgresql://postgres:hackme@localhost') as conn:\n",
    "    with conn.cursor() as cur:\n",
    "        cur.execute(query)\n",
    "        row = cur.fetchone() # <class 'tuple'>: (1, 'John')\n",
    "        conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "\n",
    "query = \"DELETE FROM users RETURNING users.*\"\n",
    "\n",
    "with psycopg2.connect('postgresql://postgres:hackme@localhost') as conn:\n",
    "    with conn.cursor() as cur:\n",
    "        cur.execute(query)\n",
    "        row = cur.fetchall() # <class 'list'>: (1, 'John')\n",
    "        conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**UPSERT: update или insert**\n",
    "- указывает действие, выполняемое в случае нарушения ограничения уникальности или ограничения-исключения\n",
    "- DO NOTHING - отмняет добавление строки\n",
    "- DO UPDATE - производит изменение строки\n",
    "- позволят выполнять операции (если нет - создать, если есть - обновить) атомарно за один запрос, можно совмещать с RETURNING\n",
    "- не может дважды за один запрос обрабоать одну и ту же строку "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "\n",
    "with psycopg2.connect('postgresql://postgres:hackme@localhost') as conn:\n",
    "    with conn.cursor() as cur:\n",
    "        cur.execute(\"\"\"\n",
    "            CREATE TABLE domains (\n",
    "                id SERIAL PRIMARY KEY, name TEXT UNIQUE, owner TEXT\n",
    "            )\n",
    "        \"\"\")\n",
    "        conn.commit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "\n",
    "with psycopg2.connect('postgresql://postgres:hackme@localhost') as conn:\n",
    "    with conn.cursor() as cur:\n",
    "\n",
    "        cur.execute(\"\"\"\n",
    "            INSERT INTO domains (name, owner) VALUES\n",
    "            ('example.com', 'John Travolta')\n",
    "        \"\"\")\n",
    "\n",
    "        cur.execute(\"\"\"\n",
    "            INSERT INTO domains (name, owner) VALUES\n",
    "            ('example.com', 'Angelina Jolie')\n",
    "            ON CONFLICT (name) DO UPDATE SET owner = EXCLUDED.owner\n",
    "            RETURNING domains.*\n",
    "        \"\"\")\n",
    "\n",
    "        # <class 'tuple'>: (1, 'example.com', 'Angelina Jolie')\n",
    "        row = cur.fetchone()\n",
    "        conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 'example.com', 'Angelina Jolie')]\n"
     ]
    }
   ],
   "source": [
    "conn = psycopg2.connect(\"postgresql://postgres:hackme@localhost\")\n",
    "\n",
    "with conn.cursor() as cur: \n",
    "    cur.execute(\"SELECT * FROM domains\")\n",
    "    print(cur.fetchall())   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SELECT FOR UPDATE** (блокирует выбранные строки для изменения; защищает от блокировки, изменения и удаленич другими транзакциями до заврешения текущей)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "\n",
    "with psycopg2.connect('postgresql://postgres:hackme@localhost') as conn:\n",
    "    with conn.cursor() as cur:\n",
    "        cur.execute(\n",
    "            \"SELECT * FROM domains WHERE name = %s FOR UPDATE\",\n",
    "            ('example.com', )\n",
    "        )\n",
    "\n",
    "        domain_id, name, *_ = cur.fetchone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with psycopg2.connect('postgresql://postgres:hackme@localhost') as conn:\n",
    "    with conn.cursor() as cur:\n",
    "        cur.execute(\n",
    "            \"\"\"\n",
    "            UPDATE domains SET owner = %(owner)s\n",
    "            WHERE id = %(domain_id)s\n",
    "            \"\"\",\n",
    "            {\n",
    "                'owner': 'New Company Ins',\n",
    "                'domain_id': domain_id\n",
    "            }\n",
    "        )\n",
    "\n",
    "        conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Сырые SQL запросы**\n",
    "\n",
    "Недостатки:\n",
    "- нельзя переиспользвать/расширять\n",
    "- большие запросы сложно читать, писать во вложенных конструкциях из-за отступов\n",
    "- нет инструментов для динамического построения запросов\n",
    "- при миграциях нужно погрепать все сырые запросы в проекте\n",
    "\n",
    "Достоинства:\n",
    "- не требуется дополнительных библиотек\n",
    "- нет накладных расходов на обработку"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Query builder**\n",
    "\n",
    "Недостатки:\n",
    "- за удобство приходится платить накладными расходами - временем на генерацию запросов и памятью\n",
    "\n",
    "Достоинства:\n",
    "- Python-синтаксис, легко разделять на части и читать\n",
    "- запросы можно переиспользовать и расширять\n",
    "- построение динамических запросов\n",
    "- при изменениях достатоно статического анализа кода"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **=== SQL Alchemy===**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- поддерживает огромное количество драйверов, баз данных, очень богатые возможности, при этом очень гибкая и дает честный единый интерфейс\n",
    "- отличная документация, большое сообщество, активно разрабатывается\n",
    "- предлагает ORM из коробки, а также много совместимых инструментов для разработки, миграций и тестирования\n",
    "- не диктует каких-либо фреймворков и библиотек\n",
    "- у нее очень крутой разработчик!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ORM (Object-Relational Mapping)** - объектно-реляционное отображение, или преобразование - технология программирования,, которая связывает базы данных с концепциями объектно-ориентированных языков программирования, создавая \"виртуальную объектную базу данных\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Из чего состоит Alchemy:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Dialect** используется для общения с различными имплементациями DBAPI, драйверами и базами данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По умолчанию из коробки доступны:\n",
    "- PostgreSQL\n",
    "- MySQL\n",
    "- SQLite\n",
    "- Oracle\n",
    "- Microsoft SQL Server"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Engine** скрывает за собой пул подключений и диалект, которые работают непосредственно с модулями DBAPI (драйвером) и базой данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-11 10:54:22,371 INFO sqlalchemy.engine.Engine select pg_catalog.version()\n",
      "2022-08-11 10:54:22,371 INFO sqlalchemy.engine.Engine [raw sql] {}\n",
      "2022-08-11 10:54:22,374 INFO sqlalchemy.engine.Engine select current_schema()\n",
      "2022-08-11 10:54:22,375 INFO sqlalchemy.engine.Engine [raw sql] {}\n",
      "2022-08-11 10:54:22,377 INFO sqlalchemy.engine.Engine show standard_conforming_strings\n",
      "2022-08-11 10:54:22,378 INFO sqlalchemy.engine.Engine [raw sql] {}\n",
      "2022-08-11 10:54:22,379 INFO sqlalchemy.engine.Engine SELECT 1\n",
      "2022-08-11 10:54:22,379 INFO sqlalchemy.engine.Engine [raw sql] {}\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import create_engine\n",
    "\n",
    "#vibo: говорим engine подключайся сюда, он сам выбирает драйвер\n",
    "engine = create_engine(\n",
    "    'postgresql://postgres:hackme@localhost', echo=True\n",
    ")\n",
    "with engine.connect() as conn:\n",
    "\n",
    "    # {sqlalchemy.engine.result.RowProxy} (1,)\n",
    "    data = conn.execute('SELECT 1').fetchone()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. MetaDate и Table**\n",
    "\n",
    "- **MetaDate** - контейнер, который содержит информацию о схеме быз данных: таблицах, индексах, типах данных и т.д.\n",
    "- **Table** - содержит описание таблиц. Для того, чтобы SQLAlchemy могла генерировать запросы ей требуется информация о таблицах (типы столбцов, индексы и т.п)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Создание таблицы с помощью SQLAlchemy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-11 11:05:05,926 INFO sqlalchemy.engine.Engine select pg_catalog.version()\n",
      "2022-08-11 11:05:05,927 INFO sqlalchemy.engine.Engine [raw sql] {}\n",
      "2022-08-11 11:05:05,929 INFO sqlalchemy.engine.Engine select current_schema()\n",
      "2022-08-11 11:05:05,930 INFO sqlalchemy.engine.Engine [raw sql] {}\n",
      "2022-08-11 11:05:05,931 INFO sqlalchemy.engine.Engine show standard_conforming_strings\n",
      "2022-08-11 11:05:05,931 INFO sqlalchemy.engine.Engine [raw sql] {}\n",
      "2022-08-11 11:05:05,934 INFO sqlalchemy.engine.Engine BEGIN (implicit)\n",
      "2022-08-11 11:05:05,935 INFO sqlalchemy.engine.Engine select relname from pg_class c join pg_namespace n on n.oid=c.relnamespace where pg_catalog.pg_table_is_visible(c.oid) and relname=%(name)s\n",
      "2022-08-11 11:05:05,936 INFO sqlalchemy.engine.Engine [generated in 0.00072s] {'name': 'domains'}\n",
      "2022-08-11 11:05:05,938 INFO sqlalchemy.engine.Engine COMMIT\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import MetaData, Table, Column, Integer, String\n",
    "\n",
    "metadata = MetaData()\n",
    "domains = Table(\n",
    "    'domains',\n",
    "    metadata,\n",
    "    Column('id', Integer, primary_key=True),\n",
    "    Column('name', String, unique=True),\n",
    "    Column('owner', String),\n",
    ")\n",
    "\n",
    "engine = create_engine(\n",
    "    'postgresql://postgres:hackme@localhost', echo=True\n",
    ")\n",
    "with engine.connect() as conn:\n",
    "    metadata.create_all(engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Добавление данных с помощью Alchemy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-11 11:18:21,074 INFO sqlalchemy.engine.Engine BEGIN (implicit)\n",
      "2022-08-11 11:18:21,076 INFO sqlalchemy.engine.Engine INSERT INTO domains (name, owner) VALUES (%(name_m0)s, %(owner_m0)s), (%(name_m1)s, %(owner_m1)s) RETURNING domains.id, domains.name, domains.owner\n",
      "2022-08-11 11:18:21,077 INFO sqlalchemy.engine.Engine [no key 0.00078s] {'name_m0': 'example.org', 'owner_m0': 'Vim Diesel', 'name_m1': 'anoter.com', 'owner_m1': 'Pg Dumpledore'}\n",
      "2022-08-11 11:18:21,082 INFO sqlalchemy.engine.Engine COMMIT\n"
     ]
    }
   ],
   "source": [
    "with engine.begin() as conn:\n",
    "\n",
    "    query = domains.insert().values([\n",
    "        {'name': 'example.org', 'owner': 'Vim Diesel'},\n",
    "        {'name': 'anoter.com', 'owner': 'Pg Dumpledore'}\n",
    "    ]).returning(*domains.columns)\n",
    "\n",
    "    # <clas 'list'>: [(1, 'example.org', 'Vim Die..]\n",
    "    data = conn.execute(query).fetchall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Получение данных с помощью SQLAlchemy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-11 11:20:43,916 INFO sqlalchemy.engine.Engine SELECT domains.id, domains.name, domains.owner \n",
      "FROM domains\n",
      "2022-08-11 11:20:43,917 INFO sqlalchemy.engine.Engine [cached since 616.4s ago] {}\n"
     ]
    }
   ],
   "source": [
    "with engine.connect() as conn:\n",
    "    \n",
    "    query = domains.select()\n",
    "\n",
    "    # <class 'list'>: [(1, 'example.org', 'Vim Die...]\n",
    "    data = conn.execute(query).fetchall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Расширение запросов**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'Select'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/home/vibo/vs_code/!!!bd_sql_09.08.2022.ipynb Cell 116\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/vibo/vs_code/%21%21%21bd_sql_09.08.2022.ipynb#ch0000118?line=0'>1</a>\u001b[0m \u001b[39m#vibo: пример 1.\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/vibo/vs_code/%21%21%21bd_sql_09.08.2022.ipynb#ch0000118?line=2'>3</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mSelect\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/vibo/vs_code/%21%21%21bd_sql_09.08.2022.ipynb#ch0000118?line=4'>5</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_domains\u001b[39m(is_deleted\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Select:\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/vibo/vs_code/%21%21%21bd_sql_09.08.2022.ipynb#ch0000118?line=5'>6</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m domains\u001b[39m.\u001b[39mselect()\u001b[39m.\u001b[39mwhere(\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/vibo/vs_code/%21%21%21bd_sql_09.08.2022.ipynb#ch0000118?line=6'>7</a>\u001b[0m         domains\u001b[39m.\u001b[39mc\u001b[39m.\u001b[39mis_deleted \u001b[39m==\u001b[39m is_deleted\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/vibo/vs_code/%21%21%21bd_sql_09.08.2022.ipynb#ch0000118?line=7'>8</a>\u001b[0m     )\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'Select'"
     ]
    }
   ],
   "source": [
    "#vibo: пример 1.\n",
    "\n",
    "def get_domains(is_deleted=False) -> Select:\n",
    "    return domains.select().where(\n",
    "        domains.c.is_deleted == is_deleted\n",
    "    )\n",
    "\n",
    "def get_expiring_domains() -> Select:\n",
    "    date = datetime.now() + timedelta(days=2)\n",
    "    return get_domains().where(domains.expire_at < date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (331547766.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Input \u001b[0;32mIn [35]\u001b[0;36m\u001b[0m\n\u001b[0;31m    def get_domains(is_deleted=False, filter_query=) -> Select:\u001b[0m\n\u001b[0m                                                   ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#vibo: пример 2.\n",
    "\n",
    "def get_domains(is_deleted=False, filter_query=) -> Select:\n",
    "    query = domains.select().where(\n",
    "        domains.c.is_deleted == is_deleted\n",
    "    )\n",
    "    \n",
    "    if filter_query:\n",
    "        subq = filter_query.alias()\n",
    "        query = select(query.columns).select_from(\n",
    "            quert.jion(\n",
    "                subq, subq.c.domain_id == query.c.domain_id\n",
    "            )\n",
    "        )\n",
    "        \n",
    "    return query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Query builder SQLAlchemy и асинхронный код**\n",
    "\n",
    "- Core можно использовать в качестве генератора запросов с асинхронными драйверами (aiopg для psycopg2, asyncpgsa для asyncpg)\n",
    "- в этом случае Engine не будет использоваться, SQLAlchemy будет только генерировать запросы, а ввыполняться они могут отдельным драйвером"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **=== ORM - Object Relational Mapping ===**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- абстракция высокого уровня, позволяет работать с данными с использованием объектно-ориентированной парадигмы\n",
    "- позволяет размещать всю логику (методы, константы), связанную с сущностью в класс"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ORM Объект (Сессия) ---> Query builder --> SQL запросы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Declarative: SQLAlchemy ORM**:\n",
    "- с помощью метакласса создается атрибут класса Table, связывает поля объекта со столбцами таблицы (Mapper), добавляет ссылку на объект MetaData\n",
    "- для синхронизации состояния объектов в базе данных и объектной модели используется специальный объект - Session\n",
    "- предоставляет механизм кэширования создания объектов и запросов - Baked Queries (после 1.4/2.0 больше не требуется)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Как описать сущность в Declarative**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "\n",
    "#vibo: возвращаем базовый класс, от которого можем наследоваться\n",
    "Base = declarative_base()\n",
    "\n",
    "#vibo: описываем уже не таблицу, а класс\n",
    "class Domain(Base):\n",
    "    __tablename__ = 'domains'\n",
    "\n",
    "    id = Column(Integer, primary_key=True)\n",
    "    name = Column(String, unique=True)\n",
    "    owner = Column(String)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"<Domain(name='%s', owner='%s')>\" %(\n",
    "            self.name, self.owner\n",
    "        )\n",
    "    \n",
    "    def get_zone(self) -> str:\n",
    "        return self.name.split('.')[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Как работать с объектами ORM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "domains\n",
      "MetaData()\n",
      "2022-08-11 14:28:09,320 INFO sqlalchemy.engine.Engine select pg_catalog.version()\n",
      "2022-08-11 14:28:09,321 INFO sqlalchemy.engine.Engine [raw sql] {}\n",
      "2022-08-11 14:28:09,324 INFO sqlalchemy.engine.Engine select current_schema()\n",
      "2022-08-11 14:28:09,325 INFO sqlalchemy.engine.Engine [raw sql] {}\n",
      "2022-08-11 14:28:09,327 INFO sqlalchemy.engine.Engine show standard_conforming_strings\n",
      "2022-08-11 14:28:09,328 INFO sqlalchemy.engine.Engine [raw sql] {}\n",
      "2022-08-11 14:28:09,330 INFO sqlalchemy.engine.Engine BEGIN (implicit)\n",
      "2022-08-11 14:28:09,333 INFO sqlalchemy.engine.Engine INSERT INTO domains (name, owner) VALUES (%(name)s, %(owner)s) RETURNING domains.id\n",
      "2022-08-11 14:28:09,334 INFO sqlalchemy.engine.Engine [generated in 0.00156s] {'name': 'example1.com', 'owner': 'Ed Jones'}\n",
      "2022-08-11 14:28:09,337 INFO sqlalchemy.engine.Engine COMMIT\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy.orm import sessionmaker\n",
    "\n",
    "print(Domain.__table__) # {Table} domains\n",
    "print(Domain.metadata) # MetaData (bind=None)\n",
    "\n",
    "engine = create_engine(\n",
    "    'postgresql://postgres:hackme@localhost', echo=True\n",
    ")\n",
    "\n",
    "#vibo: это уже сессия Alchemy\n",
    "Session = sessionmaker(bind=engine)\n",
    "session = Session()\n",
    "\n",
    "#vibo: создаем объект domain, добавляем его в сессию\n",
    "domain = Domain(name='example1.com', owner='Ed Jones')\n",
    "session.add(domain)\n",
    "#vibo: комитим\n",
    "session.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**В SQLAlchemy 1.4+ добавлена поддержка asyncpg:**\n",
    "- асинхронная только работа с сокетом, но фактически логика внутри работы с данными не меняется\n",
    "- можно асинхронно работать как в Core так и в ORM режимах\n",
    "- провязка реализована с помощью greenlet (аналог coroutine)\n",
    "- накладные расходы порядка 15%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **=== М И Г Р А Ц И И ===**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- некоторый код, который меняет структуру базы данных, а иногда и сами данные\n",
    "- код, который откатывает изменения обратно\n",
    "- процесс, при котором применяется код, меняющий базу данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Какими свойствами должны обладать миграции:**\n",
    "- атомарность - миграция (или группа миграций) должна быть применена либо полностью, либо никак\n",
    "- обратимость - миграции должны содержать код, который позволит вернуться к предыдущему состоянию\n",
    "- упорядоченнотсь - должно быть понятно, в каком порядке нужно накатывать миграции, какую катить следующей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Alembic** (стек Alchemy):\n",
    "- построен поверх SQLAlchemy\n",
    "- умеет генерировать код миграций, используя объект MetaData\n",
    "- позволяет писатьочень сложную бизнесс-логику без каких-либо ограничений\n",
    "- имеет два режима: online (можно выполнять запросы) и offline (генерирует SQL, который можно выполнить позже)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install alembic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Как начать использовать alembic**\n",
    "- $ alembic init alembic\n",
    "- после инициализации будут созданы:\n",
    "- alembic/env.py\n",
    "- alembic/script.py.mako\n",
    "- alembic/versions\n",
    "- alembic.ini"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**script.py.mako - шаблон для миграций**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как выглядит этот файл. Есть некий шаблон по которому будут осуществляться миграции. Шаблон состоит из идентификаторов. up_revision - индентификатор миграции, down_revision - индентификатор предыдущей миграции. И есть два метода, когда мы хотим накатить миграцию или откатить миграцию. Важн отметить, т.к. Alembic генерирует нам миграции, то в таблицах мы не указываем, как должны называться все индексы, разные ключи и т.д. Хорошим тоном считаетс указать, как Alchemy собирается это делать. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''$(massege)\n",
    "Revision ID: ${up_revision}\n",
    "Revises: ${down_revision | comma,n}\n",
    "Create Date: ${create_date}\n",
    "'''\n",
    "from alembic import op\n",
    "import sqlalchemy as sa\n",
    "${imports if importe else \"\"}\n",
    "\n",
    "# revision identifiers, used by Alembic.\n",
    "revision = ${repr(up_revision)}\n",
    "down_revision = ${repr(down_revision)}\n",
    "branch_labels = ${repr(branch_labels)}\n",
    "depends_on = ${repr(depends_on)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Naming conventions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "convention = {\n",
    "    'all_colunm_names': lambda constraint, table: '_'.json([\n",
    "        column.name for column in constraint.columns.values()\n",
    "    ]),\n",
    "    'ix': 'ix__%(all_column_names)s',\n",
    "    'uq': 'uq__%(table_name)s__%(all_column_names)s',\n",
    "    'ck': 'ck__%(table_name)s__%(constraint_name)s',\n",
    "    'fk': (\n",
    "        'fk__%(table_name)s__',\n",
    "        '%(all_column_names)s__',\n",
    "        '%(referred_table_name)s'\n",
    "    ),\n",
    "    'pk': 'pk__%(table_name)s'\n",
    "}\n",
    "\n",
    "metadata = MetaData(naming_convention=convention)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Полученную metadate мы передаем в declarative base, от которого мы наследуемся"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Базовый класс для моделей**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@as_declarative(metadata=metadata)\n",
    "class Base:\n",
    "    @declared_attr\n",
    "    def created_at(cls):\n",
    "        return Column(DateTime(timezone=True),\n",
    "                     server_default=text('clock_timestamp()'),\n",
    "                     nullable=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Подключение alembic в проект**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "в файле alembic/env.py необходимо подключить объект MetaData, который содержит всю информацию о нашей схеме"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add your model's MetaDate object here\n",
    "# for 'autogenerate' support\n",
    "# from myapp import mymodel\n",
    "# target_metadata = mymodel.Base.metadata\n",
    "target_metadata = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Генерация миграций**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!alembic revision --massage=\"Initial\" --autogenerate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- получает существующую схему базы данных\n",
    "- сравнивает с содержимым объекта MetaData\n",
    "- генерирует новый файл DDL, котроый приводит базу в одинаковое состояние с объектом MetaData используя шаблон script.py.mako"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Миграция**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Initial\n",
    "\n",
    "Revision ID: 7ca4000d1b18\n",
    "Revises: \n",
    "Create DAte: 2019-10-04 15:39:47.168093\n",
    "\n",
    "\"\"\"\n",
    "from alembic import op\n",
    "import sqlalchemy as sa\n",
    "\n",
    "#revision identifiers, used by Alembic.\n",
    "revision = '7ca4000d1b18'\n",
    "down_revision = None\n",
    "branch_labels = None\n",
    "depends_on = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upgrade():\n",
    "    # ### commands auto generated by Alembic - please adjust! ###\n",
    "    op.create_table(\n",
    "        'domains',\n",
    "        sa.Column('id', sa.Integer(), nullable=False),\n",
    "        sa.Column('name', sa.String(), nullable=False),\n",
    "        sa.Column('owner', sa.String(), nullable=False),\n",
    "        sa.Column('created_at', sa.DateTime(timezone=True),\n",
    "                  server_default=sa.text('clock_timestamp()'),\n",
    "                  nullable=False),\n",
    "        sa.PrimaryKeyConstraint('id', name=op.f('pk__domains')),\n",
    "        sa.UniqueConstrain('name', name=op.f('uq__domains_name'))\n",
    "    )\n",
    "    # ### end Alembic commands ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downgrade():\n",
    "    # ### commands auto generated by Alembic - please adjust! ###\n",
    "    op.drop_table('domains')\n",
    "    # ### end Alembic commands ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Применение миграций**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для применения миграций необходимо выполнить команду upgrade head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!alembic upgrade head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Готово, работы минимум. Вы описали модели, позвали команду генерации миграций, прокатили."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Как и когда применять миграции**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- если приложение on-premises или доступ к нему ограничен - можно и нужно накатывать миграции автоматически, например при запуске приложения\n",
    "- если в вас важный сервис, доступ к которому есть - накатывание миграций вручную дает больший контроль и позволяет оперативно реагировать на проблемы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Как быть с необратимми изменениями - НЕ ДЕАЛАЙТЕ ЭТО СРАЗУ!!!**\n",
    "- если вам большене нужна большая таблица или столбец, и вы хотите их удалить без возможности восстановить данные - не стоит их удалять сразу\n",
    "- убрать все обращения к ресурсам в коде как будто их не существует\n",
    "- столбцы/таблицы/типы данных стоит пометить специальным декторатором, который будет сообщать о доступе к ресурсам, которые должны быть удалены\n",
    "- создать задачу в бэког на последующее удаление"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Batch operations (еще одна функциональность у Alimpic)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SQLite поддерживает ограниченное подмножество ALTER TABLE\n",
    "- переименовать таблицу\n",
    "- переименовать существующий столбец\n",
    "- добавить столбец\n",
    "\n",
    "Alembic предоставляет batch-режим, который:\n",
    "- создает новую таблицу на основе писания миграци, используя временное имя\n",
    "- копирует данные в новую таблицу из существующей\n",
    "- существующая таблица удаляется\n",
    "- новая таблица переименовывается в существующее имя таблицы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**О чем стоит помнить**\n",
    "- менять данные на стороне Python - медленно. Лучше писать запросы, которые Alembic может выполнтиь полностью на стороне Postgres\n",
    "- если требуемые операции реализовать на стороне Postgres невозможно - используйте пагинацию\n",
    "- добавление поля в postgres без значения по умолчанию - очень быстро. С умолчанием - очень медленно. Добавление столбца без умолчания + добавление умолчания работает в итоге быстрее\n",
    "- создание индексов на таблицах и в режиме CONCURRENTLY может помочь избежать блокировок"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Зачем тестировать миграции**\n",
    "- применение миграции в production всегда сопряжено с риском\n",
    "- базы данных разработки и тестирования, как правило, меньше и чище. Данные в них лучше понимаются или, если все остальное не удается, объем данных достаточно мал для обработки человеком\n",
    "- Production базы данных обычно огромны, стары и полны сюрпризов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Из-за чего могут возникнуть проблемы**\n",
    "- поврежденные данные, которые были написаны старыми версиями программного обеспечения и не очищены должным образом\n",
    "- подразумеваемые зависимости в данных, о которых больше никто не знает\n",
    "- люди непосредственно меняют базу данных без испоьзования назначенных инструментов\n",
    "- ошибки в инструментах миграции схем\n",
    "- ошибки в предположениях о том, как следует переностить данные"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Что мы можем проверить**\n",
    "- запускается ли миграция в целом, нет ли опечаток\n",
    "- не забыт ли downgrade\n",
    "- не забыл ли разработчик удалить все типы данных, которые SQLAlchemy создает автоматически\n",
    "- если во время миграции изменяются данные - то корректно ли они изменяются и правильно ли откатываются обратно\n",
    "- соответствуют ли миграции (текущее состояние базы) описанным моделям"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Как тестировать - Stairway тест** (лесенка)\n",
    "- простой, но эффективный метод проверить - полностью ли миграция откатила изменения. Можно добавить в проект 1 раз и забыть\n",
    "- тест получает список всех миграций, и итерируетс по ним. Дял каждой он вызывает upgrade, downgrade и еще раз upgrade."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Тестирование миграций, изменяющих данные**\n",
    "- если в миграции не просто добавляется новый столбец или таблица, а каким-либо образом меняются существующие данные - то ошибка может иметь самые серьезные последствия\n",
    "- обычно такие миграции кажутся чем-то простым, но по оптыту именно в них бывает очень много багов, которые очень сложно обнаружить\n",
    "- дорогой в разработке, но очень надежный"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Как тестировать миграции, меняющие данные**\n",
    "- применяются все миграции до тестируемой (не включительно)\n",
    "- создается набор данных, который будет изменен тестируемой миграцией\n",
    "- выполняется upgrade и проверяется, что все данные корреткно изменены\n",
    "- выполняется downgrade до предыдущей миграции, проверяется, что все изменения были корректно отменены"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Тест на соответствие моделей миграцияи**\n",
    "- позволяет проверить, не забыл ли разработчик меняя что-то в моделях или миграциях поменять во втором месте\n",
    "- тест прогоняет все миграции, получает состояние базы данных с помощью MetaData reflection и ищет отличия (тем же механизмом, которым alembic генерирует миграции)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Пара советов по тестированию**\n",
    "- базу данных лучше создавать отдельную на каждый тест - это позволит запускать много тестов параллельно и все тесты будут максимально изолированы друг от друга\n",
    "- лучше не создавать/удалять базу данных вручную - модуль sqlalchemy_utils справится с этим лучше\n",
    "- пишите простые понятные фикстуры"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **=== СОЕДИНЕНИЯ В PostgreSQL ===**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Напишем простое приложение**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Приложение будет создавать соединение с Postgres, отправлять запросы и получать данные. Т.к. Python3 позволяет писать асинхронные приложения будем использовать **aiohttp** и **aiopg**. Для каждого соединения в Postgres создается отдельный процесс. Процесс польностью изолирован и в случае падения другие клиенты будут работать не заметив никаких проблем."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Простое приложение: скелет**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vibo: создаем init\n",
    "async def init(app):\n",
    "    #vibo: создаем соединение и приложение хапускается\n",
    "    app['conn'] = ... # app['conn'] = ... и request.app['conn'] один и тот же объект\n",
    "    yield\n",
    "\n",
    "async def get_data(conn):\n",
    "    ...\n",
    "\n",
    "async def handle(request):\n",
    "    #vibo: когда приходит запрос - вызываем метод get_data\n",
    "    result = await get_data(request.app['conn']) # app['conn'] = ... и request.app['conn'] один и тот же объект\n",
    "    #vibo: возвращаем ответ клиенту\n",
    "    return aiohttp.web.json_response(result)\n",
    "\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "\n",
    "#vibo: создаем объект Application\n",
    "app = aiohttp.web.Application()\n",
    "#vibo: добавляем ему route на корень\n",
    "#vibo: если человек будет обращаться к этому корню - \n",
    "#vibo: будет вызываться функция handle\n",
    "app.router.add_route('GET', '/', handle)\n",
    "#vibo: добавляем приложению в cleaanup контекст функцию init\n",
    "#vibo: это значит, что когда приложение будет запускаться оно выполнит все в init до yield,\n",
    "#vibo: а когда приложение будет останавливаться оно выполнит оставшуюся часть\n",
    "app.cleanup_ctx.append(init)\n",
    "#vibo: после этого запускаем приложение на 8081-порту\n",
    "aiohttp.web.run_app(app, port=8081)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Простое приложение: реализация**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting aiopg\n",
      "  Downloading aiopg-1.3.4-py3-none-any.whl (34 kB)\n",
      "Collecting async-timeout<5.0,>=3.0\n",
      "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
      "Requirement already satisfied: psycopg2-binary>=2.8.4 in ./venv-vsc/lib/python3.9/site-packages (from aiopg) (2.9.3)\n",
      "Installing collected packages: async-timeout, aiopg\n",
      "Successfully installed aiopg-1.3.4 async-timeout-4.0.2\n"
     ]
    }
   ],
   "source": [
    "!pip install aiopg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting aiohttp\n",
      "  Downloading aiohttp-3.8.1-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m0m\n",
      "\u001b[?25hRequirement already satisfied: charset-normalizer<3.0,>=2.0 in ./venv-vsc/lib/python3.9/site-packages (from aiohttp) (2.1.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in ./venv-vsc/lib/python3.9/site-packages (from aiohttp) (4.0.2)\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Downloading multidict-6.0.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.2/114.2 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting aiosignal>=1.1.2\n",
      "  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
      "Collecting frozenlist>=1.1.1\n",
      "  Downloading frozenlist-1.3.1-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (158 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.8/158.8 kB\u001b[0m \u001b[31m318.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in ./venv-vsc/lib/python3.9/site-packages (from aiohttp) (22.1.0)\n",
      "Collecting yarl<2.0,>=1.0\n",
      "  Downloading yarl-1.8.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (264 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m264.6/264.6 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: idna>=2.0 in ./venv-vsc/lib/python3.9/site-packages (from yarl<2.0,>=1.0->aiohttp) (3.3)\n",
      "Installing collected packages: multidict, frozenlist, yarl, aiosignal, aiohttp\n",
      "Successfully installed aiohttp-3.8.1 aiosignal-1.2.0 frozenlist-1.3.1 multidict-6.0.2 yarl-1.8.1\n"
     ]
    }
   ],
   "source": [
    "!pip install aiohttp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vibo: используем асинхронный контекстный менеджер\n",
    "\n",
    "import aiopg\n",
    "import psycopg2.extras\n",
    "\n",
    "#vibo: подключаемся к Postgres\n",
    "async def init(app):\n",
    "    async with aiopg.connect(\n",
    "        #vibo: предварительно надо создать бд\n",
    "        'postgresql://postgres:hackme@localhost/mydb'\n",
    "    ) as conn:\n",
    "        #vibo: сохраняем соединение в объект приложения\n",
    "        #vibo: запускается риложение, как-то обслуживаются клиенты\n",
    "        app['conn'] = conn\n",
    "        yield\n",
    "        #vibo: выходим из yield\n",
    "    #vibo: выходим из блока aiopg.connect, соединение разрывается\n",
    "\n",
    "#vibo: реализация функции get_data\n",
    "async def get_data(conn):\n",
    "    #vibo: берем курсор соединения\n",
    "    #vibo: курсор - это специальный объект, который в питоне предназначен для соединения и обработки данных\n",
    "    #vibo: указываем aiopg, что берем не простой курсор, а реализующий dict\n",
    "    async with conn.cursor(\n",
    "        cursor_factory=psycopg2.extras.RealDictCursor\n",
    "    ) as cur:\n",
    "        #vibo: выполняем запрос range от 0 до 1000\n",
    "        await cur.execute(\"SELECT generate_series(0, 1000) as id\")\n",
    "        return await cur.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG:asyncio:Using selector: EpollSelector\n",
      "======== Running on http://0.0.0.0:8081 ========\n",
      "(Press CTRL+C to quit)\n",
      "ERROR:aiohttp.server:Error handling request\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/vibo/vs_code/venv-vsc/lib/python3.9/site-packages/aiohttp/web_protocol.py\", line 435, in _handle_request\n",
      "    resp = await request_handler(request)\n",
      "  File \"/home/vibo/vs_code/venv-vsc/lib/python3.9/site-packages/aiohttp/web_app.py\", line 504, in _handle\n",
      "    resp = await handler(request)\n",
      "  File \"/home/vibo/vs_code/example1.py\", line 24, in handle\n",
      "    result = await get_data(request.app['conn'])\n",
      "  File \"/home/vibo/vs_code/example1.py\", line 20, in get_data\n",
      "    await cur.execute(\"SELECT generate_series(0, 1000) as id\")\n",
      "  File \"/home/vibo/vs_code/venv-vsc/lib/python3.9/site-packages/aiopg/connection.py\", line 416, in execute\n",
      "    waiter = self._conn._create_waiter(\"cursor.execute\")\n",
      "  File \"/home/vibo/vs_code/venv-vsc/lib/python3.9/site-packages/aiopg/connection.py\", line 867, in _create_waiter\n",
      "    raise RuntimeError(\n",
      "RuntimeError: cursor.execute() called while another coroutine is already waiting for incoming data\n",
      "INFO:aiohttp.access:127.0.0.1 [11/Aug/2022:17:48:19 +0000] \"GET / HTTP/1.1\" 500 244 \"-\" \"Python/3.9 aiohttp/3.8.1\"\n",
      "INFO:aiohttp.access:::1 [11/Aug/2022:17:48:19 +0000] \"GET / HTTP/1.1\" 200 13064 \"-\" \"Python/3.9 aiohttp/3.8.1\"\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!python example1.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Через Htop видим отдельный честный процесс Postgre...mybd "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Проверим, что приложение работает**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import aiohttp\n",
    "\n",
    "async def request(session):\n",
    "    async with session.get('http://localhost:8081') as resp:\n",
    "        return await resp.json()\n",
    "\n",
    "async def main():\n",
    "    async with aiohttp.ClientSession(raise_for_status=True) as session:\n",
    "        return await request(session)\n",
    "\n",
    "print(asyncio.run(main()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'id': 0}, {'id': 1}, {'id': 2}, {'id': 3}, {'id': 4}, {'id': 5}, {'id': 6}, {'id': 7}, {'id': 8}, {'id': 9}, {'id': 10}, {'id': 11}, {'id': 12}, {'id': 13}, {'id': 14}, {'id': 15}, {'id': 16}, {'id': 17}, {'id': 18}, {'id': 19}, {'id': 20}, {'id': 21}, {'id': 22}, {'id': 23}, {'id': 24}, {'id': 25}, {'id': 26}, {'id': 27}, {'id': 28}, {'id': 29}, {'id': 30}, {'id': 31}, {'id': 32}, {'id': 33}, {'id': 34}, {'id': 35}, {'id': 36}, {'id': 37}, {'id': 38}, {'id': 39}, {'id': 40}, {'id': 41}, {'id': 42}, {'id': 43}, {'id': 44}, {'id': 45}, {'id': 46}, {'id': 47}, {'id': 48}, {'id': 49}, {'id': 50}, {'id': 51}, {'id': 52}, {'id': 53}, {'id': 54}, {'id': 55}, {'id': 56}, {'id': 57}, {'id': 58}, {'id': 59}, {'id': 60}, {'id': 61}, {'id': 62}, {'id': 63}, {'id': 64}, {'id': 65}, {'id': 66}, {'id': 67}, {'id': 68}, {'id': 69}, {'id': 70}, {'id': 71}, {'id': 72}, {'id': 73}, {'id': 74}, {'id': 75}, {'id': 76}, {'id': 77}, {'id': 78}, {'id': 79}, {'id': 80}, {'id': 81}, {'id': 82}, {'id': 83}, {'id': 84}, {'id': 85}, {'id': 86}, {'id': 87}, {'id': 88}, {'id': 89}, {'id': 90}, {'id': 91}, {'id': 92}, {'id': 93}, {'id': 94}, {'id': 95}, {'id': 96}, {'id': 97}, {'id': 98}, {'id': 99}, {'id': 100}, {'id': 101}, {'id': 102}, {'id': 103}, {'id': 104}, {'id': 105}, {'id': 106}, {'id': 107}, {'id': 108}, {'id': 109}, {'id': 110}, {'id': 111}, {'id': 112}, {'id': 113}, {'id': 114}, {'id': 115}, {'id': 116}, {'id': 117}, {'id': 118}, {'id': 119}, {'id': 120}, {'id': 121}, {'id': 122}, {'id': 123}, {'id': 124}, {'id': 125}, {'id': 126}, {'id': 127}, {'id': 128}, {'id': 129}, {'id': 130}, {'id': 131}, {'id': 132}, {'id': 133}, {'id': 134}, {'id': 135}, {'id': 136}, {'id': 137}, {'id': 138}, {'id': 139}, {'id': 140}, {'id': 141}, {'id': 142}, {'id': 143}, {'id': 144}, {'id': 145}, {'id': 146}, {'id': 147}, {'id': 148}, {'id': 149}, {'id': 150}, {'id': 151}, {'id': 152}, {'id': 153}, {'id': 154}, {'id': 155}, {'id': 156}, {'id': 157}, {'id': 158}, {'id': 159}, {'id': 160}, {'id': 161}, {'id': 162}, {'id': 163}, {'id': 164}, {'id': 165}, {'id': 166}, {'id': 167}, {'id': 168}, {'id': 169}, {'id': 170}, {'id': 171}, {'id': 172}, {'id': 173}, {'id': 174}, {'id': 175}, {'id': 176}, {'id': 177}, {'id': 178}, {'id': 179}, {'id': 180}, {'id': 181}, {'id': 182}, {'id': 183}, {'id': 184}, {'id': 185}, {'id': 186}, {'id': 187}, {'id': 188}, {'id': 189}, {'id': 190}, {'id': 191}, {'id': 192}, {'id': 193}, {'id': 194}, {'id': 195}, {'id': 196}, {'id': 197}, {'id': 198}, {'id': 199}, {'id': 200}, {'id': 201}, {'id': 202}, {'id': 203}, {'id': 204}, {'id': 205}, {'id': 206}, {'id': 207}, {'id': 208}, {'id': 209}, {'id': 210}, {'id': 211}, {'id': 212}, {'id': 213}, {'id': 214}, {'id': 215}, {'id': 216}, {'id': 217}, {'id': 218}, {'id': 219}, {'id': 220}, {'id': 221}, {'id': 222}, {'id': 223}, {'id': 224}, {'id': 225}, {'id': 226}, {'id': 227}, {'id': 228}, {'id': 229}, {'id': 230}, {'id': 231}, {'id': 232}, {'id': 233}, {'id': 234}, {'id': 235}, {'id': 236}, {'id': 237}, {'id': 238}, {'id': 239}, {'id': 240}, {'id': 241}, {'id': 242}, {'id': 243}, {'id': 244}, {'id': 245}, {'id': 246}, {'id': 247}, {'id': 248}, {'id': 249}, {'id': 250}, {'id': 251}, {'id': 252}, {'id': 253}, {'id': 254}, {'id': 255}, {'id': 256}, {'id': 257}, {'id': 258}, {'id': 259}, {'id': 260}, {'id': 261}, {'id': 262}, {'id': 263}, {'id': 264}, {'id': 265}, {'id': 266}, {'id': 267}, {'id': 268}, {'id': 269}, {'id': 270}, {'id': 271}, {'id': 272}, {'id': 273}, {'id': 274}, {'id': 275}, {'id': 276}, {'id': 277}, {'id': 278}, {'id': 279}, {'id': 280}, {'id': 281}, {'id': 282}, {'id': 283}, {'id': 284}, {'id': 285}, {'id': 286}, {'id': 287}, {'id': 288}, {'id': 289}, {'id': 290}, {'id': 291}, {'id': 292}, {'id': 293}, {'id': 294}, {'id': 295}, {'id': 296}, {'id': 297}, {'id': 298}, {'id': 299}, {'id': 300}, {'id': 301}, {'id': 302}, {'id': 303}, {'id': 304}, {'id': 305}, {'id': 306}, {'id': 307}, {'id': 308}, {'id': 309}, {'id': 310}, {'id': 311}, {'id': 312}, {'id': 313}, {'id': 314}, {'id': 315}, {'id': 316}, {'id': 317}, {'id': 318}, {'id': 319}, {'id': 320}, {'id': 321}, {'id': 322}, {'id': 323}, {'id': 324}, {'id': 325}, {'id': 326}, {'id': 327}, {'id': 328}, {'id': 329}, {'id': 330}, {'id': 331}, {'id': 332}, {'id': 333}, {'id': 334}, {'id': 335}, {'id': 336}, {'id': 337}, {'id': 338}, {'id': 339}, {'id': 340}, {'id': 341}, {'id': 342}, {'id': 343}, {'id': 344}, {'id': 345}, {'id': 346}, {'id': 347}, {'id': 348}, {'id': 349}, {'id': 350}, {'id': 351}, {'id': 352}, {'id': 353}, {'id': 354}, {'id': 355}, {'id': 356}, {'id': 357}, {'id': 358}, {'id': 359}, {'id': 360}, {'id': 361}, {'id': 362}, {'id': 363}, {'id': 364}, {'id': 365}, {'id': 366}, {'id': 367}, {'id': 368}, {'id': 369}, {'id': 370}, {'id': 371}, {'id': 372}, {'id': 373}, {'id': 374}, {'id': 375}, {'id': 376}, {'id': 377}, {'id': 378}, {'id': 379}, {'id': 380}, {'id': 381}, {'id': 382}, {'id': 383}, {'id': 384}, {'id': 385}, {'id': 386}, {'id': 387}, {'id': 388}, {'id': 389}, {'id': 390}, {'id': 391}, {'id': 392}, {'id': 393}, {'id': 394}, {'id': 395}, {'id': 396}, {'id': 397}, {'id': 398}, {'id': 399}, {'id': 400}, {'id': 401}, {'id': 402}, {'id': 403}, {'id': 404}, {'id': 405}, {'id': 406}, {'id': 407}, {'id': 408}, {'id': 409}, {'id': 410}, {'id': 411}, {'id': 412}, {'id': 413}, {'id': 414}, {'id': 415}, {'id': 416}, {'id': 417}, {'id': 418}, {'id': 419}, {'id': 420}, {'id': 421}, {'id': 422}, {'id': 423}, {'id': 424}, {'id': 425}, {'id': 426}, {'id': 427}, {'id': 428}, {'id': 429}, {'id': 430}, {'id': 431}, {'id': 432}, {'id': 433}, {'id': 434}, {'id': 435}, {'id': 436}, {'id': 437}, {'id': 438}, {'id': 439}, {'id': 440}, {'id': 441}, {'id': 442}, {'id': 443}, {'id': 444}, {'id': 445}, {'id': 446}, {'id': 447}, {'id': 448}, {'id': 449}, {'id': 450}, {'id': 451}, {'id': 452}, {'id': 453}, {'id': 454}, {'id': 455}, {'id': 456}, {'id': 457}, {'id': 458}, {'id': 459}, {'id': 460}, {'id': 461}, {'id': 462}, {'id': 463}, {'id': 464}, {'id': 465}, {'id': 466}, {'id': 467}, {'id': 468}, {'id': 469}, {'id': 470}, {'id': 471}, {'id': 472}, {'id': 473}, {'id': 474}, {'id': 475}, {'id': 476}, {'id': 477}, {'id': 478}, {'id': 479}, {'id': 480}, {'id': 481}, {'id': 482}, {'id': 483}, {'id': 484}, {'id': 485}, {'id': 486}, {'id': 487}, {'id': 488}, {'id': 489}, {'id': 490}, {'id': 491}, {'id': 492}, {'id': 493}, {'id': 494}, {'id': 495}, {'id': 496}, {'id': 497}, {'id': 498}, {'id': 499}, {'id': 500}, {'id': 501}, {'id': 502}, {'id': 503}, {'id': 504}, {'id': 505}, {'id': 506}, {'id': 507}, {'id': 508}, {'id': 509}, {'id': 510}, {'id': 511}, {'id': 512}, {'id': 513}, {'id': 514}, {'id': 515}, {'id': 516}, {'id': 517}, {'id': 518}, {'id': 519}, {'id': 520}, {'id': 521}, {'id': 522}, {'id': 523}, {'id': 524}, {'id': 525}, {'id': 526}, {'id': 527}, {'id': 528}, {'id': 529}, {'id': 530}, {'id': 531}, {'id': 532}, {'id': 533}, {'id': 534}, {'id': 535}, {'id': 536}, {'id': 537}, {'id': 538}, {'id': 539}, {'id': 540}, {'id': 541}, {'id': 542}, {'id': 543}, {'id': 544}, {'id': 545}, {'id': 546}, {'id': 547}, {'id': 548}, {'id': 549}, {'id': 550}, {'id': 551}, {'id': 552}, {'id': 553}, {'id': 554}, {'id': 555}, {'id': 556}, {'id': 557}, {'id': 558}, {'id': 559}, {'id': 560}, {'id': 561}, {'id': 562}, {'id': 563}, {'id': 564}, {'id': 565}, {'id': 566}, {'id': 567}, {'id': 568}, {'id': 569}, {'id': 570}, {'id': 571}, {'id': 572}, {'id': 573}, {'id': 574}, {'id': 575}, {'id': 576}, {'id': 577}, {'id': 578}, {'id': 579}, {'id': 580}, {'id': 581}, {'id': 582}, {'id': 583}, {'id': 584}, {'id': 585}, {'id': 586}, {'id': 587}, {'id': 588}, {'id': 589}, {'id': 590}, {'id': 591}, {'id': 592}, {'id': 593}, {'id': 594}, {'id': 595}, {'id': 596}, {'id': 597}, {'id': 598}, {'id': 599}, {'id': 600}, {'id': 601}, {'id': 602}, {'id': 603}, {'id': 604}, {'id': 605}, {'id': 606}, {'id': 607}, {'id': 608}, {'id': 609}, {'id': 610}, {'id': 611}, {'id': 612}, {'id': 613}, {'id': 614}, {'id': 615}, {'id': 616}, {'id': 617}, {'id': 618}, {'id': 619}, {'id': 620}, {'id': 621}, {'id': 622}, {'id': 623}, {'id': 624}, {'id': 625}, {'id': 626}, {'id': 627}, {'id': 628}, {'id': 629}, {'id': 630}, {'id': 631}, {'id': 632}, {'id': 633}, {'id': 634}, {'id': 635}, {'id': 636}, {'id': 637}, {'id': 638}, {'id': 639}, {'id': 640}, {'id': 641}, {'id': 642}, {'id': 643}, {'id': 644}, {'id': 645}, {'id': 646}, {'id': 647}, {'id': 648}, {'id': 649}, {'id': 650}, {'id': 651}, {'id': 652}, {'id': 653}, {'id': 654}, {'id': 655}, {'id': 656}, {'id': 657}, {'id': 658}, {'id': 659}, {'id': 660}, {'id': 661}, {'id': 662}, {'id': 663}, {'id': 664}, {'id': 665}, {'id': 666}, {'id': 667}, {'id': 668}, {'id': 669}, {'id': 670}, {'id': 671}, {'id': 672}, {'id': 673}, {'id': 674}, {'id': 675}, {'id': 676}, {'id': 677}, {'id': 678}, {'id': 679}, {'id': 680}, {'id': 681}, {'id': 682}, {'id': 683}, {'id': 684}, {'id': 685}, {'id': 686}, {'id': 687}, {'id': 688}, {'id': 689}, {'id': 690}, {'id': 691}, {'id': 692}, {'id': 693}, {'id': 694}, {'id': 695}, {'id': 696}, {'id': 697}, {'id': 698}, {'id': 699}, {'id': 700}, {'id': 701}, {'id': 702}, {'id': 703}, {'id': 704}, {'id': 705}, {'id': 706}, {'id': 707}, {'id': 708}, {'id': 709}, {'id': 710}, {'id': 711}, {'id': 712}, {'id': 713}, {'id': 714}, {'id': 715}, {'id': 716}, {'id': 717}, {'id': 718}, {'id': 719}, {'id': 720}, {'id': 721}, {'id': 722}, {'id': 723}, {'id': 724}, {'id': 725}, {'id': 726}, {'id': 727}, {'id': 728}, {'id': 729}, {'id': 730}, {'id': 731}, {'id': 732}, {'id': 733}, {'id': 734}, {'id': 735}, {'id': 736}, {'id': 737}, {'id': 738}, {'id': 739}, {'id': 740}, {'id': 741}, {'id': 742}, {'id': 743}, {'id': 744}, {'id': 745}, {'id': 746}, {'id': 747}, {'id': 748}, {'id': 749}, {'id': 750}, {'id': 751}, {'id': 752}, {'id': 753}, {'id': 754}, {'id': 755}, {'id': 756}, {'id': 757}, {'id': 758}, {'id': 759}, {'id': 760}, {'id': 761}, {'id': 762}, {'id': 763}, {'id': 764}, {'id': 765}, {'id': 766}, {'id': 767}, {'id': 768}, {'id': 769}, {'id': 770}, {'id': 771}, {'id': 772}, {'id': 773}, {'id': 774}, {'id': 775}, {'id': 776}, {'id': 777}, {'id': 778}, {'id': 779}, {'id': 780}, {'id': 781}, {'id': 782}, {'id': 783}, {'id': 784}, {'id': 785}, {'id': 786}, {'id': 787}, {'id': 788}, {'id': 789}, {'id': 790}, {'id': 791}, {'id': 792}, {'id': 793}, {'id': 794}, {'id': 795}, {'id': 796}, {'id': 797}, {'id': 798}, {'id': 799}, {'id': 800}, {'id': 801}, {'id': 802}, {'id': 803}, {'id': 804}, {'id': 805}, {'id': 806}, {'id': 807}, {'id': 808}, {'id': 809}, {'id': 810}, {'id': 811}, {'id': 812}, {'id': 813}, {'id': 814}, {'id': 815}, {'id': 816}, {'id': 817}, {'id': 818}, {'id': 819}, {'id': 820}, {'id': 821}, {'id': 822}, {'id': 823}, {'id': 824}, {'id': 825}, {'id': 826}, {'id': 827}, {'id': 828}, {'id': 829}, {'id': 830}, {'id': 831}, {'id': 832}, {'id': 833}, {'id': 834}, {'id': 835}, {'id': 836}, {'id': 837}, {'id': 838}, {'id': 839}, {'id': 840}, {'id': 841}, {'id': 842}, {'id': 843}, {'id': 844}, {'id': 845}, {'id': 846}, {'id': 847}, {'id': 848}, {'id': 849}, {'id': 850}, {'id': 851}, {'id': 852}, {'id': 853}, {'id': 854}, {'id': 855}, {'id': 856}, {'id': 857}, {'id': 858}, {'id': 859}, {'id': 860}, {'id': 861}, {'id': 862}, {'id': 863}, {'id': 864}, {'id': 865}, {'id': 866}, {'id': 867}, {'id': 868}, {'id': 869}, {'id': 870}, {'id': 871}, {'id': 872}, {'id': 873}, {'id': 874}, {'id': 875}, {'id': 876}, {'id': 877}, {'id': 878}, {'id': 879}, {'id': 880}, {'id': 881}, {'id': 882}, {'id': 883}, {'id': 884}, {'id': 885}, {'id': 886}, {'id': 887}, {'id': 888}, {'id': 889}, {'id': 890}, {'id': 891}, {'id': 892}, {'id': 893}, {'id': 894}, {'id': 895}, {'id': 896}, {'id': 897}, {'id': 898}, {'id': 899}, {'id': 900}, {'id': 901}, {'id': 902}, {'id': 903}, {'id': 904}, {'id': 905}, {'id': 906}, {'id': 907}, {'id': 908}, {'id': 909}, {'id': 910}, {'id': 911}, {'id': 912}, {'id': 913}, {'id': 914}, {'id': 915}, {'id': 916}, {'id': 917}, {'id': 918}, {'id': 919}, {'id': 920}, {'id': 921}, {'id': 922}, {'id': 923}, {'id': 924}, {'id': 925}, {'id': 926}, {'id': 927}, {'id': 928}, {'id': 929}, {'id': 930}, {'id': 931}, {'id': 932}, {'id': 933}, {'id': 934}, {'id': 935}, {'id': 936}, {'id': 937}, {'id': 938}, {'id': 939}, {'id': 940}, {'id': 941}, {'id': 942}, {'id': 943}, {'id': 944}, {'id': 945}, {'id': 946}, {'id': 947}, {'id': 948}, {'id': 949}, {'id': 950}, {'id': 951}, {'id': 952}, {'id': 953}, {'id': 954}, {'id': 955}, {'id': 956}, {'id': 957}, {'id': 958}, {'id': 959}, {'id': 960}, {'id': 961}, {'id': 962}, {'id': 963}, {'id': 964}, {'id': 965}, {'id': 966}, {'id': 967}, {'id': 968}, {'id': 969}, {'id': 970}, {'id': 971}, {'id': 972}, {'id': 973}, {'id': 974}, {'id': 975}, {'id': 976}, {'id': 977}, {'id': 978}, {'id': 979}, {'id': 980}, {'id': 981}, {'id': 982}, {'id': 983}, {'id': 984}, {'id': 985}, {'id': 986}, {'id': 987}, {'id': 988}, {'id': 989}, {'id': 990}, {'id': 991}, {'id': 992}, {'id': 993}, {'id': 994}, {'id': 995}, {'id': 996}, {'id': 997}, {'id': 998}, {'id': 999}, {'id': 1000}]\n"
     ]
    }
   ],
   "source": [
    "!python example2.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Сколько одновременных запросов выдержит приложение?** (ответ - одно, говорили выше, postgres не выполняет параллельные запросы в одном соединении, это защита драйвера). Если поробуем выполнить два одновременных запроса на первый запрос ответ - 200, на второй - 500 (ошибка) - called while another coroutine is already waiting for incoming data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import aiohttp\n",
    "\n",
    "async def request(session):\n",
    "    async with session.get('http://localhost:8081') as resp:\n",
    "        return await resp.json()\n",
    "\n",
    "async def main():\n",
    "    async with aiohttp.ClientSession(raise_for_status=True) as session:\n",
    "        coros = [request(session) for _ in range(2)]\n",
    "        return await asyncio.gather(*coros)\n",
    "\n",
    "print(await main())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RuntimeError: cursor.execute() called while another coroutine is already waiting for incoming data\n",
    "INFO:aiohttp.access:127.0.0.1 [11/Aug/2022:17:48:19 +0000] \"GET / HTTP/1.1\" 500 244 \"-\" \"Python/3.9 aiohttp/3.8.1\"\n",
    "INFO:aiohttp.access:::1 [11/Aug/2022:17:48:19 +0000] \"GET / HTTP/1.1\" 200 13064 \"-\" \"Python/3.9 aiohttp/3.8.1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Подведем итоги:**\n",
    "- это можно починить подключаясь к БД каждый запрос, или если отдельно брать блокировку на соединение в приложении\n",
    "- пока соединение выполняет запрос, другой конкурентно выполнять нельзя (например позвать gather) \n",
    "- RPS(чтение) = Секунда/(время на 1 запрос); при 50ms/запрос - лучшим возможным результатом будет 20 RPS\n",
    "- RPS на запись может быть ниже, в зависимости от требуемых блокировок\n",
    "- вывод - приложению нужно больше соединений!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **RPS(чтение) = Секунда/(время на 1 запрос); при 50ms/запрос - лучшим возможным результатом будет 20 RPS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20.0"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RPS = 1 / (50 * 0.001) #vibo: мили сек\n",
    "RPS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **=== ПУЛЫ СОЕДИНЕНИЙ ===**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Соединения дешевле не закрывать**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Много соединений в приложении. Проблемы?**\n",
    "- открытвать соединения иногда дорого (терминирование SSL, создание нового процесса, и т.д.), но их не обязательно закрывать\n",
    "- максимальное количество подключений к Postgres ограничивается директивой max_connections (по умолчанию 100), а также ограничено физическими ресурсами и др.\n",
    "- на старте приложения скорее всего одного подключения не хватит, нужно при запуске создвать минимальное количество соединений\n",
    "- пики обращений (необходимость иногда обрабатывать больше клиентов, чем есть соединений)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Приложение --> Пул или группа соединений (сообщение, сообщение) --> Postgres (процесс, процесс)\n",
    "Приложение --> Пул или группа соединений (сообщение, сообщение) --> Postgres (процесс, процесс)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Как устроен пул соединений**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vibo: ЭТО ИГРУШЕЧНЫЙ ПУЛ, НЕ ДЛЯ PRODUCTION\n",
    "\n",
    "import asyncio\n",
    "import asyncpg\n",
    "\n",
    "#vibo: класс\n",
    "class Pool:\n",
    "    #vibo: принимает в инит строчку для подключения бд\n",
    "    #vibo: у него есть размер, т.е. количество соединений, которые нужно создать\n",
    "    def __init__(self, dsn, size: int = 10):\n",
    "        self.dsn = dsn\n",
    "        self.size = size\n",
    "        self.started = False\n",
    "        #vibo: самое важно - асинхронная очередь\n",
    "        self.conns = asyncio.Queue()\n",
    "    \n",
    "    #vibo: метод старт, вызываем и делаем сразу все соединения (10 штук)\n",
    "    async def start(self):\n",
    "        #vibo: создаем корутины в цикле\n",
    "        coros = [asyncpg.connect(self.dsn) for _ in range(self.size)]\n",
    "        #vibo: зовем им всем gather\n",
    "        for conn in await asyncio.gather(*coros):\n",
    "            #vibo: кладем все в очередь и говорим, что пул готов к работе\n",
    "            await self.conns.put(conn)\n",
    "        self.stareted = True\n",
    "    \n",
    "    #vibo: пробегаем по всем соединения, забираем информацию и закрываем\n",
    "    async def close(self):\n",
    "        while not self.conns.empty():\n",
    "            conn = self.conns.get_nowait()\n",
    "            await conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как нам из него получить соединение, чтобы еще ни с кем за него не подраться..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Метод acquire**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vibo: это асинхронный контекстный менеджер, т.е. это такой декоратор, который позволяет эту функцию асинхронную сделать \n",
    "#vibo: не асинхронным генератором, а асинхронным контекстным менеджером\n",
    "#vibo: когда будем в него входить - все выполнится до yield, когда выходить - все после yield \n",
    "\n",
    "import asyncio\n",
    "import contextlib\n",
    "\n",
    "class Pool:\n",
    "    ...\n",
    "    @contextlib.asynccontextmanager\n",
    "    async def acquire(self) -> Connection:\n",
    "        #vibo: если пул не был запущен\n",
    "        if not self.started:\n",
    "            #vibo: мы его запускаем\n",
    "            await self.start()\n",
    "        #vibo: получаем из очереди первое освободившееся соединение,\n",
    "        #vibo: если соединения нет - зависаем, пока соединение не появится\n",
    "        conn = await self.conns.get()\n",
    "        try:\n",
    "            yield conn\n",
    "        finally:\n",
    "            #vibo: после того, как операция завершена - возвращаем соединение, чтобы его могла вязть другая корутина\n",
    "            #vibo: соответственно мы можем запускать много корутин, которые будут работать с меньшим количеством соединений,\n",
    "            #vibo: за счет блокировок этой очереди\n",
    "            await self.conns.put(conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Как использовать наш игрушечный пул соединений**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import asyncpg\n",
    "import contextlib\n",
    "\n",
    "async def get_data(pool: Pool):\n",
    "    async with pool.acquire() as conn:\n",
    "        return await conn.fetch(\"SELECT generate_series(0, 1000) as id\")\n",
    "\n",
    "async def request(session):\n",
    "    async with session.get('http://localhost:8081') as resp:\n",
    "        return await resp.json()\n",
    "\n",
    "async def main():\n",
    "    #vibo: говорим, что мы хотим в пул только два соединения\n",
    "    pool = Pool('postgresql://postgres:hackme@localhost', 2)\n",
    "    #vibo: потом говорим, что хотим создать сразу пять корутин в нем для получения данных\n",
    "    coros = [get_data(pool) for _ in range(5)]\n",
    "    # {list: 5} [[<Record id=0>, ...], [...], [...], [...], [...]]\n",
    "    #vibo: зовем gather и получаем все данные - это работает благодаря асинхронной очереди\n",
    "    series = await asyncio.gather(*coros)\n",
    "    await pool.close()\n",
    "\n",
    "#asyncio.run(main())\n",
    "await main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Пулы соединений: подводим итоги**\n",
    "- экономят время на подключение к PostgreSQL (при запросе от клиента обработчик сразу плучает готовое к работе соединение из очереди)\n",
    "- позволяют контролировать количество одновременных подключений, в лучшем случа использует минимальное необходимое количество соединений\n",
    "- сглаживает резкие пики нагрузки\n",
    "- RPS(чтение) = секунда / (время на 1 запрос * количество соединений) при 50 ms/запрос с 10 подклчениями лучшим возможным результатом будет 200 RPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200.0"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#vibo: раньше было 20 RPS на одно соединение, то на 10 будет 200 RPS\n",
    "\n",
    "n = 10 #количество подключений\n",
    "RPS = (1 / (50 * 0.001)) * n #vibo: мили сек\n",
    "RPS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Что происходит при наращивании количества инстансов приложения**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Становится все больше и больше соединений. Мы начинае видеть ошибки PostgreSQL. Пора увеличивать количество подключений (max_connections, по умолчанию 100)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Что происходит  при наращивании количества подключений**\n",
    "- из-за сетевых задержек и времени обработки результатов OLTP запросов (быстрые) приложениями соединения могут простаивать большую чатсь времени (для справкиесть еще OLAP - аналитические запросы, более тяжлые, более долго обрабатываются)\n",
    "- всплески нагрузки требуют создавать пулы соединений с запасом, соединения простаивают\n",
    "- масштабирование PostgreSQL (вертикальное или горизонтальное) с большим % простаивающих соединеий (и, соответсвенно, ресурсов) - дорого\n",
    "- растут расходы на териминирование SSL у PostgreSQL и клиентов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Очень большое количество соединений снижает производительность... уменьшаем количество соединений**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Как лучше утилизировать подключения и сократить простаивающие**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **=== П У Л Е Р Ы ===**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Прокси пулеры:**\n",
    "- PgBouncer (самый популярный)\n",
    "- Odyssey (более продвинутая верся PgBouncer)\n",
    "- Pgpool II\n",
    "- Crunchy-Proxy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PgBouncer: режим работы**\n",
    "- session pooling (режим сессии - это не сессии SQLAlchemy, а сессии с которыми работаем в PostgreSQL)\n",
    "- transaction pooling (режим транзакции)\n",
    "- statement pooling (режим стейтмент)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Зачем нужны балансировщики** - если хотим обновить бд, в балансровщиках можно все сообщения поставить на паузу."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PgBouncer и SSL** - мы поставили PgBouncer после PgBouncera, чтобы ты мог использовать пул пока ты используешь пул (с)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PgBouncer: подведем итоги**\n",
    "- позволяет сократить количество простаиващих подключений (и ресурсов) к PostgreSQL для мелких транзакций/запросов\n",
    "- дает возможность перезагружать/обновлять PostgreSQL без отключения клиентов\n",
    "- может потреблять только 1 ядро, плохо масштабируется (особенно с SSL), именно поэтому нам нужно много PgBouncer\n",
    "- много уровневый каскад с SO_REUSEPORT справляется с SSL лучше, о дороже в поддержке и все рано есть проблемы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Odyssey: пулер соединений от Яндекса**\n",
    "- умеет утилизировать несколько CPU, что важно, когда начинается SSL (не нужно поддерживать каскад PgBouncer)\n",
    "- позволяет указывать индивидуальный режим изоляции на базу и каждого отдельног пользователя (в PgBouncer жесткая конфигурация - режим работы баунсера один для всех пользователей и всех баз)\n",
    "- умеет возвращать понятные ошибки\n",
    "- умеет очень много всего, активно развиваетсч"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **=== Р Е П Л И К А Ц И Я ===**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Как масштабируются реляционные базы данных**\n",
    "- вертикально (берем сервер помощнее)\n",
    "- устанавливаем несколько серверов и реплицируем между ними данные"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Например, два сервера Master и Replica, на Master идут запросы на запись, на Replica идут запросы на чтение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Реплики бывают асинхронные и синхронные:**\n",
    "- ***асинхронная репликация***: возможна небольшая задержка между подтвержением транзакции на ведущем сервере и появлением этих изменений на резервном; позволяет завершать транзакции быстрее, но в случае краха СУБД последние изменения могут быть потеряны; подходит дял OLAP, pg_dump и проч\n",
    "- ***синхронная реаликация***: гарантирует, что подтвержденная сервером транзакция будет защищена, даже если сразу после этого произойдет крах мастера; для коротких транакций основной составляющей общего времени транзакции будет задержка синхронизации \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Как выглядит обычный PostgreSQL кластер в Яндексе (Yandex Cloud)**\n",
    "- мастер (DC1)\n",
    "- синхронная реплика (DC2)\n",
    "- асинхронная реплика (DC3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Можно ли автоматизировать переключение мастера и реплики**\n",
    "- если какой-нибудь из хостов в кластере сломался (особенно масте) - сервис лежит, исправление руками занимает время\n",
    "- когда кластеров больше 10.000, руками их не починишь, нужна автоматика\n",
    "- если в случаее падения одного из хостов кластеров автоматически перестроится (кто-то станет новым мастером, а кто-то синхронной репликой), как приложению понять, кто реплика, а кто матсер?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Как приложению отличить мастер и реплику**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('off',)\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "\n",
    "conn = psycopg2.connect(\n",
    "    \"postgresql://postgres:hackme@localhost\"\n",
    ")\n",
    "with conn.cursor() as cur:\n",
    "    cur.execute(\"SHOW transaction_read_only\")\n",
    "    print(cur.fetchone())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если не read_only ('off') значит мастер"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Что начет libpq и target_sessin)attrs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<connection object at 0x7f50ef2f6e00; dsn: 'user=postgres password=xxx host=localhost target_session_attrs=read-write', closed: 0>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import psycopg2\n",
    "\n",
    "psycopg2.connect(\n",
    "    'postgresql://postgres:hackme@localhost'\n",
    "    \"?target_session_attrs=read-write\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**HASQL - запуск**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from halsql.psycopg3 import PoolManager\n",
    "\n",
    "host = \",\".join([\n",
    "    \"master-host:5432\", \"replica-host-1:5432\", \"replica-host-2:5432\"\n",
    "])\n",
    "multihost_dsn - f\"postgresql://user:password@{hosts}/dbname\"\n",
    "\n",
    "async def create_pool(dsn) -> PoolManager:\n",
    "    pool = PoolManager(multihost_dsn)\n",
    "\n",
    "    # Waiting for 1 master and 1 replica will be avilable\n",
    "    await pool_manager.read(masters_count=1, replicas_count=1)\n",
    "    return pool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**HASQL - получение соединения к мастеру**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def do_writes():\n",
    "    pool = await creat_pool(multihost_dsn)\n",
    "    async with pool.acquire(read_only=False) as connection:\n",
    "        ...\n",
    "\n",
    "async def do_writes():\n",
    "    pool = await creat_pool(multihost_dsn)\n",
    "    async with pool.acquire_master() as connection:\n",
    "        ..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.9 ('venv-vsc': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "43807f5c999ff1bc99c26ab56886fdb0eb1ab623df40ddad9a297a39d65cf47c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
