## Дебаг. Логирование. Профилирование

Первоисточник: [Python - Дебаг - логирование - профилирование - YouTube](https://www.youtube.com/watch?v=0MEMOQVJZ00)

> **ПОЛЕЗНЫЕ КОМАНДЫ:**

**План лекции:**

1. Управление памятью;

2. Управление процессами;

3. Многозадачность;

4. IPC;

5. Файлы;

6. Системные вызовы.

### 1. Управление памятью

#### Операционная система

Операционная система семантически состоит из двух блоков **User spase** и **Kernal space**. Для связи User space и Kernal space используется стандартная библиотека С, самые популярные реализации этой библиотеки - glibc, musl, bionic. Вся система крутится на железе. Ядро представляет нам некую абстракцию, которая позволяет на не думать об рахитектуре процессора и о том как там все устроено. Мы делаем системные вызовы к ядру и это все работает.

<img title="" src="file:///home/vibo/Pictures/GlobalMarkText/2022-08-25-20-34-22-image.png" alt="" data-align="center">

#### Таблица страниц

Физическая память разделена на страницы, такая организация памяти существует со времен появления архитектуры Х86. Память делится на страницы. Часть страниц занята ядром операционной системы, какие-то станицы памяти заняты какими-то процессами, каие-то свободны. Чтобы с этим нам было проце работать у нас есть виртуальная память. Мы размечаем пространство вируальной памяти для доступа к памяти физической. Это устройство представляет собой таблицу страниц и является обычной хэш-таблицей.

<img src="file:///home/vibo/Pictures/GlobalMarkText/2022-08-25-20-35-39-image.png" title="" alt="" data-align="center">

В случае, если мы не можем получить доступ к нужной странице в оперативной памяти у нас наступает ситуация, под названием Page fault. Это не исключительная ситуация, а обычная история. 

#### Page fualt

- minor (легкий) отказ страниц - нужно только добавить запись в таблицу страниц

- major (значительный) отказ страниц - нужно найти свободную страницу и загрузить в нее данные, перед обновлением таблицы страниц

#### sar

Посмотреть статистику страниц по page fault можно с помощью утилиты sar

`sudo apt install sysstat` # установка (на ubuntu)

 `sar -B 1` # вызов

```bash
Linux 5.4.0-124-generic (minikube)     08/25/22     _x86_64_    (2 CPU)

17:47:37     pgpgin/s pgpgout/s   fault/s  majflt/s  pgfree/s pgscank/s pgscand/s pgsteal/s    %vmeff
17:47:38         0.00     43.56      1.98      0.00      8.91      0.00      0.00      0.00      0.00
17:47:39         0.00      0.00      3.00      0.00      0.00      0.00      0.00      0.00      0.00
17:47:40         0.00      0.00      0.00      0.00      0.00      0.00      0.00      0.00      0.00
17:47:41         0.00      0.00      0.00      0.00      0.00      0.00      0.00      0.00      0.00
17:47:42         0.00      0.00      2.00      0.00     12.00      0.00      0.00      0.00      0.00
17:47:43         0.00  44072.00      0.00      0.00     12.00      0.00      0.00      0.00      0.00
17:47:44         0.00   1904.95      0.00      0.00      0.00      0.00      0.00      0.00      0.00
```

Нас интересуют три столбца: 

- fault/s - количество отказов в секунду; 

- majfit/s - количество major (значительный) отказов;

- pgfree/s - количество освобождений памяти.

Исходя из этой статистики можно сделать выводы, например, если очень много раз в секунду освобождается память - возможно мы слишком часто задействуем потоки ввода/вывода.

#### Преимущества виртуальной памяти

Виртуальная память - это таблица. Старший гибабайт виртуальной памяти всегда занят пространством ядра. Это очень удобно, т.к. когда мы переключаемся между процессами мы всегда знаем где находится пространство ядра.

- Защита памяти процесса и ядра от несанкционированного доступа

- Поддержка памяти только для чтения

- Разделение памяти между множеством процессов и ядром

- Выгрузка давно не используемых сраниц на диск (свопинг)

- Поддержка разделяемой между процессами памяти и copy-on-write

#### Сегменты памяти

Простарнство ядра, Случайное смещение, **Стек** - часть памяти в которой храняться все системные вызовы, там же хранятся все агрументы функций, там же хранятся результаты выплнения функций. Далее идет случайное смещение и блок **Memory mapping** - необходим дял быстрой рабтоы с файлами. Если посмотреть на пятять снизу (до этого шли сверху) - там будет **Heap (куча)** - она предназначена для хранения всех наших динамических данных, переменных, которые мы используем в работе. В основании лежат статические переменные и код нашей программы.

#### vmstat

Статистику применения памяти можно получить используя  vmstat.

`vmstat`

```bash
procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu-----
 r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st
 1  0      0 1747124  45808 550376    0    0   143    17   48   80  0  0 99  0  0
```

Нас интересуют столбцы:

- swpd - объем данных, который был перенесен в swap в боевом бэкенде обычно не применяется swap;

- free - колчиество свободной памяти;

- buff - буферизованные данные;

- cash - закешированные данные, которые ожидают действий.

### 2. Управление процессами

- Процесс - это экземпляр запущенной программы.

- Процесс, который запускает другой процесс надывается **родительским,** а созданные - **дочерним**.

- Все запущенные процессы образуют **дерево процессов**.

#### Создание процесса

Есть процесс Parant_id. Чтобы создать дочерний процесс мы используем системный вызов fork(). После этого родительский процесс продолжает существовать, а дочерний процесс возникает и получает свой process_id. Далее внутри дочернего процесса производится какая-то полезная работа, исполяются другие системные вызовы. В это время родительский процесс ожидает. По окончании работы дочернего процесса он возвращает код выхода в родительский процесс.

<img src="file:///home/vibo/Pictures/GlobalMarkText/2022-08-27-09-56-52-image.png" title="" alt="" data-align="center">

Рассмотрим пример создания процесса.

```python
import os

def main():
    print(f'{os.getpid()}: Давайте создадим процесс')

    res = os.fork()

    if res !=0:
        print(f'{os.getpid()}: Новый процесс с pid={res} создан')
    else:
        print(f'{os.getpid()}: Я дочерний процесс')
        print(f'{os.getpid()}: pid родительского процесса (ppid) = '
                f'{os.getppid()}')

    input()

if __name__ == '__main__':
    main()
```

В питоне, все, что связано с системными вызовами лежит в модуле os. Системный вызов fork() находится в модуле os. В зависимости от того в каком процессе он запущен вывод будет разный. Если os.fork() запущен в родительском процессе, то вернется номер дочернего процесса, если он исполняется в дочернем процессе, то os.fork() возвращает ноль. Так в коде можно узнать в каком процессе мы находимся.

`python example1.py`

```bash
343: Давайте создадим процесс
343: Новый процесс с pid=344 создан
344: Я дочерний процесс
344: pid родительского процесса (ppid) = 343
```

#### htop

Дерево процессов удобно смотреть в утилите htop. Находим процесс и нажимаем `F5`. Наш example1.py выполняется в двух процессах - родительском и дочернем.

![](/home/vibo/Pictures/GlobalMarkText/2022-08-28-10-47-54-image.png)

#### Copy-on-write

 Когда процесс порождает второй процесс он полностью разделяет свою виртуальную память со своим предком. И таким образом мы можем не удваивать размер памяти, пользоваться одними и теми же данными, которые уже загружены в опеартивную память.

<img src="file:///home/vibo/Pictures/GlobalMarkText/2022-08-28-11-11-42-image.png" title="" alt="" data-align="center">

Механизм copy-on-write - выделяется дополнительная страница памяти. Туда полностью копируется содержимое исходной страницы.

### 3. Многозадачность

Т.к. процессов много больше, чем ядер операционной системы - нам необходимо выполнять вычисления последовательно. В операционной системе есть планировщик задач, который выделяет каждом процессу квант времени на вычисление.

<img src="file:///home/vibo/Pictures/GlobalMarkText/2022-08-28-11-29-29-image.png" title="" alt="" data-align="center">

Coppletely Fair Scheduler - планировщик задач в Linux.

- Выбор следующего процесса: по истечению кванта времени выбирается процесс, который получил меньше всего процессорного времени на данный момент.

- Размер кванта времени вычисляется на основе nice-value (приоритета) процесса и количества запущенных процессов.

#### vmstst[2]

Статистику использования процессорного времени можно посмотреть с помощью утилиты vmstat

`vmstat`

```bash
procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu-----
 r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st
 1  0      0 1747124  45808 550376    0    0   143    17   48   80  0  0 99  0  0
```

- us - размер очереди процессов;

- sy - время в %, которое процессор работал в режиме user space (испольнял непосредственно наш код);

- id - время в %, которое процессор работал в режиме cernal space (выполнял задачи ядра);

- wa - сколько процессор бездействовал, время в %;

- st - время в %, когда процессы были заблокированы вводом/выводом.

#### Переключение контекста

Сохранение и восстановление состояния:

- Регистры процессора

- Указатель стека

- Счетчик команд

- Виртуальное адресное пространство

Бывает:

- доровольная (voluntary) смена контекста

- принудительная (non-voluntary) смена контекста

#### pidsatat

Количество переключений контекста можно посмотреть с помощью утилиты pidstat

- cswch/s - количество добровольных переключений

- nvcswch/s - количество принудительных переключений

Отсюда можно сделать выводы, если много добровольных переключений - значит мы очень часто блокируем ввод/вывод, возможно стоит перейти на синхронный ввод/вывод. Если много принудительных перекючений контекста - это может говорить о том, что на процессор слишком большая нагрузка, возможн остоит оптимизировать алгоритм.

`pidstat -w -p 1733 1`

```bash
08:47:58      UID       PID   cswch/s nvcswch/s  Command
08:47:59     1000      1733      0.99      0.00  htop
08:48:00     1000      1733      0.00      0.00  htop
08:48:01     1000      1733      1.00      0.00  htop
08:48:02     1000      1733      0.93      0.00  htop
08:48:03     1000      1733      0.00      0.00  htop
08:48:04     1000      1733      1.00      0.00  htop
08:48:05     1000      1733      1.00      1.00  htop
```

### 4. Межпроцессное взаимодействие

#### Сигналы

Как управлять процессами в операционной системе. Для этого в линуксе есть сигналы. Сингналы - механиизм обработки асинхронных событий процессами.

Процесс может настроить обработку сигнала:

- добавить функцию-обработчик

- игнорировать сигнал

- выполнять действие по-умолчанию.

Всего по стандарту POSIX (Portable Operating System Interface) у нас существует 28 различных типов сигналов. Рассмотрим только некоторые из них.

<img title="" src="file:///home/vibo/Pictures/GlobalMarkText/2022-08-28-12-02-25-image.png" alt="" data-align="center">

С помощью модуля signal можем сделать обработчики своих сигналов.

```python
import signal
import time

def on_signt(signo, stack_frame):
    print(f'Поймал сигнал {signo}')

signal.signal(signal.SIGINT, on_signt)

while True:
    time.sleep(1)
```

`python example2.py`

Можем сколько угодно нажимать `ctrl`+`C`, но из процесса мы не выйдем.

```bash
^CПоймал сигнал 2
^CПоймал сигнал 2
^CПоймал сигнал 2
```

`ctrl`+`Z`

```bash
[1]+  Stopped(SIGTSTP)        python example2.py
```

Завершение процесса:

- процесс возвращает exit-code после завершения

- 0 - успешное завершение, остальные - ошибка.

Самый простой пример, если мы попытаемся проситать с помощью утилиты cat несуществующий файл:

`cat /404.txt`

```bash
cat: /404.txt: No such file or directory
```

С помощью переменной $? мы можем получить последний код выхода из процесса, это будет 1, а не ноль, значит что-то пошло не так.

`echo $?`

```
1
```

#### Exit code

Можно использовать любые, за искючением:

- 128+n, где n-онмер сигнала - завершен в результате получения сигнала n

- 127 - команда не найдена

- 126 - нельзя запустить программу

### 5. Файлы

Ключевая идея Linux, а также всех UNIX подобных операционных систем звучит так. В виде файлов представлено все: непосредственно сами файлы, дескрипторы физических устройств, сетевые сокеты. Наша операционная система работает с файлами посредством файловых дескрипторов.

#### Файловые дескрипторы

- ОС хранит список файлов открытых процессом

- каждый открытый файл обозначен числом - файловым дескриптором

- дескрипторы 0б 1б 2 часто зарезирвированы по STDIN, STDOUT и STDERR соответственно.

В модуле os есть набор методов для работы с файлами. Например, open, не возвращает файловый дескриптор. Его можно вызвать с помощью fileno(). Статистику файла можно посмотреть с помощью stat().

```python
import os

def main():
    print(f'PID = {os.getpid()}')
    with open('bar.txt', 'w') as f:
        f.write('Bar')
        print(f'Файловый дескриптор '
                f'{f.fileno()}')
        print(f'Статус файлового дескриптора '
                f'{os.stat(f.fileno())}')
        input()

if __name__ == '__main__':
    main()
```

`python example3.py`

```bash
PID = 15642
Файловый дескриптор 3
Статус файлового дескриптора os.stat_result(st_mode=33188, st_ino=795942,
st_dev=39, st_nlink=1, st_uid=1000, st_gid=1000, st_size=0, 
st_atime=1661679515, st_mtime=1661679515, st_ctime=1661679515)
```

Мы получили process_id, также файловый дескриптор - 3, размер файла, когда был создан, когда был открыт, изменен последний раз, соответственно все, что мы можем посмотреть с помощью операционной системы о нашем файле.

Список файловых дескрипторов можно посмотреть с помощью lsof.

`lsof -p 15642`

```bash
COMMAND  PID    USER   FD   TYPE DEVICE SIZE/OFF  NODE NAME
python  15642 vibo    0u   CHR  136,5      0t0       8 /dev/pts/5
python  15642 vibo    1u   CHR  136,5      0t0       8 /dev/pts/5
python  15642 vibo    2u   CHR  136,5      0t0       8 /dev/pts/5
python  15642 vibo    3w   REG   0,39        0  795942 /home/vibo/vs_code/bar.txt
```

Видим, что первые три дескриптора зарезервированы под stdin, stdout, stderr и дескриптор с индексом 3 связан с нашим bar.txt, который мы открыли.

Буква w рядом с индексом дескриптора обозначает, что он открыт только для записи. А u - обозначает, что файл открыт и для чтения и для записи.

#### lsof

С помощью этой утилиты можно также посмотреть дескрипторы связанные с определенным портом. Если, например, анализируем сетевой трафик, рассмотрм пример. 

Открываем http-сервер на 8000 порту:

`python3 -m http.server 8000 &`

```bash
[1] 16307

Serving HTTP on 0.0.0.0 port 8000 (http://0.0.0.0:8000/) ...    
```

Передаем номер порта и смотрим дескриптор, связанный с этим портом

`lsof -i :8000`

```bash
COMMAND   PID USER   FD   TYPE DEVICE SIZE/OFF NODE NAME
python3 16307 vibo    3u  IPv4 115178      0t0  TCP *:irdmi (LISTEN)
```

### 6. Системные вызовы

- Приложения из user-space не могут обращаться в kernal space

- Системные вызовы - механизм через который процесс может обратиться к ядру для выполнеия операции

- Ядро проверяет полномочия процесса и выполняет действие или отказывает.

#### strace

Генерируется некоторое случайное количество байт. Затем мы их переводим в строковый тип. И записываем их в mypass.txt.

```python
import base64

def main():
        with open('/dev/urandom', 'rb') as urand:
                rand_bytes = urand.read(128)
        with open('/tmp/mypass.txt', 'wb') as mypass:
                mypass.write(base64.a85encode(rand_bytes))

if __name__ == '__main__':
        main()
```

С помощью утилиты strace мы можем запустить код на исполнение. -P передаем фильтр, связанный только с mypass.txt.

`strace -P /tmp/mypass.txt python3 example4.py`

```bash
openat(AT_FDCWD, "/tmp/mypass.txt", O_WRONLY|O_CREAT|O_TRUNC|O_CLOEXEC, 0666) = 3
fstat(3, {st_mode=S_IFREG|0664, st_size=0, ...}) = 0
ioctl(3, TCGETS, 0x7ffe299662c0)        = -1 ENOTTY (Inappropriate ioctl for device)
lseek(3, 0, SEEK_CUR)                   = 0
write(3, "_'5Ktq>ubOi)kr;VL(uZ%s;B\"e\",.P=#"..., 160) = 160
close(3)                                = 0
+++ exited with 0 +++
```

- openat - открывает файловый дескриптор, здесь видим некоторые флаги, напрмер, O_CREAT говорит о том, что файл нужно создать если он не существует. O_TRUNC - говорит о тм, что нужно очистить файл, если он существует

- fstat - некоторые статистические данные

- lseek - выставляет курсор в нулевую позицию

- write - запись в файловый дескриптор

- close - закрытие файлового дескриптора

#### htop[2]

Можно вызывать ltrace, strace, lsof прямо из htop, для жого нужно выделить процесс и нажать соответственно L, s, l соотвтетсвенно.

#### tcpdump

В процессе отладки нам может понадобиться просмотр сетевого трафика.

`pytnon3 -m http.server 8000` # Терминал 1

`tcpdump -n -i lo0 -A port 8000` # Терминал 2

`curl http://127.0.0.1:8000/` # Терминал 3

<img src="file:///home/vibo/Pictures/GlobalMarkText/2022-08-28-14-09-46-image.png" title="" alt="" data-align="center">

Утилита tcpdump вывела следующую информацию:

- 1 - время с точностью до мс, когда произошел вызов

- 2 - адрес клиента с присвоеному ему портом, порт назначается случайным образом, если мы не задали конкретный

- 3 - адрес нашего сервера, который мы запустили в терминале 1.

- 4 - конфигурации сети

- 5 - заголовки запроса к серверу

После этого сервер нам отвечает пакетом ack, который обозначает, что сервер получил запрос и дальше идет пакет с заголовком ответа - 200 ок. После этого клиент отвечает пакетом ack - заголовки получены, после чего сервер отправлеяет html разметку.

<img src="file:///home/vibo/Pictures/GlobalMarkText/2022-08-28-14-14-56-image.png" title="" alt="" data-align="right">

Таким образом можно посмотреть как перемещались пакеты, если один потеряется мы об этом узнаем.

#### wireshark

Также можно использовать графический интерфейс wireshark - анализатор пакетов, который предоставляет большую функциональность и графический интерфейс.

Запускаем wireshark, выбираем loback lo, затем стафим фильтр tcp.port==8000.

`pytnon3 -m http.server 8000` # Терминал 1

`curl http://127.0.0.1:8000/` # Терминал 2

Рузультат выполнения запроса (example.pcapng)

![](/home/vibo/Pictures/GlobalMarkText/2022-08-28-14-23-47-image.png)

## Дебаг в python

#### pdb

Утилита pdb позволяет запускать код пошагово. 

Запустить программу и остановиться на первой строке

`python -m pdb myapp.py`

Чтобы остановиться в каком-то конкретном месте нужно добавить

`breakpoint()`

Ниже простейшая функция, принимающая количестов запрсоов и количество секунд за которое эти запросы приходили и возвращает нам rps. Далее в цикле мы принимаем через input числа с которыми будем работать.

Когда запускаем файл через pdb:

```python
def calculate_rps(requests, seconds):
        return requests / seconds

while True:
        print('Requests:', end='')
        request = float(input())
        print('Seconds:', end='')
        seconds = float(input())
        rps = calculate_rps(request, seconds)
        print(f'{rps} requests per seconds')
```

`python -m pdb example5.py`

```bash
> /home/vibo/vs_code/example5.py(1)<module>()
-> def calculate_rps(requests, seconds):
(Pdb) 
```

##### continue

Останавливаемся сразу на входе в функцию. Для продолжения нужно отправить continue.

`continue`

```bash
> /home/vibo/vs_code/example5.py(1)<module>()
-> def calculate_rps(requests, seconds):
(Pdb) continue
Requests:100
Seconds:10
10.0 requests per seconds
```

Попробуем поделить на ноль:

```bash
Requests:100
Seconds:0
Traceback (most recent call last):
  File "/usr/lib/python3.9/pdb.py", line 1723, in main
    pdb._runscript(mainpyfile)
  File "/usr/lib/python3.9/pdb.py", line 1583, in _runscript
    self.run(statement)
  File "/usr/lib/python3.9/bdb.py", line 580, in run
    exec(cmd, globals, locals)
  File "<string>", line 1, in <module>
  File "/home/vibo/vs_code/example5.py", line 1, in <module>
    def calculate_rps(requests, seconds):
  File "/home/vibo/vs_code/example5.py", line 2, in calculate_rps
    return requests / seconds
ZeroDivisionError: float division by zero
Uncaught exception. Entering post mortem debugging
Running 'cont' or 'step' will restart the program
> /home/vibo/vs_code/example5.py(2)calculate_rps()
-> return requests / seconds
(Pdb) 
```

##### where

Прграмма упала, но pdb осталась в активном состоянии. Можем проанализировать что в коде произошло. Командой where возвращаем весь стек вызовов

`where`

```bash
(Pdb) where
  /usr/lib/python3.9/pdb.py(1723)main()
-> pdb._runscript(mainpyfile)
  /usr/lib/python3.9/pdb.py(1583)_runscript()
-> self.run(statement)
  /usr/lib/python3.9/bdb.py(580)run()
-> exec(cmd, globals, locals)
  <string>(1)<module>()
  /home/vibo/vs_code/example5.py(1)<module>()
-> def calculate_rps(requests, seconds):
> /home/vibo/vs_code/example5.py(2)calculate_rps()
-> return requests / seconds
(Pdb) 
```

Видим, что ошибка произошла в файле example5.py на (2) - строке в функции calculate_rps().

##### list

С помощью команды list можем посмотреть на листинг кода с указанием конкретной строки в которой произошла ошибка

`list`

```bash
(Pdb) list
  1     def calculate_rps(requests, seconds):
  2  ->         return requests / seconds
  3  
  4     while True:
  5             print('Requests:', end='')
  6             request = float(input())
  7             print('Seconds:', end='')
  8             seconds = float(input())
  9             rps = calculate_rps(request, seconds)
 10             print(f'{rps} requests per seconds')
[EOF]
(Pdb) 
```

##### args

Команда args возвращает аргументы функции.

`args`

```bash
(Pdb) args
requests = 100.0
seconds = 0.0
(Pdb) 
```

Еще в pdb можем выполнить произвольный код, если нам это нужно.

`seconds == 0`

```
(Pdb) seconds == 0
True
(Pdb)
```

Добавим в функцию принудительный breakpoint()

```python
def calculate_rps(requests, seconds):
        breakpoint()    # вот эту строку добавили
        return requests / seconds

while True:
        print('Requests:', end='')
        request = float(input())
        print('Seconds:', end='')
        seconds = float(input())
        rps = calculate_rps(request, seconds)
        print(f'{rps} requests per seconds')
```

Теперь даже если мы не будем запускать код примера в режиме pdb, программа войдет в режим отладки, остановится и мы также можем исследовать код, с помощью команды step.

`python -m example6.py`

```bash
Requests:5000
Seconds:25
> /home/vibo/vs_code/example6.py(3)calculate_rps()
-> return requests / seconds
(Pdb) 
```

##### step/next

`step`

```bash
(Pdb) step
--Return--
> /home/vibo/vs_code/example6.py(3)calculate_rps()->200.0
-> return requests / seconds
(Pdb) step
> /home/vibo/vs_code/example6.py(11)<module>()
-> print(f'{rps} requests per seconds')
(Pdb) step
200.0 requests per seconds
> /home/vibo/vs_code/example6.py(6)<module>()
-> print('Requests:', end='')
(Pdb) 
```

step - если мы хотим идти вглубь функции, если на текущем уровне, то next.

```bash
(Pdb) help step
s(tep)
        Execute the current line, stop at the first possible occasion
        (either in a function that is called or in the current
        function).

# Выполнение текущей строки, остановка в первом возможном случае 
# (либо в вызываемой функции, либо в текущей функции).
(Pdb) 
```

```bash
(Pdb) help next
n(ext)
        Continue execution until the next line in the current function
        is reached or it returns.

# Продолжайте выполнение до тех пор, пока не будет достигнута следующая
# строка в текущей функции или она не вернется.
(Pdb) 
```

##### break

С помощью функции break можно установить break по условию:

```bash
(Pdb) break calculate_rps, seconds == 0
Breakpoint 1 at /home/vibo/vs_code/example6.py:1
(Pdb) cont
Requests:100
Seconds:10
> /home/vibo/vs_code/example6.py(3)calculate_rps()
-> return requests / seconds
(Pdb) cont
10.0 requests per seconds
Requests:100
Seconds:0
> /home/vibo/vs_code/example6.py(3)calculate_rps()
-> return requests / seconds
(Pdb) 
```

Во втором случае, при попытке поделить на ноль - остановились перед входом в функцию.

##### Другие полезные команды

- tbreak - тоже, что и break, но удаляется после первой остановки

- pp - prettyprint результата и выражения

- longlist - выводит весь код текущей функции

- return - продолжить выполнение пока текущая функция не вернет управление

- interact - провалиться в REPL с глобальными и локальными переменными из текущего скоупа

- run - перезапуск программы, брейкпоинты сохраняются

- quit - выход из отладчика, завершение программы.

#### PyCharm debugger

Удобно в графическом виде.

#### gdb

Если нужно анализировать ошибку, которая происзодит не в коде питона, а глубже. В этом коде мы обращаемя к некоторому адресу памяти, который не аллоцирован и мы получим segmentation fault.

```python
from ctypes import string_at

class Foo:
        def bar(self):
                string_at(0xDEADBEEF) # Здесь будет Seqfault

if __name__ == '__main__':
        f = Foo()
        f.spam = 42
        f.bar()
```

` python example7.py`

```
Segmentation fault (core dumped)
```

Пробуем подебажить это с помощью pdb. Снова получаем segmentation fault, что неочень информативно.

`python -m pdb example7.py`

```bash
> /home/vibo/vs_code/example7.py(1)<module>()
-> from ctypes import string_at
(Pdb) cont 
Segmentation fault (core dumped)
```

Пробуем gdb - это встроенная утилита линукса (надо установить ).

`gdb python3`

```bash
GNU gdb (GDB) 12.1
Copyright (C) 2022 Free Software Foundation, Inc.
License GPLv3+: GNU GPL version 3 or later <http://gnu.org/licenses/gpl.html>
This is free software: you are free to change and redistribute it.
There is NO WARRANTY, to the extent permitted by law.
Type "show copying" and "show warranty" for details.
This GDB was configured as "x86_64-pc-linux-gnu".
Type "show configuration" for configuration details.
For bug reporting instructions, please see:
<https://www.gnu.org/software/gdb/bugs/>.
Find the GDB manual and other documentation resources online at:
    <http://www.gnu.org/software/gdb/documentation/>.

For help, type "help".
Type "apropos word" to search for commands related to "word"...
Reading symbols from python3...
(No debugging symbols found in python3)
```

##### run

(gdb) `run example7.py`

```bash
Starting program: /usr/bin/python3 example7.py
[Thread debugging using libthread_db enabled]
Using host libthread_db library "/usr/lib/libthread_db.so.1".

Program received signal SIGSEGV, Segmentation fault.
0x00007ffff7b6483c in ?? () from /usr/lib/libc.so.6
```

##### py-list

Можно посмотреть где мы сейчас находимся.

(gdb) `py-list` # не запустилась (на manjaro)

`sudo apt-get install -y python3-dbg` # поставил на виртуальной машине

`gdb python3`

(gdb) `run example7.py`

```bash
Starting program: /usr/bin/python3 example7.py
[Thread debugging using libthread_db enabled]
Using host libthread_db library "/lib/x86_64-linux-gnu/libthread_db.so.1".

Program received signal SIGSEGV, Segmentation fault.
0x00007ffff76acf45 in string_at (
    ptr=0xdeadbeef <error: Cannot access memory at address 0xdeadbeef>, 
    size=-1) at ./Modules/_ctypes/_ctypes.c:5576
5576    ./Modules/_ctypes/_ctypes.c: No such file or directory.
```

(gdb) `py-list` # смотрим, где мы находимся

Видим, что мы внутри функции _string_at, это уже C-Python.

```bash
509    _string_at = PYFUNCTYPE(py_object, c_void_p, c_int)(_string_at_addr)
 510    def string_at(ptr, size=-1):
 511        """string_at(addr[, size]) -> string
 512    
 513        Return the string at addr."""
>514        return _string_at(ptr, size)
 515    
 516    try:
 517        from _ctypes import _wstring_at_addr
 518    except ImportError:
 519        pass
```

##### py-up

(gdb) `py-up` # поднимаемся выше по стеку

```bash
#16 Frame 0x7ffff7735040, for file example7.py, line 5, in bar (self=<Foo(spam=42) at remote 0x7ffff77febb0>)
    string_at(0xDEADBEEF) # Здесь будет Seqfault
```

(gdb) `py-list` # снова вызываем 

```bash
   1    from ctypes import string_at
   2    
   3    class Foo:
   4            def bar(self):
  >5                    string_at(0xDEADBEEF) # Здесь будет Seqfault
   6    
   7    if __name__ == '__main__':
   8            f = Foo()
   9            f.spam = 42
```

Здесь видим, что остановились на строке 5.

##### py-locals

Можно посмотреть перечень локальных переменных.

(gdb) `py-locals`

```bash
  10            f.bar()self = <Foo(spam=42) at remote 0x7ffff77febb0>
```

##### py-print f

Можно вывести значение любой переменной на экран.

(gdb) `py-print f`

```bash
global 'f' = <Foo(spam=42) at remote 0x7ffff77febb0>
```

##### py-bt

И получить полный бэктрейс.

(gdb) `py-bt`

```bash
Traceback (most recent call first):
  File "example7.py", line 5, in bar
    string_at(0xDEADBEEF) # Здесь будет Seqfault
  File "example7.py", line 10, in <module>
    f.bar()
```

## Логирование

Когда пишел программу на локальном компьютере мы можем спокойно посмотреть, потрейсить, посмотреть стандартный вывод, можем увидеть что пошло не так. Все это исчезает при выходе в продакшн.

#### Что писать в лог

- исключения;

- важные события возникающие в бизнесс-процессе;

- все ваши запросы к сервису и их результат;

- ошибки при валидации входящих данных;

- запуск и результаты работы периодических задач;

- статус шагов процесса запуск/остановки сервиса;

- события свзяанные с безопасностью;

- взаиимодействия с другими сервисами и их результаты.

#### Что не писать в лог

- слишком частые и малозначимые события;

- секреты и приватные данные;

- неинформативные записи из которых не понятно что импенно произошло.

Всегда помните, что вам эти логи потом может понадобится читать.

#### Проблемы использования print для логирования

- нельзя задать уровни логирования;

- нет автоматического добавления контекста в лог;

- нет настройки формата логирования;

- нужно вручную форматировать эксепгены;

- по-умолчанию пишет в stdout, лушче писать логи в stderr.

#### Встроенный логгер

```python
import logging
import os
logging.basicConfig(level=logging.INFO)

logging.info(
        'Worker with PID %s has been started',
        os.getpid(),
)
```

`python example8.py`

Видим уровень лога, сам логгер, сообщение.

```bash
INFO:root:Worker with PID 3948 has been started
```

#### Форматирование строк в логгере

logging поддерживает форматирование непосредственно в логгере, это немного экономит вычислительные ресурсы.

```
- log.debug('Worker with PID %s has been started' % os.getpid())
+ log.debug('Worker with PID %s has been started', os.getpid())
```

#### Уровни логов

- DEBUG - неважные события, нужные в процессе разработки (в продакшн рекомендуют отключать);

- INFO - какео-то событие означающее, что программа работает исправно;

- WARNING - ошибка не мешающая работоспособности программы (но неприятная для пользователя, уже нужно пофиксить);

- ERROR - ошибка, которая может привести к деградации работы программы;

- CRITICAL - ошибка которая означает отказ дальнейшей работы программы.

#### Формат логов

Логи можно форматировать. Для этого при конфигурировании логгера мы задаем ему формат. В примере ниже: имя логгера, уровень логирования, время, сообщение. Время также можно задать в определенном формате.

```python
import logging
import os

logging.basicConfig(
        level=logging.INFO,
        format='%(name)s %(levelname)s %(asctime)s      '
                '%(message)s',
        datefmt='%I:%M:%S'
)

log = logging.getLogger()

log.info('Worker with PID %s has been started',
        os.getpid())
```

`python example9.py`

```bash
root INFO 07:12:11      Worker with PID 4223 has been started
```

#### Настройка логгера

Для настройки используются четыре компонента:

- Filters - позволяют гибко настраивать какие логи отправлять;

- Formatters - определяют формат логов на выходе;

- Handlers - отпаравляют залогированные сообщения;

- Loggers - представляют интерфейс, который используется приложением.

##### Filters

Фильтры добавленные в логгер принимают все сообщения логгера и принимают решение отправлять сообщение или отбросить. Когда нам нужно создать фильтр - создаем класс отнаследованныей от logging.Filter и таким образом реализуем метод filter. Соответственно может отфильтровать все запросы, связанные с пингом нашего api.

```python
import logging

class NoPingFilter(logging.Filter):

        def filter(self, record) -> bool:
                return '/api/v1/ping' not in record.getMessage()
```

##### Handlers

- Хэндлеры отвечают за отправку данных (например в: файл, syslog, HTTP, SMTP);

- К логгеру можно добавить несколько хэндлеров и сообщения будут отправляться в каждый из них;

- Формат сообщения в отдельном хэндлере можно установить добавив форматтер через метод setFormatter;

- Уровень сообщений для хэндлера устанавливается при помощи метода setLevel;

- Также можно добавить фильтры на уровне хэндлера при помощи метода addFilter.

```python
from cgitb import handler
import logging

# создаем логгер
log = logging.getLogger()
# задаем ему уровень DEBUG
log.setLevel(logging.DEBUG)

# создаем хендлер, который будет писать логи в файл
handler = logging.FileHandler('myapp.log')
# задаем форматтер: уровень, название, сообщение
handler.setFormatter(logging.Formatter(
        '%(levelname)s:%(name)s         %(message)s'
))
# задаем свой уровень логирования у хэндлера INFO
# будем игнорировать у него уровень DEBUG
handler.setLevel(logging.INFO)

log.addHandler(handler)
log.addHandler(logging.StreamHandler())

# проверим все три вызова
log.debug('Debag message')
log.info('Info message')
log.warning('Warning message')
```

`python example11.py`

```bash
Debag message
Info message
Warning message
```

Заглянем в лог

`cat myapp.log`

```bash
INFO:root         Info message
WARNING:root         Warning message
```

Видим, что лог уровня DEBUG туда не записался.

##### Formatters

C помощью форматтеров мы можем не тоько форматировать вывод, можем сделать json-файлом; елси прийдется анализировать - потом не нужно будет писать нудные регулярки. Можно спокойно будет распарсить через json  и передать какому-то скрипту.

```bash
import os, logging, json

class JSONFormatter(logging.Formatter):
        def format(self, record):
                return json.dumps(
                        {
                                'args': record.args,
                                'file': record.filename,
                                'func': record.funcName,
                                'line': record.lineno,
                                'message': record.getMessage(),
                        },
                        ensure_ascii=False
                )
```

##### Loggers

Это все объединяют логгеры.

```python
import logging

# получаем логгер
log = logging.getLogger(__name__)
# устанавливаем уровень
log.setLevel(logging.INFO)
# добавляем фильтры
log.addFilter(PingFilter())
# добавляем хэндлеры
log.addHandler(logging.StreamHandler())
# используем
log.info('..')
log.debug('..')
```

##### Иерархия логгеров

Один логгер может быть потомком другого логгера. Это бывает полезно, когда один модуль зависит от другого. Так можем  проследить как у нас по иерархии кода произошло логирование. 

```python
from logging import getLogger

# True
print(getLogger('foo') is getLogger('foo'))
```

` python example14.py`

```bash
True
```

```python
import logging

log = logging.getLogger()
print(log.name)
```

`python example15.py`

```bash
root
```

По умолчанию getLogger принимает строку и строка обозначает имя нашего логгера. По умолчанию это root, но мы можем создвать сколько угодно логгеров, иерархия задается через точку.

```python
import logging

root_log = logging.getLogger()
foo_log = logging.getLogger('foo')
foo_bar_log = logging.getLogger('foo.bar')
foo_baz_log = logging.getLogger('foo.baz')
spam_log = logging.getLogger('spam')
```

<img src="file:///home/vibo/Pictures/GlobalMarkText/2022-08-28-20-10-24-image.png" title="" alt="" data-align="center">

В данном случае все наши логгеры дочерние от root. Но если нам нужно, чтобы это было не так можно задать свойство propagate = False. Тогда логгер foo будет прородителем для своих foo.bar, foo.baz, но не будет наследником root.

```python
import logging

root_log = logging.getLogger()
foo_log = logging.getLogger('foo')
foo_log.propagate = False # добавили
foo_bar_log = logging.getLogger('foo.bar')
foo_baz_log = logging.getLogger('foo.baz')
spam_log = logging.getLogger('spam')
```

<img src="file:///home/vibo/Pictures/GlobalMarkText/2022-08-28-20-12-14-image.png" title="" alt="" data-align="center">

#### Логгирование в проде

- единый формат сообщений;

- логирование в json или другом формате структурированных данных;

- набор полей одинаковый для всех микросервисов.

Есть системы сбора логов, например kibana, где все логи сведены в удобном формате.

## Профилирование

- небольшая часть программы может потреблять большую часть ресурсов;

- сложность в том, чтобы найти эти участки кода и оптимизировать их;

- профилировщик собирает статистику о работающей программе;

- остается тоько проанализировать собранные данные, чтобы найти узкие места.

#### Виды профилирования

- трейсинг (детерминированное профилирование) - когда в начало профилируемого кода добавляем таймер и в конце этот таймер останавливаем и смотрим сколько времени код исполнялся; для этого есть утилиты:
  
  - cProfile;
  
  - vmprof.

- сэмплировние по таймеру - когда мы в определенный промежуток времени делаем дамп нашего процесса и смотрим сколько времени наш процесс провел в каждой конкретной функции; соответсвующие утилиты:
  
  - py-spy;
  
  - scalene;
  
  - memory_profiler.

#### Профилирование по CPU

Даны два csv файла:

- users.csv - информация о пользователях (id, name, address, email, birthdate);

- promo-users.csv - ID пользователей по которым нужно выполнить рассылку.

Нам нужно наполнить файл emails.csv списком email адресов из users.csv для тех пользователй, id которых есть в promo-users.csv.

**Файл 1.**

`head -n 2 users.csv`

```bash
id,name,address,email,birthdate
633678,Фомин Конон Харитонович,'ул. Республиканская, д. 72, 854977',
samuil_02@example.org,1985-08-14
```

`wc -1 users.csv`

```bash
1000001 users.csv
```

**Файл 2.**

`head -n 2 promo-users.csv`

```
id
9758
```

`wc -1 promo-users.csv`

```
10001 promo-users.csv
```

Из 1 млиона строк нужно выбрать 10 тысяч. Самая простая реализация будет следующая:

```python
import csv

# функция поиска ids
def get_ids():
    ids = []
    # открываем на чтение promo-users.csv
    with open('promo-users.csv') as f:
        r = csv.reader(f)
        next(r)
        # проходим по всем строкам
        for row in r:
            # записываем в лист
            ids.append(row[0])
    # возвращаем лист ids promo-users
    return ids

# функция возвращает email по ids
def get_emails(ids):
    emails = [] 
    # открываем users.csv
    with open('users.csv') as f:
        r = csv.reafer(f)
        next(r)
        # проходим по всем строкам
        for row in r:
            id_ = row[0]
            # выбираем email по ids
            if id_ in ids:
                emails.append(row[3])
    return emails

def write_emails(emails):
    with open('emails.csv', 'w') as f:
        r = csv.writer(f)
        r.writerow(['email'])
        for email in emails:
            r.writerow([email])

def main():
    ids = get_ids
    emails = get_emails(ids)
    write_emails(emails)

if __name__ == '__main__':
    main()
```

Код неплохой, но выполняться будет 2 минуты, хотелось бы лучше.

Потрейсим спомощью cProfile.

`python -m cProfile example17.py`

##### cProfile

```python
from cProfile import Profile

pr = Profile()
pr.enable()
# здесь профилируемый код
pr.disable()
```

На профилировщик говорит, что из 131 секунды на выполненеие - 130 секунд код провел при выполнении get_emails:

<img src="file:///home/vibo/Pictures/GlobalMarkText/2022-08-28-22-32-27-image.png" title="" alt="" data-align="center">

Проилировщик сам также увеличивает время работы приложения.

##### cProfile + snakeviz

`pytnon -m cProfile -o pick.prof -s tottime pick.py`

`snakeviz pick.prof`

<img src="file:///home/vibo/Pictures/GlobalMarkText/2022-08-28-22-35-28-image.png" title="" alt="" data-align="center">

Получим информацию в более красивом структурированном виде.

##### vmprof

`python3 -m vmprof pick.py`

<img src="file:///home/vibo/Pictures/GlobalMarkText/2022-08-28-22-37-28-image.png" title="" alt="" data-align="center">

Можем спуститься до кода на котором написан python. Рассмотрим функцию listobject. Она берет некоторый список и начинает в цикле по нему проходить.

<img src="file:///home/vibo/Pictures/GlobalMarkText/2022-08-28-22-39-11-image.png" title="" alt="" data-align="center">

Здесь линейная сложность. Если заменить list на set - у set время чтения константа.

<img src="file:///home/vibo/Pictures/GlobalMarkText/2022-08-28-22-42-01-image.png" title="" alt="" data-align="center">

Повторно выполним профилирование. Увидим, что время выполнения упало на два порядка.

`pytnon -m cProfile -s tottime pick.py`

<img src="file:///home/vibo/Pictures/GlobalMarkText/2022-08-28-22-44-00-image.png" title="" alt="" data-align="center">

##### PyCharm profiler

В pycharm есть свой профилилровщик с графическим интерфейсом.

#### Профилирование памяти

##### tracemalloc

В стандартной библиотеке python есть утилита **tracemalloc**, которая позволяет:

- собирать информацию о выделении памяти в процессе работы программы;

- логировать каждый запрос на выделение памяти вместе с стек трйсом;

- сохранять снепшоты памяти в заданные моменты времени;

- сравнивать снепшоты дял поиска утечек памяти.
  
  <img src="file:///home/vibo/Pictures/GlobalMarkText/2022-08-28-22-50-19-image.png" title="" alt="" data-align="center">

<img src="file:///home/vibo/Pictures/GlobalMarkText/2022-08-28-22-50-50-image.png" title="" alt="" data-align="center">

![](/home/vibo/Pictures/GlobalMarkText/2022-08-28-22-51-21-image.png)

##### mprof

Чем больше список emails по которым делаем рассылку - тем больше будет выделяться памяти. Это также можно понаблюдать на графике с помощью утилиты **mprof**.

<img src="file:///home/vibo/Pictures/GlobalMarkText/2022-08-28-22-54-06-image.png" title="" alt="" data-align="center">

Здесь каждая точка на графике представляет собой следующую итеррацию размера списка пользователей. Увлеличиваетс он с каждым шагом примерно на 20 тысяч. Видно, что расход памяти у нас растет линейно. Если убрать list из нашего кода и будем использовать yield.

<img src="file:///home/vibo/Pictures/GlobalMarkText/2022-08-28-22-56-43-image.png" title="" alt="" data-align="center">

Сравним два снепшота памяти - увидим, что расход уменьшился.

<img src="file:///home/vibo/Pictures/GlobalMarkText/2022-08-28-22-57-53-image.png" title="" alt="" data-align="center">

<img src="file:///home/vibo/Pictures/GlobalMarkText/2022-08-28-22-58-15-image.png" title="" alt="" data-align="center">

Можно делить на батчи и грузить батчами.
