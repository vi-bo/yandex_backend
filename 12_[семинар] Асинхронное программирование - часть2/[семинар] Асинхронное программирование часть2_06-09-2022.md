## Асинхронное программирование. Часть 2.

Первоисточник: [Часть 1](https://www.youtube.com/watch?v=rMh5O4eZrug), [Часть 2](https://www.youtube.com/watch?v=rYQk3PW16bE)

**В чем разберемся:**

- Asyncio

- Awaitable объекты

- Высокоуровневые и низкоуровневые API

- Асинхронные интерфейсы

- Aiohttp

- Middlewares

- Payloads

- Retry policy

- Готовые сервисы

- Декораторы

- Contextvars

- Pytest plugin

Код будет приведен на псевдопитоне.

### Asyncio

#### Что такое asyncio?

- Библиотека для написания конкурентных задач в Python 3.4+

- Учитывает опыт Twisted, Tulip, greenlet и прочих (переключали контекст не явно)

- Привнес синтаксис async / await в Python 3.5+

- Прослойка между расширениями, работающими на функциях обратного вызова и async / await

#### Что такое сандарт asyncio?

- Фундамент для асинхронных фреймворков

- Базовые абстракции (Future / Coroutine / Task / AbstractEventLoop)

- Высокоуровневый API
  
  - Сопрограммы (coroutine, generator coroutine), задачи (Task)
  
  - Streams (потоки), примитивы для сихронизации, Queues
  
  - API для работы с процессами и межпроцессного взаимодействия

- Низкоуровневый API
  
  - Loop.*, Asyncio.Future
  
  - Транспорты и протоколы    

### Awaitable объекты

- Это объекты, в которых можно использовать в выражении await

- Использование объекта в выражении await означает, что текущая сопрограмма переключит контекст и будет ожидать, пока выражение не будет выполнено **<u>(т.е. мы доходим до точки await и ждем пока выражение не будет выполнено)</u>**

- Существует 3 встроенных типа Awaitable объектов: Coroutine, Task, Future

Пример:

```python
import asyncio
import time

class Timer:
    def __init__(self, coro):
        self.coro = coro
        self.spent = 0

    def __await__(self):
        started = time.monotonic()
        result = yield from self.coro.__await__()
        self.spent = time.monotonic() - started
        return result

async def main():
    t = Timer(asyncio.sleep(1, 'test'))
    res = await t #vibo: ждем завершение Timer, только после этого возвращаем результат
    print(res) # test
    print(t.spent) # 1.00341845

#vibo: здесь и далее для запуска в jupyter
await main()
```

```python
test
1.0022023540004739
```

Есть класс Timer с внутренними методами init и await. Мы хотим запустить таймер с ожиданием по sleep 1 сек, дождаться и вывести сколько мы потратили времени. Отработав и вычислив у нас получается примерно 1 сек.

#### Что такое сопрограмма?

Методика связи программных модулей друг с другом по принципу кооперативной многозадачности. 

Сопрограмма это некая многозадачность в которой мы параллельно выполняем те или иные процессы. Т.е. когда мы распределяем те или иные задачи в сопрограмме независимо выполняются те или иные дейсивия. Это могут быть какие-то вычисления, это может быть получение каких-то данных, сетевое взаимодейстиве, работа с файлами и т.д. Суть в модели многозадачности.

#### Что такое объект coroutine в Python?

Доходим до определенной точки , ждем пока event-loop выполнит какую-то работу и в итоге мы получаем какой-то результат и точку выхода.

> **ПЕРЕКЛЮЧЕНИЕ КОНТЕКСТА = ПЕРЕДАЧА УПРАВЛЕНИЯ**

- Объект, который имеет ряд инструкций, умеет хранить свое состояние и может переключать контекст (передавать управление)

- Является более обобщенной формой подпрограмм (интерпретатор может входить в подпрограмму в 1 точке и выходить в другой). В сопрограммах может быть несколько точек выхода, выхода и возврата

- ГЕНЕРАТОР, а в Python 3.5+ специальный объект, который ведет себя как генератор

#### Что такое coroutine function?

- функция, возвращающая объект **coroutine**

- определяется ключевыми словами **async def**

- может содержать ключевые слова: **await, async for, async with** 

#### Что такое coroutine?

Когда мы хотим параллельно, независимо заняться каким-то процессом.

##### await

- контекст переключает await

```python
import asyncio

async def actual_coro(): # <class 'function'> - coroutine function
    print('hello')
    await asyncio.sleep(1)
    print('world')

coro = actual_coro() # <class 'coroutine'> - coroutine object
```

**Итого блок функции это <class 'function'> - coroutine function, а объект, который она возвращает <class 'coroutine'> - coroutine object.**

В новой версии возвращаемый объект **coroutine**.

##### yield from

В более старой версии...

- Контекст переключает yield from

- Считаются устаревшими

```python
import asyncio

@asyncio.coroutine
async def old_coro(): # <class 'function'>
    print('hello')
    yield from asyncio.sleep(1)
    print('world')

coro = old_coro() # <class 'generator'> 
```

В старой версии возвращаемый объект **generator**, а не **coroutine**.

#### Как запустить сопрограмму?

##### asyncio.run / await

- `asyncio.run()` - запуск event loop ожидания  окончания работы асинхронной функции, завершение работы event loop и отмена всех порожденных асинхронных задач

- `await` - запуск из асинхронного кода с явным переключением контекста: await

```python
import asyncio

async def get_text():
    return 'hello, world!'

async def say_text():
    text = await get_text() # await - явное переключение с передачей урправления
    await asyncio.sleep(1)
    return(text)

#vibo: для запуска из python
#result = asyncio.run(say_text())
#print(result) # hello, world!

#vibo: здесь и далее для запуска в jupyter
await say_text()
```

```python
'hello, world!'
```

##### asyncio.create_task()

- `asyncio.create_task()` - запуск задачи в фоновом режиме

```python
async def get_text(delay, text):
    await asyncio.sleep(delay)
    return text

async def say_text():
    task1 = asyncio.create_task(get_text(1, 'hello'))
    task2 = asyncio.create_task(get_text(1, 'world'))
    await task1
    await task2
    return ', '.join([task1.result(), task2.result()])

#result = asyncio.run(say_text())
#print(result) # hello, world

#vibo: здесь и далее для запуска в jupyter
await say_text()
```

```python
'hello, world!'
```

#### Что такое asyncio.Task и зачем он нужен?

- представляет из себя сопрограмму, запущенную или запланированную для запуска в цикле событий и контекст

- позволяет запускать задачи в фоновом режиме

- создается с помощью `asyncio.create_task()` или `loop.create_task()`, которые оборачивают сопрограмму в объект **Task** и планируют ее выполнение в цикле событий на ближайшее время

- абстракция, позволяющая отменить-прервать выполнение сопрограммы с помощью `.cancel()`

Рассмотрим пример. Допустим, что мы запускаем какой-то сервер по адресу 127.0.0.1 на порту 8888. Делаем async with сервера и запускаем некий метод serve_forever(). Сам main() как договорились запускаем через asyncio.run(). В хендлере (def handler) получаем рандомное значение курса доллара.

```python
import asyncio
import random

rate = random.randint(1, 99)

async def handle (reader, writer):
    writer.write(f'Dollar rate is {rate}. \n'.encode())
    await writer.drain()
    writer.close()

async def main():
    server = await asyncio.start_server(handle, '127.0.0.1', 8888)
    async with server:
        await server.serve_forever()

asyncio.run(main())
#await main()
```

В целом норм, на что обратить внимание. Например, подключился пользователь,  он захотел получить значение актуального курса. Он его получил, висит на этом соединении и так может висеть весь день. Ему интересно, чтобы за день это значение менялось. А в нашей концепции это значение не меняется. Будем это исправлять. 

Напишем метод update_rate.

Будем создавать таску, обращаясь к нашему методу update_rate. Будем поднимать наш сервер через start_server. И по async with по серверу висеть на бесконечном ожидании, но главная разница в том, что наша глобальная переменная rate будет обновляться кадые 10 сек.

```python
import asyncio
import random

rate = random.randint(1, 99)

async def update_rate():
    global rate
    while True:
        rate = random.randint(1, 99) # обновляем rate каждый 10 сек
        await asyncio.sleep(10)

async def main():
    asyncio.create_task(update_rate())
    server = await asyncio.start_server(handle, '127.0.0.1', 8888)
    async with server:
        await server.serve_forever()

asyncio.run(main())
```

Под random.randint() может быть что угодно - обращение к какой-то базе данных, обращение к веб-ресурсу, это не важно. Конецепция решения проблемы обновления информации в установленном нами коннекте.

#### Что такое asyncio.Future?

##### loop.create_future()

- специализированный низкоуровневый Awaitable объект, представляющий конечный результат выполнения асинхронной операции

- позволяет использовать низкоуровневый код, реализованный на функциях обратного вызова с высокоуровневым кодом на async/await

- создается с помощью `loop.create_future()`

Рассмотрим пример. У нас есть main(), в нем делаем get_running_loop(). Делаем печать текущего времени. Воспользуемся методом my_sleep на 1 секунду, в котором будем делать get_running_loop() и delay от set_result.

```python
import asyncio
import time

async def my_sleep(delay):
    loop = asyncio.get_running_loop()
    future = loop.create_future()
    loop.call_later(delay, future.set_result, True)
    await future

async def main():
    loop = asyncio.get_running_loop()
    print(loop.time()) # 0.9779213
    await my_sleep(1)
    print(loop.time()) # 1.979251479

#vibo: для запуска из python
#asyncio.run(main())
#vibo: для запуска в jupyter
await main()
```

```python
2905.004298577
2906.005998291
```

Текущее время увеличивается на 1 секунду.

### Высокоуровневый API

#### Как приостановить задачу на некоторое время?

- `asyncio.sleep()` - приостанавливает действие текущей задачи на указанное время, позволяя выполнять другие задачи

- если указан параметр **result**, то его значение возвращается вызывающему объекту по завершении работы сопрограммы

```python
import asyncio

async def main():
    print(await asyncio.sleep(1, 'hello'))

#vibo: для запуска из python
#asyncio.run(main())
#vibo: для запуска в jupyter
await main()
```

В ожидании через 1 секунду мы получим результат.

#### Как запустить сразу несколько задач?

- Проверим: с каким id существуют пользователи в определенном сервисе?

Рассматриваем задачу в которой хотим опредлеить какие пользователи и с какими id есть в нашем сервисе. Для примера будем считать, что проверить это можно по некому url с привязаным к нему user_id.

##### def check_user_exists() #1

```python
import aiohttp

async def check_user_exists(user_id: int) -> bool:
    async with aiohttp.ClientSession() as session:
        url = f'https://example.org/users/{user_id}'
        async with session.head(url) as resp:
            print(user_id, resp.status == 200)
            return resp.status == 200
```

Наша функция check_user_exists имеет следующую структуру:

- async with с aiohttp.ClientSession() 
  
  > aiohttp - абстракция для работы на сетевом уровне, для установления соединения, минуя различные системные вызовы

- задаем интересующий нас url

- далее делаем async with по нашему url и получаем какой-то resp

- печатаем user_id и resp.status если он равен 200

- возвращаем True или False

Если попробуем запустить в лоб по циклу с тригером функции check_user_exists, то по сути такая ассинхронная функция будет не сильно отличаться от синхронной. Существенно разницы мы не получим.

```python
import asyncio

async def main():
    for i in range(10):
        await check_user_exists(i)

#vibo: для запуска из python
#asyncio.run(main())
#vibo: для запуска в jupyter
await main()
```

```python
0 False
1 False
2 False
3 False
4 False
5 False
6 False
7 False
8 False
9 False
```

Время выполнения 5.4 секунды. 

##### asyncio.get_running_loop().create_future()

Пробуем сделать лучше. Заведем running_loop через create_future. У нас будет лист тасок executing и мы непосредственно проходим в цикле, создаем таски для проверки под каждого пользователя. Добавляем сallback. Когда executing будет равным нулю значит мы выполнили все таски и можно возвращать результат и печатаем его после await future.

```python
async def main():
    future = asyncio.get_running_loop().create_future()
    tasks = []
    executing = 0

    def cb(task):
        nonlocal executing
        executing -= 1
        if executing == 0:
            future.set_result([task.result() for task in tasks])

    for i in range(10):
        task = asyncio.create_task(check_user_exists(i))
        task.add_done_callback(cb)
        executing += 1
        tasks.append(task)

    await future
    print(future.result())
```

```python
6 False
7 False
0 False
4 False
8 False
2 False
5 False
9 False
3 False
1 False
[False, False, False, False, False, False, False, False, False, False]
```

Время выполнения 0.5 секунды.

Мы асинхронно посоздавали тасок, асинхронно пообращались за результатами. Пока оно выполняется мы счетчик увеличиваем, когда таска завершается (ее выполнение оканчивается) - мы этот счетчик уменьшаем на единицу. В конечном итоге, когда все таски выполнены счетчик становится равным нулю.

##### asyncio.gather(*)

Еще вариант через asyncio.gather:

```python
import asyncio

async def main():
    coros = (
        check_user_exists(i)
        for i in range(10)
    )

    # <class 'list'>: [False, False, ...]
    results = await asyncio.gather(*coros) # здесь есть await

await main()
```

```python
1 False
7 False
0 False
5 False
6 False
3 False
8 False
2 False
4 False
9 False
```

Время выполнения 0.5 секунды.

По сути у нас есть некая корутина, которая делает проверку на то, что пользователь существует под каким-то id и мы возвращаем результат через asyncio.gather в котором у нас будет лист с нашими результами.

#### А что будет если не ждать gather?

```python
import asyncio

async def main():
    coros = (
        check_user_exists(i)
        for i in range(10)
    )

    asyncio.gather(*coros) # здесь убрали await
    await asyncio.sleep(10)

await main()
```

```python
7 False
6 False
4 False
2 False
1 False
3 False
5 False
0 False
9 False
8 False
```

В данном случе все хорошо, т.к. все таски успевают отработать и мы получаем результат. Но есть ощущение, что так делать не стоит.

#### asyncio.gather()

Примеры выше.

- asyncio.gather() запускает указанные awaitable объекты в конкурентном режиме и возвращает результаты выполнения в том же порядке

- оборачивает объекты coroutine в asyncio.Task

- в случае отмены asyncio.gather() отменяются все запущенные (но еще не завершенные) задачи.

#### Что будет в случае исключения в одной из задач в gather?

Рассмотрим функцию russian_roulette, в которой через корутину заводим через тригер наши процессы и рандомным образом выбираем значения. При позиции = 3 происходит событие ('Boooom!'). В противном случае - OK на этой позиции. Делаем except RuntimeError и await со sleep(10).

```python
async def trigger(position):
    await asyncio.sleep(position)
    if position == 3:
        raise RuntimeError('Boooom!')
    print ('%d is OK' % position)

async def russian_roulette():
    coros = (trigger(i) for i in range(8))
    try:
        await asyncio.gather(*coros)
    except RuntimeError as e:
        print(e)
    await asyncio.sleep(10)

#asyncio.ru(russian_roulette)
await russian_roulette()
```

```python
0 is OK
1 is OK
2 is OK
Boooom!
4 is OK
5 is OK
6 is OK
7 is OK
```

Получили ожидаемый результат. Делая sleep(10) мы не гарантируем, что успеем выполнить все такси. Так можно деалть только в теории, для оценки. То как нужно делать на практике посмотрим дальше.

**Что будет в случае исключения в одной из задач в gather:**

- если параметр return_exeption=False (значение по умолчанию), первое исключение из задачи, запущенной в gather() будет брошено, где запущен await gather(). Остальные задачи, запущенные в gather(), продолжат выполнение.

- если return_exсeption=True, исключения возвращаются в списке с результатами

- если ожидаемый объект, переданный в gather() будет отменен - gather() не отменяется и остальные задачи продолжают выполняться.

#### Как отменить задачу?

- задача coro() будет прервана и не выведет finished

В main() запускаем таску1 - coro(), а затем таску2 - cancel(task) с отменой таски1. Деалаем await со sleep(5), assert cancelled(). В def cancel() делаем sleep на 0.5 секунды, task.cancel() (здесь собственно отменяем таску1). Здесь же делаем try на
await task, если ловим исключение, то оно должно быть CancelledError и сообщаем, что таска1 отменена (print('task successfully cancelled')).

```python
async def coro():
    print('start')
    await asyncio.sleep(2)
    print('finished')

async def cancel(task):
    await asyncio.sleep(0.5)
    task.cancel()
    print('task.cancel() called')
    try:
        await task
    except asyncio.CancelledError:
        print('task successfully cancelled')

async def main():
    task = asyncio.create_task(coro())
    asyncio.create_task(cancel(task))
    await asyncio.sleep(5)
    assert task.cancelled()

await main()
```

В итоге видим, что мы начали, затем видим, что вызвана отмена таски и в итоге, что она отменена.

```python
start
task.cancel() called
task successfully cancelled
```

#### Зачем ждать отмененную задачу?

Рассмотрим функцию check_user_exists, которая возвращает bool. Через aiohttp у нас настроен ClientSession(). Мы через try по нашему url делаем async with соответствующим url на resp, печатаем user_id и resp.status. Возвращаем соответствие - ответ 200 или нет. Если таска отменена мы должны дождаться и выдать какой-то результат (мы должны как-то отреагировать на то, что таска отменена).

##### def check_user_exists() #2

```python
async def check_user_exists(user_id: int) -> bool:
    async with aiohttp.ClientSession() as session:
        try:
            url = f'https://example.org/users/{user_id}'
            async with session.head(url) as resp:
                print(user_id, resp.status == 200)
                return resp.status == 200
        finally: # task.cancel()
            await session.post(
                'http://stat.com/checked-users',
                json={'user_id': user_id}
            )
```

#### Как защитить задачу от отмены?

Допустим мы хотим игнорировать отмены. Проверим, что это работает.

##### except asyncio.CancelledError

- задача coro() не будет отменена

```python
async def coro():
    print('start')
    try:
        await asyncio.sleep(2)
    except asyncio.CancelledError:
        print('ninja coroutine!')
    print('finished')

async def main():
    task = asyncio.create_task(coro())
    asyncio.create_task(cancel(task))
    await asyncio.sleep(5)
    assert not task.cancelled()

#asyncio.run(main())
await main()
```

Т.к. мы поставили except на исключение CancelledError, мы продолжаем работатть, проигнорировав отмену.

```python
start
task.cancel() called
ninja coroutine!
finished
```

Такой подход опасен тем, что мы можем сколь угодно долго ждать завершения процесса. Если мы игнорируем отмены, мы должны понимать, что мы должны ограничиваться таймаутом. Например, если мы асинхронно делаем запись на жесткий диск и ждем успешного завершения... а в этот момент у нас потерялась связь. Будем долго ждать завершения. Важно делать таймаут для исключения подобных ситуаций.

##### asyncio.shield()

`asyncio.shield()` - позволяет защитить наши awaitable объекты от отмены.

- оборачивает сопрограмму в asyncio.Task

```python
async def coro():
    print('start')
    await asyncio.sleep(2)
    print('finished')

async def main():
    task = asyncio.create_task(coro())
    shielded = asyncio.shield(task)
    asyncio.create_task(cancel(shielded))
    await asyncio.sleep(5)
    assert not task.cancelled()

#asyncio.run(main())
await main()
```

```python
start
task.cancel() called
task successfully cancelled
finished
```

Кроме того в shield мы можем указывать время таймаута на которое нам можно не отменяться.

#### Что происходит с ожидающим отмененной задачи, которую отменили?

- ожидающий shield-задачу получит CancelledError

```python
async def coro():
    print('start')
    await asyncio.sleep(2)
    print('finished')

async def main():
    task = asyncio.create_task(coro())
    shielded = asyncio.shield(task)
    asyncio.create_task(cancel(shielded))
    await shielded
    assert not task.cancelled()

#asyncio.run(main())
await main()
```

```python
start
task.cancel() called
task successfully cancelled
---------------------------------------------------------------------------
CancelledError                            Traceback (most recent call last)
/home/vibo/vs_code/async_lect.ipynb Cell 42 in <cell line: 14>()
     11     assert not task.cancelled()
     13 #asyncio.run(main())
---> 14 await main()

/home/vibo/vs_code/async_lect.ipynb Cell 42 in main()
      8 shielded = asyncio.shield(task)
      9 asyncio.create_task(cancel(shielded))
---> 10 await shielded
     11 assert not task.cancelled()

CancelledError: 
```

#### Как ограничить время ожидания awaitable объекта (таймаут)?

- `asyncio.wait_for()` - ожидает выполнение задачи в течение указанного времени, если задача не успевает выполниться - она отменяется и бросается asuncio.TimeoutError

- отмену задачи можно предотвратить с помощью `asyncio.shield()`

- если кто-то отменяет `wait_for()`, то и обернутый им awaitable объект тоже отменяется

##### asyncio.wait_for()

Есть функция main(). Через try делаем wait_for от некоторого обработчика (метода)  eternity() с таймаутом 1 секунда, после этого ловим исключение на TimeoutError. В eternity() делаем try со sleep(3600) секунд.

```python
async def eternity():
    try:
        await asyncio.sleep(3600)
    except asyncio.CancelledError:
        print('I was cancelled')
        raise
    print('finished')

async def main():
    try:
        await asyncio.wait_for(eternity(), timeout=1.0)
    except asyncio.TimeoutError:
        print('timeout')

#asyncio.run(main())
await main()
```

```python
I was cancelled
timeout
```

#### Как подождать выполнения awaitable объектов?

##### asyncio.wait()

Помимо `asyncio.wait_for()` у нас есть `asyncio.wait()`:

- `asyncio.wait()` запускает awaitable-объекты и отдает поток управления, пока не будет выполнено условие return_when (FIRST_COMPLETED, FIRST_EXCEPTION, ALL_COMPLETED)

- оборачивает объекты в coroutine в asyncio.Task

- возвращает два множества: выполненные и выполняющиеся объекты

- не отменяет задачи в случае FIRST_COMPLETED или FIRST_EXCEPTION

```python
async def main():
    tasks = [
        asyncio.create_task(check_user_exists(i))
        for i in range(10)
    ]

    done, pending = await asyncio.wait(tasks, timeout=1)
    # done: <class 'set'>: {<Task finished coro=...>}
    # pending: <class 'set'>: {<Task finished coro=...>}
    print(done, pending)

#asyncio.run(main())
await main()
```

```python
5 False
3 False
7 False
4 False
8 False
6 False
0 False
9 False
1 False
2 False
set() {<Task pending name='Task-7' coro=<check_user_exists() running at /tmp/ipykernel_244/1346784782.py:9> wait_for=<Future pending cb=[<TaskWakeupMethWrapper object at 0x7fc763856d60>()]>>, <Task pending name='Task-12' coro=<check_user_exists() running at /tmp/ipykernel_244/1346784782.py:9> wait_for=<Future pending cb=[<TaskWakeupMethWrapper object at 0x7fc7638e2370>()]>>, <Task pending name='Task-14' coro=<check_user_exists() running at /tmp/ipykernel_244/1346784782.py:9> wait_for=<Future pending cb=[<TaskWakeupMethWrapper object at 0x7fc763873940>()]>>, <Task pending name='Task-10' coro=<check_user_exists() running at /tmp/ipykernel_244/1346784782.py:9> wait_for=<Future pending cb=[<TaskWakeupMethWrapper object at 0x7fc763856d30>()]>>, <Task pending name='Task-8' coro=<check_user_exists() running at /tmp/ipykernel_244/1346784782.py:9> wait_for=<Future pending cb=[<TaskWakeupMethWrapper object at 0x7fc763856af0>()]>>, <Task pending name='Task-13' coro=<check_user_exists() running at /tmp/ipykernel_244/1346784782.py:9> wait_for=<Future pending cb=[<TaskWakeupMethWrapper object at 0x7fc763873880>()]>>, <Task pending name='Task-15' coro=<check_user_exists() running at /tmp/ipykernel_244/1346784782.py:9> wait_for=<Future pending cb=[<TaskWakeupMethWrapper object at 0x7fc7638739d0>()]>>, <Task pending name='Task-6' coro=<check_user_exists() running at /tmp/ipykernel_244/1346784782.py:9> wait_for=<Future pending cb=[<TaskWakeupMethWrapper object at 0x7fc7636f2040>()]>>, <Task pending name='Task-11' coro=<check_user_exists() running at /tmp/ipykernel_244/1346784782.py:9> wait_for=<Future pending cb=[<TaskWakeupMethWrapper object at 0x7fc760530a30>()]>>, <Task pending name='Task-9' coro=<check_user_exists() running at /tmp/ipykernel_244/1346784782.py:9> wait_for=<Future pending cb=[<TaskWakeupMethWrapper object at 0x7fc76396df70>()]>>}
```

Эта информация полезна, если мы хотим логировать процесс (какие таски уже выполнены, какие в процессе выполнения).

##### asyncio.FIRST_EXCEPTION

Если мы хотим дождаться первого исключения (первой ошибки), тогда мы будем это делать через asyncio.FIRST_EXCEPTION. Тогда мы остановимся, когда словим первое исключение.

```python
import asyncio
import aiohttp

async def main():
    tasks = [
        asyncio.create_task(check_user_exists(i))
        for i in range(10)
    ]

    done, pending = await asyncio.wait(
        tasks, return_when=asyncio.FIRST_EXCEPTION
    )
    # done: <class 'set'>: {<Task finished rn=...>}
    # pending: <class 'set'>: {<Task finished coro=...>}
    print(done, pending)

#asyncio.run(main())
await main()
```

```python
7 False
1 False
4 False
2 False
8 False
0 False
3 False
5 False
9 False
6 False
{<Task finished name='Task-23' coro=<check_user_exists() done, defined at /tmp/ipykernel_245/1346784782.py:1> result=False>, <Task finished name='Task-25' coro=<check_user_exists() done, defined at /tmp/ipykernel_245/1346784782.py:1> result=False>, <Task finished name='Task-19' coro=<check_user_exists() done, defined at /tmp/ipykernel_245/1346784782.py:1> result=False>, <Task finished name='Task-21' coro=<check_user_exists() done, defined at /tmp/ipykernel_245/1346784782.py:1> result=False>, <Task finished name='Task-17' coro=<check_user_exists() done, defined at /tmp/ipykernel_245/1346784782.py:1> result=False>, <Task finished name='Task-24' coro=<check_user_exists() done, defined at /tmp/ipykernel_245/1346784782.py:1> result=False>, <Task finished name='Task-26' coro=<check_user_exists() done, defined at /tmp/ipykernel_245/1346784782.py:1> result=False>, <Task finished name='Task-22' coro=<check_user_exists() done, defined at /tmp/ipykernel_245/1346784782.py:1> result=False>, <Task finished name='Task-18' coro=<check_user_exists() done, defined at /tmp/ipykernel_245/1346784782.py:1> result=False>, <Task finished name='Task-20' coro=<check_user_exists() done, defined at /tmp/ipykernel_245/1346784782.py:1> result=False>} set()
```

#### Как еще подождать выполнения awaitable объектов?

##### asyncio.as_completed()

- `asyncio.as_completed()` запускает awaitable-объекты, возвращает итератор по результатам в порядке выполнения (сначала - самые быстро вычисленные)

- можно указать параметр timeout, если все awaitable объекты не успевают выполниться - будет брошено исключение asyncio.TimeoutError

```python
import asyncio
import aiohttp

async def dalayed_result(delay) -> bool:
    return await asyncio.sleep(delay, delay)

async def main():
    tasks = [
        dalayed_result(i)
        for i in range(10)
    ]

    for earliest in asyncio.as_completed(tasks):
        result = await earliest
        print(result)

#asyncio.run(main())
await main()
```

```python
0
1
2
3
4
5
6
7
8
9
```

Если бы таска под номером 2 была бы более трудоемкая она бы шла позже. А насколько позже - зависит от того насколько трудоемкая была бы задача.

#### Что сейчас выполняется?

##### asyncio.current_task()

- `asyncio.current_task()` вернет выполняющуюся в данный момент задачу или None

```python
import asyncio

async def main():
    task = asyncio.current_task()
    # <Task pending coro=<main() running at ...>
    print(task)

#asyncio.run(main())
await main()
```

```python
<Task pending name='Task-15' coro=<InteractiveShell.run_cell_async() running at /home/vibo/vs_code/venv-vsc/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3135> cb=[IPythonKernel._cancel_on_sigint.<locals>.cancel_unless_done(<Future pendi...ernel.py:271]>)() at /home/vibo/vs_code/venv-vsc/lib/python3.9/site-packages/ipykernel/ipkernel.py:271, <TaskWakeupMethWrapper object at 0x7fa67431c400>()]>
```

##### asyncio.all_tasks()

- `asyncio.all_tasks()` вернет все незаконченные задачи, запущенные в цикле событий

```python
import asyncio
import aiohttp

async def main():
    coros = (
        check_user_exists(i)
        for i in range(10)
    )
    asyncio.gather(*coros)
    await asyncio.sleep(0.1)
    tasks = asyncio.all_tasks()
    print(type(tasks))
    print(tasks)

#asyncio.run(main())
await main()
```

```python
<class 'set'>
{<Task pending name='Task-24' coro=<check_user_exists() running at /tmp/ipykernel_241/1346784782.py:5> wait_for=<Future pending cb=[BaseSelectorEventLoop._sock_write_done(118, handle=<Handle BaseS...16.34', 443))>)(), <TaskWakeupMethWrapper object at 0x7f2b0058bdc0>()]> cb=[_gather.<locals>._done_callback() at /usr/lib/python3.9/asyncio/tasks.py:771]>, <Task pending name='Task-26' coro=<check_user_exists() running at /tmp/ipykernel_241/1346784782.py:5> wait_for=<Future pending cb=[BaseSelectorEventLoop._sock_write_done(119, handle=<Handle BaseS...16.34', 443))>)(), <TaskWakeupMethWrapper object at 0x7f2b0058bfa0>()]> cb=[_gather.<locals>._done_callback() at /usr/lib/python3.9/asyncio/tasks.py:771]>, <Task pending name='Task-20' coro=<check_user_exists() running at /tmp/ipykernel_241/1346784782.py:5> wait_for=<Future pending cb=[BaseSelectorEventLoop._sock_write_done(99, handle=<Handle BaseS...16.34', 443))>)(), <TaskWakeupMethWrapper object at 0x7f2b0058b910>()]> cb=[_gather.<locals>._done_callback() at /usr/lib/python3.9/asyncio/tasks.py:771]>, <Task pending name='Task-22' coro=<check_user_exists() running at /tmp/ipykernel_241/1346784782.py:5> wait_for=<Future pending cb=[BaseSelectorEventLoop._sock_write_done(100, handle=<Handle BaseS...16.34', 443))>)(), <TaskWakeupMethWrapper object at 0x7f2b017632b0>()]> cb=[_gather.<locals>._done_callback() at /usr/lib/python3.9/asyncio/tasks.py:771]>, <Task pending name='Task-19' coro=<check_user_exists() running at /tmp/ipykernel_241/1346784782.py:5> wait_for=<Future pending cb=[BaseSelectorEventLoop._sock_write_done(98, handle=<Handle BaseS...16.34', 443))>)(), <TaskWakeupMethWrapper object at 0x7f2b0058b4f0>()]> cb=[_gather.<locals>._done_callback() at /usr/lib/python3.9/asyncio/tasks.py:771]>, <Task pending name='Task-17' coro=<InteractiveShell.run_cell_async() running at /home/vibo/vs_code/venv-vsc/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3135> cb=[IPythonKernel._cancel_on_sigint.<locals>.cancel_unless_done(<Future pendi...ernel.py:271]>)() at /home/vibo/vs_code/venv-vsc/lib/python3.9/site-packages/ipykernel/ipkernel.py:271, <TaskWakeupMethWrapper object at 0x7f2b02e87070>()]>, <Task pending name='Task-25' coro=<check_user_exists() running at /tmp/ipykernel_241/1346784782.py:5> wait_for=<Future pending cb=[BaseSelectorEventLoop._sock_write_done(109, handle=<Handle BaseS...16.34', 443))>)(), <TaskWakeupMethWrapper object at 0x7f2b0058bf40>()]> cb=[_gather.<locals>._done_callback() at /usr/lib/python3.9/asyncio/tasks.py:771]>, <Task pending name='Task-27' coro=<check_user_exists() running at /tmp/ipykernel_241/1346784782.py:5> wait_for=<Future pending cb=[BaseSelectorEventLoop._sock_write_done(121, handle=<Handle BaseS...16.34', 443))>)(), <TaskWakeupMethWrapper object at 0x7f2b0058b3d0>()]> cb=[_gather.<locals>._done_callback() at /usr/lib/python3.9/asyncio/tasks.py:771]>, <Task pending name='Task-2' coro=<Kernel.dispatch_queue() running at /home/vibo/vs_code/venv-vsc/lib/python3.9/site-packages/ipykernel/kernelbase.py:510> wait_for=<Task pending name='Task-17' coro=<InteractiveShell.run_cell_async() running at /home/vibo/vs_code/venv-vsc/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3135> cb=[IPythonKernel._cancel_on_sigint.<locals>.cancel_unless_done(<Future pendi...ernel.py:271]>)() at /home/vibo/vs_code/venv-vsc/lib/python3.9/site-packages/ipykernel/ipkernel.py:271, <TaskWakeupMethWrapper object at 0x7f2b02e87070>()]> cb=[IOLoop.add_future.<locals>.<lambda>() at /home/vibo/vs_code/venv-vsc/lib/python3.9/site-packages/tornado/ioloop.py:687]>, <Task pending name='Task-23' coro=<check_user_exists() running at /tmp/ipykernel_241/1346784782.py:5> wait_for=<Future pending cb=[BaseSelectorEventLoop._sock_write_done(101, handle=<Handle BaseS...16.34', 443))>)(), <TaskWakeupMethWrapper object at 0x7f2b0058b940>()]> cb=[_gather.<locals>._done_callback() at /usr/lib/python3.9/asyncio/tasks.py:771]>, <Task pending name='Task-21' coro=<check_user_exists() running at /tmp/ipykernel_241/1346784782.py:5> wait_for=<Future pending cb=[BaseSelectorEventLoop._sock_write_done(110, handle=<Handle BaseS...16.34', 443))>)(), <TaskWakeupMethWrapper object at 0x7f2b0058be50>()]> cb=[_gather.<locals>._done_callback() at /usr/lib/python3.9/asyncio/tasks.py:771]>, <Task pending name='Task-18' coro=<check_user_exists() running at /tmp/ipykernel_241/1346784782.py:5> wait_for=<Future pending cb=[BaseSelectorEventLoop._sock_write_done(97, handle=<Handle BaseS...16.34', 443))>)(), <TaskWakeupMethWrapper object at 0x7f2b0058b100>()]> cb=[_gather.<locals>._done_callback() at /usr/lib/python3.9/asyncio/tasks.py:771]>}
```

### Низкоуровневый API

#### Policy (политика)

- глобальный объект для каждого процесса, отвечает за выбор, настройку и управление циклом событий

- определяет понятие контрекста и управляет отдельным циклом событий для каждого контекста (по умолчания контекст - текущий поток)

- по умолчанию используется DefaulEventLoopPolicy, использует SelecorEventLoop на *nix и Proactor на Windows

- есть альтернативные WindowsSelectorEventLoopPolicy и WindowsProactorEventLoopPolicy

- можно получить текущую с помощью asyncio.get_event_loop_policy()

- настраивается с помощью asyncio.set_event_loop_policy(policy)

Например, если мы хотим задать определенный EventLoop, то делаем это через `set_event_loop_policy` и указываем конкретный WindowsSelectorEventLoopPolicy.

```python
import asyncio

asyncio.set_event_loop_policy(
    asyncio.WindowsSelectorEventLoopPolicy
)

...
```

#### Что скрывается за uvloop.install()?

Под uvloop.install() находится система информации о том, как и что запускается, импортится. Вано понимать, что EventLoop имеет разные варианты под разные задачи.

```python
def install():
    """A helper function to install uvloop policy."""
    __asyncio.set_event_loop_policy(EventLoopPolicy())

class EventLoopPolocy(__BasePolicy):
    """Event loop policy.
    The preferred way to make your application use uvloop:
    >>> import asyncio
    >>> import uvloop
    >>>
asyncio.set_event_loop_policy(uvloop.EventLoopPolicy())
    >>> asyncio.get_event_loop(
    <uvloop.Loop running=False closed=False debug=False>
    """
```

### Цикл событий

EventLoop - и есть ядро нашего асинхронного приложения, делает распределение в наших задачах, кто на что переключается и т.д.

- ядро любого asyncio приложения

- выполняет асинхронные задачи и функции обратного вызова из очереди, выполняет сетевой I/O, управляет выполнением процессов (см. _run_once())

- asyncio предоставляет нам SelectorEventLoop (*nix) и ProactorEventLoop (Windows)

#### SelectorEventLoop

- использует модуль selectors, который включает в себя
  
  - SelectSelector
  
  - PollSelector
  
  - EpollSelector
  
  - DevpollSelector
  
  - KqueueSelector
  
  - DefaultSelector (по умолчанию)

DefaulSelector сам выбирает селектор, который больше подходит для оптимизации, но если мы хотим воспользоваться каким-то конкретным, мы можем его указать.

#### Что умеет цикл событий?

- планировать обратные вызовы (что в какой последовательности и с каким приоритетом)

- открывать сетевые подключения, в т.ч. защищенные (TLS)

- создавать сетевые серверы

- эффективно передавать файлы (sendfile)

- мониторить файловые дескрипторы (операции с файлами)

- напрямую работать с объектами socket

- резолвить DNS (в потоках, потому что "unix плох")

- обрабатывать сигналы операционной системы (*nix)

- выполнять код в пулах потоков или процессов

- выполнять подпроцессы

#### Запуск синхронного кода в процессе/потоке

Через asyncio делаем get_running_loop(), делаем run_in_executor и у нас есть некий blocking_io. Метод в котором мы блокируемся на работу с нашими файлами, т.е. мы можем заблокироваться на read как в данном случае. В нашем случае используем default EventLoop в котором мы запускаем наш метод на обработку. Мы не блокируемся, потому, что делаем обращение на чтение. Блокируемся, занимаемся чем-то другим полезным и те, что дорабатывают и получают необходимый результат завершаются и мы их закрываем.

```python
def blocking_io():
    with open('dev/urandom', 'rb') as f:
        return f.read(100)

def cpu_bound():
    return sum(i * i for i in range(10 ** 7))

async def main():
    loop = asyncio.get_running_loop()
    # 1. Run in the default loop's executor:
    result = await loop.run_in_executor(None, blocking_io)
    print('default thread pool', result)

#asyncio.run(main()
await main()
```

По сути это и есть реализация "идеального мира" (лекция, часть 1.)

<img src="file:///home/vibo/Pictures/GlobalMarkText/2022-09-05-10-37-51-2022-09-01-09-53-37-image.png" title="" alt="" data-align="center">

Ниже рассматривается ситуация, где мы также делаем `get_running_loop()`. Делаем явно `ThreadPoolExecutor()`, в котором мы пробегаем по тредам и делаем что-то полнезное, также блокируясь в методе blocking_io по работе с файлами. После этого через `ProcessPoolExecutor()` записываем результат, тоже через run_in_executor какие-то cpu_bound задачи, которые тоже являются блокером (как мы обсуждали выше). Потому, что если задача трудоемкая, может на долго остановиться на ее вычислении.

```python
async def main():
    loop = asyncio.get_running_loop()

    # 2. Run in a custom thread pool:
    with concurrent.futures.ThreadPoolExecutor() as pool:
        result = await loop.run_in_executor(pool, blocking_io)
        print('custom thread pool', result)

    #3. Run in a custom process pool:
    with concurrent.futures.ProcessPoolExecutor() as pool:
        result = await loop.run_in_executor(pool, cpu_bound)
        print('custom process pool', result)

#asyncio.run(main())
await main()
```

#### Альтернативные циклы: uvloop

- реализован поверх libuv, стабильный

- может дать хороший прирост производиельности, если есть очень много сетевого I/O

Идея та же, смысл в мощной оптимизации, реализация на С. uvloop - хорошее решение в высоконагруженных системах.

<img src="file:///home/vibo/Pictures/GlobalMarkText/2022-09-05-11-02-13-image.png" title="" alt="" data-align="center">

### Асинхронные интерфейсы

#### Асинхронный менеджер контекста

- способен приостановить выполнение в aenter и aexit методах

- как и с обычными менеджерами контекста, можно использовать несколько объектов с оператором async with

#### Как реализовать асинхронный менеджер контекста?

Допустим у нас есть метод init в котором мы возвращаем connection. Делаем aenter в котором мы делаем execute на 'BEGIN', печатаем какой-то промежуточный результат и return. После этого делаем aexit с 'ROLLBACK' и conn.execute по какой-то конкретной команде и печатаем exiting context.

```python
class TransactionCtx:
    def __init__(self, conn):
        self.conn = conn

    async def __aenter__(self):
        await self.conn.execute('BEGIN')
        print('entering context')
        return self

    async def __aexit__(self, exc_type, exc, tb):
        command = 'ROLLBACK' if exc else 'COMMIT'
        await self.conn.execute(command)
        print('exiting context')
```

#### Как использовать асинхронный менеджер контекста?

Для этого делаем await connect, после async with...

```python
async def main():
    conn = await connect(...)
    async with TransactionCtx(conn) as transaction:
        ...
```

#### Для чего нужны асинхронные итераторы?

- можно вызывать асинхронный код

- итерируемый объект должен реализовывать метод aiter

- итератор должен реализовывать асинхронный метод anext

- по завершении метод anext должен бросить исключение StopAsyncIteration

#### Как написать асинхронный итератор?

В init делаем инициализацию полей. В anext проверяем, что если мы дошли до конца деалем raise по исключению StopAsyncIteration, если это не так, то увеличиваем наш итератор на 1. Суть в том, что мы можем работать с итераторами в асинхронщине точно также.

```python
class Ticker:
    def __init__(self, delay, to):
        self.delay = delay
        self.i = 0
        self.to = to

    def __aiter__(self):
        return self

    async def __anext__(self):
        i = self.i
        if i >= self.to:
            raise StopAsyncIteration
        self.i += 1
        if i:
            await asyncio.sleep(self.delay)
        return i
```

#### Как использовать асинхронный итератор?

Делаем через async for - асинхронно проходя до 10 и запускаем.

```python
async def main():
    async for i in Ticker(1, 10):
        print(i)
    else:
        print('hm?')

#asyncio.run(main())
await main()
```

```python
0
1
2
3
4
5
6
7
8
9
hm?
```

#### Асинхронные генераторы

- асинхронная функция, в которйо используется yield

- вместо send и throw - асинхронные asend() и athrow()

- можно использовать c async for

- не поддерживают yield from

В целом, если захотим выйти из цикла через breake, то мы не сможем вернуться обратно. Если мы хотим итерироваться по циклу и ходить по объектам используются генераторы и в асинхронщиене они сделаны очень удобно.

#### Как реализовать и использовать асинхронный генератор?

Мы проходим в неком нашем цикле, делаем yield по каждому i. После этого делам sleep и асинхронно проходим в нашем цикле и печатем i.

```python
async def ticker(delay, to):
    for i in range(to):
        yield i
        await asyncio.sleep(delay)

async def main():
    async for i in ticker(1, 10):
        print(i)

#asyncio.run(main())
await main()
```

```python
0
1
2
3
4
5
6
7
8
9
```

#### Asynchronous comprehensions

- в python 3.6+ поддерживаются все comprehensions:
  
  - множество: {i async for i in agen()}
  
  - список: [i async for i in agen()]
  
  - словарь: {i: i ** 2 async for i in agen()}
  
  - генератор (i ** 2 async for i in agen())

- можно сочетать с for и условиями if

Давайте посмотрим на примере: есть main, где мы проходим в циклах через async for и нам нужно условие, что i не делится нацело на 2 и j делится нацело на 2.

```python
async def ticker(delay, to):
    for i in range(to):
        yield i
        await asyncio.sleep(delay)

async def main():
    results = [
        (i, j)
        async for i in ticker(0.1, 5)
        async for j in ticker(0.1, 5)
        if not i % 2 and j % 2
    ]
    print(results)

await main()
```

```python
[(0, 1), (0, 3), (2, 1), (2, 3), (4, 1), (4, 3)]
```

### Aiohttp

#### Что это и зачем?

- Есть какие-то клиенты, для них есть обработчики, нам нужно парсить какие-то запросы, обрабатывать, делать request на пользователя и в конечном итоге отправлять наш response.

Сам сервер мы запускаем через start_server на адресе и порте. И запускаем наш сервер в бесконечном цикле через serve_forever() в котором написаны какие-то базовые вещи. Соответсвенно нам нужно осуществлять на сетевом уровне взаимодецствие с нашими обработчиками.

```python
import asyncio

async def handle(reader, writer):
    # get client headers
    # parse request headers
    # route request (call appropriate handler)
    # retrieve request body
    # write response headers
    # write response payload (body)
    pass

async def main():
    server = await asyncio.start_server(handle, '127.0.0.1', 8888)
    async with server:
        await server.serve_forever()

#asyncio.run(main())
await main()
```

- асинхронный HTTP клиент и сервер для asyncio

- поддерживает HTTP 1.0, 1.1 не поддерживает 2.0

- поддерживает вебсокеты

- обработчик должен быть awaitable

- парсер HTTP написан на С (взят из nodejs)

#### Пример HTTP сервера

Допустим есть какое-то приложение Application, мы указывем route то, что у нас будет по GET. Делаем run_app на соответствующем порту. И будет 

```python
from aiohttp import web
from aiohttp.web import run_app

async def handle(request):
    return web.Response(text='Meow.')

app = web.Application()
app.router.add_route('GET', '/', handle)
run_app(app, port=8888)
```

`python simple_http_serv.py`

```bash
(venv-vsc) sh-5.1$ python simple_http_serv.py
======== Running on http://0.0.0.0:8888 ========
(Press CTRL+C to quit)
```

#### Постучимся в CAAS

`http -v 0.0.0.0:8888` # sh: http: command not found

Вывел через curl

`curl  http://0.0.0.0:8888` # терминал 2

```bash
Meow.
```

`curl -v http://0.0.0.0:8888`

```bash
* STATE: INIT => CONNECT handle 0x5634023a55e0; line 1834 (connection #-5000)
* Added connection 0. The cache now contains 1 members
* family0 == v4, family1 == v6
*   Trying 0.0.0.0:8888...
* STATE: CONNECT => CONNECTING handle 0x5634023a55e0; line 1895 (connection #0)
* Connected to 0.0.0.0 (127.0.0.1) port 8888 (#0)
* STATE: CONNECTING => PROTOCONNECT handle 0x5634023a55e0; line 2027 (connection #0)
* STATE: PROTOCONNECT => DO handle 0x5634023a55e0; line 2050 (connection #0)
> GET / HTTP/1.1
> Host: 0.0.0.0:8888
> User-Agent: curl/7.82.0-DEV
> Accept: */*
> 
* STATE: DO => DID handle 0x5634023a55e0; line 2146 (connection #0)
* STATE: DID => PERFORMING handle 0x5634023a55e0; line 2265 (connection #0)
* Mark bundle as not supporting multiuse
* HTTP 1.1 or later with persistent connection
< HTTP/1.1 200 OK
< Content-Type: text/plain; charset=utf-8
< Content-Length: 5
< Date: Mon, 05 Sep 2022 10:07:53 GMT
< Server: Python/3.9 aiohttp/3.8.1
< 
* STATE: PERFORMING => DONE handle 0x5634023a55e0; line 2464 (connection #0)
* multi_done: status: 0 prem: 0 done: 0
* Connection #0 to host 0.0.0.0 left intact
* Expire cleared (transfer 0x5634023a55e0)
Meow.
```

Тем самым с помощью aiohttp мы абстрагируемся от низкоуровневых системных вызовов, от системной информации. Мы максимально быстро можем строить клиент-серверное взаимодействие. Наша цель, чтобы сервер давал ответ, он его дает, вся остальная настрйока опускается.  Это очень удобно.

#### Пример HTTP клиента

```python
import asyncio
import aiohttp

async def main():
    async with aiohttp.ClientSession() as session:
        async with session.get('http://0.0.0.0:8888') as resp:
            print(resp.status) # body не можем распечатать - payloads (разберем ниже)
            print(await resp.text)

asyncio.run(main())
```

### Middleware

#### Что такое middleware?

- очень мощный инструмент для изменения логики работы обработчиков и их ответов:
  
  - аутентификация и авторизация
  
  - обработка ошибок
  
  - модифицирование ответов

У нас есть некое приложение Application в которм мы настраиваем наше взаимодействие через router.add_get. Запускаем приложение. В middleware идет обработка того или иного запроса и возвращение response.

```python
from aiohttp import web
from aiohttp.web import run_app

async def test(request):
    print('Handler function called')
    return web.Response(text='Hello')

@web.middleware
async def middleware(request, handler):
    print('Middleware called')
    response = await handler(request)
    print('Middleware finished')
    return response

app = web.Application(middlewares=[middleware])
app.router.add_get('/', test)
web.run_app(app)    
```

`python simple_middleware.py` # терминал 1

`curl http://0.0.0.0:8080` # терминал 2

```bash
# Терминал 1.
======== Running on http://0.0.0.0:8080 ========
(Press CTRL+C to quit)
Middleware called
Handler function called
Middleware finished
```

```bash
# Терминал 2.
Hello
```

### Payloads

#### Напишем простое aiohttp приложение

Выше говорили о том, что у нас есть проблема - когда делаем aiohttp проблема получить значение в response в body. Для того, чтобы это сделать рассмотрим пример.

Заводим Application, делаем append(init_pg) - обращение к базе данных. В хендлере делаем обработку - какой-то sql-запрос и формирование Response в удобной нам форме.

```python
import aiohttp
import asyncpg
from aiohttp import web
from aiohttp.web import run_app

async def init_pg(app):
    app['pg'] = await asyncpg.create_pool(
        #'postgresql://user:me@0.0.0.0/test'
        'postgresql://postgres:me@0.0.0.0/test' # для моего pg + надо создать test
    )

'''
aiohttp.payload.LookupError
ValueError.Unsupported bode type <class 'dict'>

Здесь ловим ошибку, потому, что в init_pg возвращаем результат
в виде dict. Происходит несоответсвие типов.
'''

async def handle(request):
    async with request.app['pg'].acquire() as conn:
        row = await conn.fetchrow('SELECT 1 as col')
    return aiohttp.web.Response(body={'data': row})

app = web.Application()
app.router.add_route('GET', '/', handle)
app.on_startup.append(init_pg)
aiohttp.web.run_app(app, port=8082)
```

```bash
(venv-vsc) sh-5.1$ python simple_aiohttp_app.py
======== Running on http://0.0.0.0:8082 ========
(Press CTRL+C to quit)
```

#### Научим aiohttp работать с Mapping-объектами

Можем воспользоваться PAYLOAD_REGISTRY в котором мы говорим, что хотим использовать JsonPayload.

```python
'''
TypeError: Object of type Record is not JSON serializable

Здесь тоже будет ошибка
'''

from typing import Mapping
from aiohttp import PAYLOAD_REGISTRY, JsonPayload
PAYLOAD_REGISTRY.register(JsonPayload, Mapping)
```

#### Что такое JsonPayload?

У нас есть некий init в котором мы задаем значения, кодировку, дампы и прочие аргументы.

```python
from json import JSONEncoder

class JsonPayload(BytesPayload):

    def __init__(self,
                value: Any,
                encoding: str='utf-8',
                content_type: str='application.json',
                dumps: JSONEncoder=json.dumps,
                *args: Any,
                **kwargs: Any) -> None:

        super().__init__(
            dumps(value).encode(encoding),
            content_type=content_type, encoding=encoding,
            *args, **kwargs)
```

Для решения нам потребуется singledispatch.

#### singledispatch for win

У нас есть convert_datetime, в котором мы делаем соответсвующую конвертацию. Возвращаем dict на наше значение и если такого соответствия нет - выдаем исключение.

```python
from datetime import datetime
from functools import singledispatch
from asyncpg import Record

@singledispatch
def convert(value):
    raise NotImplementedError(f'Unserializable value: {value!r}')

@convert.register(Record)
def convert_asyncpg_record(value: Record):
    return dict(value)

@convert.register(datetime)
def convert_datetime(value: datetime):
    return value.isoformat()
```

#### Научим aiohttp работать с объектами типа asyncpg.Record и datetime

```python
from email.policy import default
import json
from functools import partialmethod, partial
from typing import Mapping

dumps = partial(json.dumps, default=convert)

class UniversalJsonPayload(JsonPayload):
    __init__ = partialmethod(JsonPayload.__init__, dumps=dumps)

PAYLOAD_REGISTRY.register(UniversalJsonPayload, Mapping)
```

### Проблемы

#### Управление фоновыми задачами

##### Запуск и остановка Event Loop

У нас есть event loop в котором запускаются и останавливаются таски. У нас есть хендлер с текщим временем. У нас етсь сервер, который запускает хендлер. И есть main, где у нас происходит инициализация.

```python
import asyncio, time

async def handler(reader, writer):
    writer.write(f'{time.time()}\n\r'.encode())
    writer.close()

async def server():
    server = await asyncio.start_server(handler, '::1', 2023)
    await server.serve_forever # ?

async def main():
    await server()

#asyncio.run(main())
await main()
```

##### Управление задачами

Рассмотрим ситуацию, когда большое количество задач. Нам надо как-то обновлять cache, у нас есть сервер, статистика, записываем еще логи. Все это запускаем через gather.

```python
async def cache(interval):
    """ Start updateing response cache """
    pass

async def server():
    """ Start TCP server """
    pass

async def statistic():
    """ Start sending usage statistic """
    pass

async def log_sender():
    """ Start sending internal logs to LOG collection """
    pass

async def main():
    await asyncio.gather(cache(), server(), statistic(), log_sender())

asyncio.run(main())
```

##### Прототипы задач

Допустим с какой-то задачей что-то пошло не так. Допустим есть некая реализция, в каждом методе мы что-то делаем полезное. Если где-то происходит ошибка, например в statistic() - отменится все! Нам бы хотелось, даже если у нас упала статистика дозавершить подготовку кеш и сервер должен продолжать работать и писаться логи.

```python
async def cache(interval):
    """ Start updateing response cache """
    while True:
        await update_global_cache()
        await asyncio.sleep(interval)

async def server():
    """ Start TCP server """
    await passing_config_to_handler()
    await create_server()

async def statistic():
    """ Start sending usage statistic """
    await configuring_sender()
    await start_sending()

async def log_sender():
    """ Start sending internal logs to LOG collection """
    await configuring_sender()
    await start_sending()

async def main():
    await asyncio.gather(cache(), server(), statistic(), log_sender())

asyncio.run(main())
```

##### Решение с wait

- если одна задача упала, нужно отменить все остальные

```python
async def main():
    done, pending = await asyncio.wait(
        [
            cache(),
            server(),
            statistic(),
            log_sender(),
        ],
        return_when=asyncio.FIRST_EXCEPTION
    )
    pass

asyncio.run(main())
```

#### Stdout блокируется

##### Простой пример

Также есть проблема с stdout блокировкой. Когда мы бере и в цикле просто печатаем каждую итерацию, то получается, что это тоже трудоемкий процесс. Через pv мы можем ограничиться промежутком и посмотреть  насколько мы укладываемся по времени.

```python
import logging

logging.basicConfig(level=logging.DEBUG)

for i in range(1000):
    logging.info("Iteration %s", i)
```

`time python simple_example.py 2>&1 | pv -q -L 5000 | dd of=/dev/null` # надо установить pv ()

```bash
0+52 records in
46+1 records out
23890 bytes (24 kB, 23 KiB) copied, 4.73544 s, 5.0 kB/s
python simple_example.py 2>&1  0.04s user 0.01s system 98% cpu 0.045 total
pv -q -L 5000  0.00s user 0.01s system 0% cpu 4.739 total
dd of=/dev/null  0.01s user 0.00s system 0% cpu 4.739 total
```

`time python simple_example.py 2>&1 | pv -q | dd of=/dev/null`

```bash
0+971 records in
46+1 records out
23890 bytes (24 kB, 23 KiB) copied, 0.0425232 s, 562 kB/s
python simple_example.py 2>&1  0.03s user 0.01s system 99% cpu 0.045 total
pv -q  0.00s user 0.01s system 14% cpu 0.044 total
dd of=/dev/null  0.01s user 0.00s system 11% cpu 0.044 total
```

### Retry policy

#### Сеть ненадежна

- сеть работает довольн осложно, и иногда маршрутизаторы сбрасываю соединения/перезагружаются и т.д.

- TCP соединения разрываются - это норма

Мы должны это учитывать при разработке микросервиса. Должны все обрабатывать.

##### Умный клиент

Клиент делает запрос на наш сервис, сервис делает запрос на сервер. Получает результат 503 (сервер не готов обработать данный запрос). Прогоняем этот ответ сервера через наш сервис и возвращаем этот ответ клиенту. Умный клиент делает **retry**. 

<img src="file:///home/vibo/Pictures/GlobalMarkText/2022-09-05-22-26-25-image.png" title="" alt="" data-align="center">

##### Умный прокси

Мы поднимаем какой-нибудь Nginx, делаем также запрос на сервис, обращаясь к тому или иному ресурсу, получаем 503 (сервер недоступен). Nginx сразу делает retry и возвращается уже к клиенту с результату. 

<img src="file:///home/vibo/Pictures/GlobalMarkText/2022-09-05-22-31-16-image.png" title="" alt="" data-align="center">

##### Умный сервис

Когда мы внутри нашей питонячей реализации на сервисе. Клиент делает запрос через нас. Мы обращаемся к тому или иному ресурсу, получаем fail и сами делаем retry 5-7 с определенными таймаутами, как сами зададим. И если после нескоьких попыток вернули положительный результат - отправляем его клиенту.

<img src="file:///home/vibo/Pictures/GlobalMarkText/2022-09-05-22-35-17-image.png" title="" alt="" data-align="center">

Пример:

```python
import aiohttp, asyncio

async def fetch(session, url):
    while True:
        try:
            async with session.get(url) as response:
                return await response.text()
        except aiohttp.ClientError:
            await asyncio.sleep(0.5)

async def main():
    async with aiohttp.ClientSession() as session:
        print(await fetch(session, 'http://python.org'))

#asyncio.run(main())
await main()
```

##### Чего хочется на практике?

- клиент не готов ждать выполнения запроса вечно

- обычно он готов ждать больше секунды (на пяти в крайнем случае)

- требуется "вести себя прилично " и не "заваливать" удаленный сервер запросами (мы же асинхронные, и можем их много и часто запрашивать)

- нужно понимать какие именно исключения нужно бросать сразу; например в ответ на ошибку доступа - нет смысла пытаться сделать повторный запрос.

##### ThreadPool/ProcessPool

Блокирующие операции. Мы рассматривали ситуацию, когда в асинхронном режиме выполняли различные задачи и застряли на выполнении какой-то CPU-bound задачей, которая заняла много ресурсов и забила наш EventLoop. Нам важно, чтобы те или иные блокирующие операции выполнялись отдельно от EventLoop и у нас не ломалась наша асинхронная модель в пуле потоков или процессов.

<img src="file:///home/vibo/Pictures/GlobalMarkText/2022-09-06-13-53-48-image.png" title="" alt="" data-align="center">

- блокирующие операции ~~можно~~ нужно выполнять отдельно от EventLoop, в пуле потоков или процессов

- чаще всего блокирующие операции отпускают GIL, и треды не ждут друг-друга, но нужно это отдельно исследовать

- задачи, которые делают много вычислений (особенно в циклах), можно вызвать в ProcessPool или использовать что-то что выполнит эту задачу оптимально (NumpyNumba/Cython)

Пример: есть main в котором мы делаем запуск reader; в reader делаем get_running_loop и читаем файл, открываем его и мы должны получить успешное выполнение нашего осистемного вызова read(). Делаем return run_in_executor на read_file.

```python
import asyncio
from concurrent.futures import ThreadPoolExecutor

loop = asyncio.new_event_loop()
loop.set_default_executor(ThreadPoolExecutor(8))

def reader(fname):
    loop = asyncio.get_running_loop()
    def read_file():
        with open(fname, "rb") as fp:
            return fp.read()
    return loop.run_in_executor(None, read_file)

async def main():
    print(await reader("/ect/bashrc"))

loop.run_until_complete(main())
```

### Основные концепции

#### Entrypoint

##### Запуск и остановка EventLoop

Воспользуемся aiomisc.entrypoint() и через run_until_complete мы делаем запуск main.

```python
import asyncio
import aiomisc

async def main():
    await asyncio.sleep(1)

with aiomisc.entrypoint() as loop:
    loop.run_until_complete(main()) # analog asyncio.run()
```

Можем это деалть и по интереснее. Делаем create_task от main() и после этого еще делаем run_forever(). В самом main у нас есть какой-то сервер, мы его вызываем. А в хендлере делаем какую-то необходимую запись и закрываем соединение. 

```python
import asyncio, time, aiomisc

async def hanler(reader, writer):
    writer.write(f"{time.time()}\n\r".encode())
    writer.close()

async def server():
    server = await asyncio.start_server(handler, "::1", 2023)

async def main():
    await server()

with aiomisc.entrypoint() as loop:
    loop.create_task(main())
    loop.run_forever()
```

##### Что произошло?

- сощдание и запуск event loop
  
  - создает default thread pool
  
  - подключаем uvloop (если установлен)
  
  - инициализируем thread-pool
  
  - отдаем объект в контекст
  
  - выполняем пользовательсткий код в контекстае
  
  - ожидание всех блоков finally и закрытие экземпляра event loop

##### Что еще умеет делать entrypoint?

Логи - это важно, это дополнительная информация по которой можно определить какой произошел fail. В чем проблем логирования? - в асинхронщине. Под логированиевыделяется отдельный тред, по умолчанию, и на это выделяется немало ресурсов. Для того, чтобы эффективнее использовать наше железо - мы должны через entrypoint явно указывать различные значения, которые нас устаивают. 

```python
async def main():
    while True:
        await asyncio.sleep(1)
        logging.info('Hello there')

with aiomisc.entrypoint(
    pool_size=2,            # thread pool size
    log_level='info',       # logging configuratiion
    log_format='color',     # log formatter
    log_buffer_size=1024,   # buffer size for log records
    log_flush_interval=0.2, # write logs in separate thread
    debug=False,            # set debug flag for event loop
    log_config=True,
    policy=asyncio.DefaultEventLoopPolicy(),
) as loop:
    loop.create_task(main())
    loop.run_forever()
```

### Сервисы

#### Сервис - базовый класс

Рассмотрим сервис как базовый класс. Например, MyService, который образован от Service. У него есть метод start и stop, которые что-то делают. Соответственно так инициализируем сервис с теми или иными методами на обработку.

```python
import asyncio
from aiomisc import entrypoint, Service

class MyService(Service):
    async def start(self):
        self.task = self.loop.create_task(
            asyncio.sleep(3600, loop=self.loop)s
        )

    async def stop(self):
        self.task.cancel()

        try:
            await self.task
        except asyncio.CancelledError:
            pass
```

Мы можем явно указывать, что метод stop нас не интересует, мы хотим преимущественно расмотреть start.

```python
import asyncio
from aiomisc import entrypoint, Service

class MyService(Service):
    async def start(self):
        self.start_event.set()
        await asyncio.sleep(3600, loop=self.loop)
```

#### Как запустить сервис?

```python
with entrypoint(MyService()) as loop:
    loop.run_forever()
```

#### Как запустить сервисы?

Сервисы могут запускаться и работать в одном потоке, в одной программе. Выглядеть это будет следующим образом. Деаем with entrypoint по двум нашим сервисам s1, s2.

```python
import asyncio
from aiomisc import entrypoint, Service

class MyService(Service):
    async def start(self):
        self.start_event.set()
        await asyncio.sleep(3600, loop=self.loop)

s1 = MyService()
s2 = MyService()

with entrypoint(s1, s2, log_level='info') as loop:
    loop.run_forever()
```

#### Базовые классы сервисов

##### TCPServer

Создаем класс, указываем в аргументе TCPServer и прописываем в методе handle_client и прочее. Для запуска через entrypoint указываем инициализированный сервис.

```python
from aiomisc.entrypoint import entrypoint
from aiomisc.service import TCPServer

class EchoServer(TCPServer):
    async def handle_client(self, reader, writer):
        while True:
            writer.write(await reader.readline())

echo = EchoServer(address='::1', port=8901)

with entrypoint(echo) as loop:
    loop.run_forever()
```

##### TLSServer

```python
from aiomisc.entrypoint import entrypoint
from aiomisc.service import TLSServer

class EchoServer(TLSServer):
    async def handle_client(self, reader, writer):
        while True:
            writer.write(await reader.readline())

ssl_opts = dict(ca='ca.pem', cert='cert.pem', key='key.pem')
echo = SecureEchoServer(address='::1', port=8900, **ssl_opts)

with entrypoint(echo) as loop:
    loop.run_forever()
```

##### UDPServer

```python
from aiomisc.entrypoint import entrypoint
from aiomisc.service import UDPServer

class UDPPrinter(UDPServer):
    async def handle_dategram(self, data: bytes, addr):
        print(addr, '->', data)

service = UDPPrinter(address='::1', port=3000)

with entrypoint(service) as loop:
    loop.run_forever()
```

##### PeriodicService

```python
import aiomisc
from aiomisc.service.periodic import PeriodicService

class MyPeriodicService(PeriodicService):
    async def callback(self):
        log.info('Running periodic callback')
        #...

service = MyPeriodicService(interval=3600) # once per hour

with entrypoint(service) as loop:
    loop.run_forever()
```

##### Много сервисов в одном процессе

```python
services = (
    LoggingService(name='#1'),
    EchoServer(address='::1', port=8901),
    UDPPrinter(address='::1', port=3000),
)

with entrypoint(*services) as loop:
    loop.run_forever()
```

Мы можем указать несколько сервисов, которые мы хотим одновременно инициализировать.

##### Конфигурирование сервисов

```python
class LoggingService(Service):
    __required__ = frozenset({'name'}) # required kwargs

    delay: int = 1                     # default value

    async def start(self):
        self.start_event.set()
        while True:
            print('Hello from service', self.name)
            await asyncio.sleep(self.delay)

services = (
    LoggingService(name='#1'),
    LoggingService(name='#2', delay=3),
)

with entrypoint(*services) as loop:
    loop.run_forever()
```

##### aiohttp service

Допустим у нас есть некий хендлер, который матчит необходимую информацию. Делает Response необходимый. У нас  есть класс REST - который принимает AIOHTTPService, в котором происходит create_application с инициализацией рутов и возвращает это приложение.

```python
async def handle(request):
    name = request.match_info.get('name', "Anonymous")
    return aiohttp.web.Response(text='Hello, ' + name)

class REST(AIOHTTPService):
    async def create_application(self):
        app = aiohttp.web.Application()

        app.add_routes([
            aiohttp.web.get('/', handle),
            aiohttp.web.get('/{name}', handle)
        ])

        return app

with entrypoint(REST(address="::", port=8081)) as loop:
    loop.run_forever()
```

### Готовые сервисы

#### MemoryTracer

В Яндексе активно используется MemoryTracer - нужен, например, для того чтобы с кам-то интервалом смотреть не происходит ли утечка по памяти. 

Воспользуемся  MemoryTracer с интервалом в 1 секунду, который будет выдавать топ-5 результатов по использованию памяти и возвращать соответствующий результат. В нашем main будет сама загрузка памяти через leaking.append.

```python
import asyncio
import os
from aiomisc import entrypoint
from aiomisc.service import MemoryTracer

async def main():
    leaking = []

    while True:
        leaking.append(os.urandom(128))
        await asyncio.sleep(0)

with entrypoint(MemoryTracer(interval=1, top_results=5)) as loop:
    loop.run_until_complete(main())
```

` python memory_tracer.py`

```bash
2022-09-06 15:38:20 [T:MainThread] WARNING:aiomisc.service.tracer: Start memory tracer
2022-09-06 15:38:20 [T:Thread 0 from pool default] INFO:aiomisc.service.tracer: Top memory usage:
 Objects | Obj.Diff |   Memory | Mem.Diff | Traceback
      10 |       10 |   2.0KiB |   2.0KiB | /usr/lib/python3.9/asyncio/events.py:80
       4 |        4 |  1000.0B |  1000.0B | /home/vibo/vs_code/venv-vsc/lib/python3.9/site-packages/aiomisc/utils.py:403
       8 |        8 |   877.0B |   877.0B | /usr/lib/python3.9/asyncio/base_events.py:433
       5 |        4 |   800.0B |   728.0B | /usr/lib/python3.9/_weakrefset.py:89
       3 |        3 |   712.0B |   712.0B | /home/vibo/vs_code/venv-vsc/lib/python3.9/site-packages/aiomisc/recurring.py:159

2022-09-06 15:38:22 [T:Thread 2 from pool default] INFO:aiomisc.service.tracer: Top memory usage:
 Objects | Obj.Diff |   Memory | Mem.Diff | Traceback
   77055 |    77055 |  12.4MiB |  12.4MiB | /home/vibo/vs_code/memory_tracer.py:10
      63 |       63 |   4.9KiB |   4.9KiB | /usr/lib/python3.9/tracemalloc.py:115
      15 |       15 |   3.8KiB |   3.8KiB | /usr/lib/python3.9/asyncio/events.py:80
      80 |       80 |   3.8KiB |   3.8KiB | /usr/lib/python3.9/tracemalloc.py:193
      37 |       37 |   3.0KiB |   3.0KiB | /usr/lib/python3.9/abc.py:123

...
```

#### Profiler

Нужна чтобы видеть насколько мы загружаемся при выполнении.

```python
import asyncio
import os
from aiomisc import entrypoint
from aiomisc.service import Profiler
import time

async def main():
    for i in range(100):
        time.sleep(0.01)

with entrypoint(Profiler(interval=0.1, top_results=5)) as loop:
    loop.run_until_complete(main())
```

`python profiler.py`

```bash
2022-09-06 15:47:37 [T:MainThread] INFO:aiomisc.service.profiler.140319943764528:          187 function calls in 0.000 seconds

   Ordered by: cumulative time
   List reduced from 76 to 5 due to restriction <5>

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
        3    0.000    0.000    0.000    0.000 base_events.py:1815(_run_once)
        6    0.000    0.000    0.000    0.000 events.py:78(_run)
        6    0.000    0.000    0.000    0.000 {method 'run' of 'Context' objects}
        2    0.000    0.000    0.000    0.000 recurring.py:86(_start)
        1    0.000    0.000    0.000    0.000 periodic.py:33(start)



2022-09-06 15:47:38 [T:MainThread] INFO:aiomisc.service.profiler.140319943764528:          899 function calls in 1.034 seconds

   Ordered by: cumulative time
   List reduced from 170 to 5 due to restriction <5>

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
       12    0.000    0.000    1.034    0.086 base_events.py:1815(_run_once)
        2    0.000    0.000    1.034    0.517 base_events.py:606(run_until_complete)
        2    0.000    0.000    1.034    0.517 base_events.py:583(run_forever)
       20    0.000    0.000    1.033    0.052 events.py:78(_run)
       20    0.000    0.000    1.033    0.052 {method 'run' of 'Context' objects}



2022-09-06 15:47:38 [T:MainThread] INFO:aiomisc.service.profiler.140319943764528: Stop profiler
```

### Декораторы

#### @timeout

У нас есть функция, которая делает asyncio.sleep() на 2 секунды. И мы можем для нее указать декоратором определенный таймаут, например 1 секунду.

```python
from aiomisc import timeout

@timeout(1)
async def bad_func():
    await asyncio.sleep(2)
```

#### @asyncbackoff

- подходит к проблеме теймаутов и ретрайев со стороны пользователя
  
  - пользователю не важна причина по которой сервер не отвечает
  
  - пользователь не хочет слишком долго ждать

Как это будет выглядеть:

```python
from typing import Type
from aiomisc import asyncbackoff

attempt_timeout = 0.1
deadline = 1
pause = 0.1

@asyncbackoff(attempt_timeout, deadline, pause)
async def db_fetch():
    pass

# Passing exceptions for handling
@asyncbackoff(0.1, 1, 0.1, TypeError, RuntimeError, ValueError)
'''
0.1            # timeout of one attempt
1              # maximum execution time
0.1            # pause between attempts
RuntimeError   # retry only these exceptions  
'''
async def db_fetch(data: dict):
    pass
```

Инициализируем таймаут, дедлайн и паузу. В asyncbackoff первым аргументом - время на ретрай, второй - максимвлаьное время выполнения, третий - какую паузу мы делаем между нашими попытками. RuntimeError - это ретрай только на такие исключения.

Как это может выглядеть.

![](/home/vibo/Pictures/GlobalMarkText/2022-09-06-16-07-37-image.png)

Первая ситуация, когда все сработало с первого раза. Во втором случае мы сначала зафейлились, затем сделали установленную паузу, сделали вторую попытку и все заработало. Третья систуация неприятная - у нас таймаут, затем ошибка и удачное соединение, в итоге отменяемся, т.к. вышли за таймаут по времени. Четвертая ситуация, когда ловим исключение не из списка обрабатываемых (OSError). Мы это исключение не указывали в допустимое для retry и мы поэтому завершаемся. Дальше наша задача - проанализировать это исключение и подумать, что мы с ним будем делать.

#### Еще примеры

Первый случай - максимлаьное количество повторных попыток 3 (max_tries) и указываем для каких исключений мы делаем ретрай, если получили.

Второй пример - аргумент giveup, где мы указываем правило - можем или нет мы делать ретрай при еще одном условии. 

```python
# Will be retried no more then 2 times (3 tries total)
@asyncbackoff(attempt_timeout=0.5, 
                deadline=1,
                pause=0.1,
                max_tries=3,
                exceptions=[TypeError, RuntimeError, ValueError])
async def db_fetch(data: dict):
    pass

# Will be retried only on connection abort (on POSIX systems)
@asyncbackoff(attempt_timeout=0.5, 
                deadline=1,
                pause=0.1,
                exceptions=[OSError],
                giveup=lambda e: e.errno != errno.ECONNABORTED)
async def db_fetch(data: dict):
    pass
```

#### FileIO

Есть некий file_write в котором мы открываем файл для записи. Деалем записи и после этого печатаем содержимое.

```python
from aiomisc.io import async_open

async def file_write():
    async with async_open('/tmp/test', 'w+') as afp:
        await afp.write("Hello")
        await afp.write(" ")
        await afp.write("world")

        await afp.seek(0)
        print(await afp.read())
```

### Работа с потоками

#### @aiomisc.threaded

threaded полезен, чтобы мы не блокировались, т.е. это более тонкая донастройка для тех ситуаций, где мы можем заблокироваться.

```python
import asyncio, time, aiomisc

@aiomisc.threaded
def blocking_function():
    time.sleep(1)

async def main():
    # Running in parallel
    await asyncio.gather(
        blocking_function(),
        blocking_function(),
    )

with aiomisc.entrypoint() as loop:
    loop.run_until_complete(main())
```
